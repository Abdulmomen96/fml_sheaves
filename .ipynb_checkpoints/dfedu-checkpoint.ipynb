{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d5d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7617ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph implementation\n",
    "def generate_graph(cluster_sizes=[100,100], pin=0.5, pout=0.01, seed=0):\n",
    "    \"\"\"Generate a random connected graph\"\"\"\n",
    "    probs = np.array([[pin, pout],[pout, pin]])\n",
    "    while True:\n",
    "        g = nx.stochastic_block_model(cluster_sizes, probs)\n",
    "        if nx.algorithms.components.is_connected(g):\n",
    "            return g\n",
    "\n",
    "\n",
    "cluster_sizes = [10, 10]\n",
    "pin = 0.5\n",
    "pout = 0.01\n",
    "seed = 0\n",
    "alpha = 1e-3\n",
    "lamda = 1e-3\n",
    "eta = 1e-3\n",
    "no_users = sum(cluster_sizes)\n",
    "batch_size = 20\n",
    "epochs = 1\n",
    "it = 1000\n",
    "G = generate_graph(cluster_sizes, pin, pout, seed)\n",
    "\n",
    "#nx.draw(G, with_labels=True, node_size=100, alpha=1, linewidths=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809e7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.2        0.         0.16666667\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.33333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2        0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.2        0.         0.         0.         0.         0.16666667\n",
      "  0.16666667 0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.         0.16666667 0.         0.\n",
      "  0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.         0.16666667 0.         0.16666667\n",
      "  0.         0.16666667 0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.2        0.         0.         0.16666667\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.2        0.2        0.\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.11111111 0.         0.11111111\n",
      "  0.11111111 0.         0.11111111 0.11111111 0.11111111 0.11111111\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.125      0.14285714 0.         0.         0.         0.2\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.         0.         0.11111111 0.125\n",
      "  0.         0.125      0.         0.125      0.         0.125\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.14285714\n",
      "  0.125      0.         0.125      0.         0.14285714 0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.125      0.         0.         0.         0.\n",
      "  0.         0.125      0.         0.         0.11111111 0.\n",
      "  0.         0.125      0.         0.125      0.125      0.\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.125      0.         0.125      0.         0.16666667 0.16666667\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.         0.14285714 0.125      0.16666667 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.2\n",
      "  0.125      0.         0.         0.16666667 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.125      0.14285714 0.125      0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.33333333 0.         0.         0.         0.\n",
      "  0.         0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "[[0.46666667 0.         0.         0.2        0.         0.16666667\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.54166667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.33333333]\n",
      " [0.         0.         0.8        0.         0.         0.\n",
      "  0.         0.2        0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.2        0.         0.         0.26666667 0.         0.16666667\n",
      "  0.16666667 0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.8        0.\n",
      "  0.         0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.         0.16666667 0.         0.20833333\n",
      "  0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.         0.16666667 0.         0.16666667\n",
      "  0.16666667 0.16666667 0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.2        0.         0.         0.16666667\n",
      "  0.16666667 0.34166667 0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.2        0.2        0.\n",
      "  0.16666667 0.         0.23333333 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.74603175 0.11111111 0.\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.11111111 0.11111111 0.11111111\n",
      "  0.11111111 0.         0.11111111 0.11111111 0.11111111 0.11111111\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.42103175\n",
      "  0.125      0.14285714 0.         0.         0.         0.2\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.         0.         0.11111111 0.125\n",
      "  0.13888889 0.125      0.         0.125      0.         0.125\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.14285714\n",
      "  0.125      0.17857143 0.125      0.         0.14285714 0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.125      0.         0.         0.         0.\n",
      "  0.         0.125      0.         0.         0.11111111 0.\n",
      "  0.         0.125      0.13888889 0.125      0.125      0.\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.125      0.         0.125      0.30555556 0.16666667 0.16666667\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.         0.14285714 0.125      0.16666667 0.45436508 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.2\n",
      "  0.125      0.         0.         0.16666667 0.         0.39722222\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11111111 0.\n",
      "  0.125      0.14285714 0.125      0.         0.         0.\n",
      "  0.49603175 0.        ]\n",
      " [0.         0.33333333 0.         0.         0.         0.\n",
      "  0.         0.         0.2        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46666667]]\n"
     ]
    }
   ],
   "source": [
    "# Metropolis weights \n",
    "number_nodes = G.number_of_nodes()\n",
    "weights = np.zeros([number_nodes, number_nodes])\n",
    "for edge in G.edges():\n",
    "  i, j = edge[0], edge[1]\n",
    "  weights[i - 1][j - 1] = 1 / (1 + np.max([G.degree(i), G.degree(j)]))\n",
    "  weights[j - 1][i - 1] = weights[i - 1][j - 1]\n",
    "\n",
    "print(weights)\n",
    "\n",
    "weights = weights + np.diag(1 - np.sum(weights, axis=0))\n",
    "\n",
    "metropolis_weights = weights\n",
    "print(metropolis_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f67564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees(A):\n",
    "    \"\"\"Return the degrees of each node of a graph from its adjacency matrix\"\"\"\n",
    "    return np.sum(A, axis=0).reshape(A.shape[0], 1)\n",
    "\n",
    "def node_degree(n, G):\n",
    "    cnt = 0\n",
    "    for i in G.neighbors(n):\n",
    "        cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def get_neighbors(n, G):\n",
    "    neighbors_list = []\n",
    "    for i in G.neighbors(n):\n",
    "        neighbors_list.append(int(i))\n",
    "    return neighbors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc31eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = {}\n",
    "count = 0\n",
    "W1 = np.array([2, 2])\n",
    "W2 = np.array([-2, 2])\n",
    "W = [W1, W2]\n",
    "m = 200\n",
    "n = 2\n",
    "noise_sd = 0.001\n",
    "for i, cluster_size in enumerate(cluster_sizes):\n",
    "    for j in range(cluster_size):\n",
    "        features = np.random.normal(loc=0.0, scale=1.0, size=(m, n))\n",
    "        label = np.dot(features, W[i]) + np.random.normal(0,noise_sd)\n",
    "        datapoints[count] = {\n",
    "                'features': features,\n",
    "                'degree': node_degree(count, G),\n",
    "                'label': label,\n",
    "                'neighbors': get_neighbors(count, G)\n",
    "            }\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self, user_id):\n",
    "        super(MLP_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 1, bias=False)\n",
    "        #self.fc2 = nn.Linear(4, 1, bias=False)\n",
    "        #self.fc3 = nn.Linear(200, 10)\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        output = self.fc1(x)\n",
    "        #output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93f4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "\n",
    "def grads_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:\n",
    "    r\"\"\"Convert parameters to one vector\n",
    "\n",
    "    Args:\n",
    "        parameters (Iterable[Tensor]): an iterator of Tensors that are the\n",
    "            parameters of a model.\n",
    "\n",
    "    Returns:\n",
    "        The parameters represented by a single vector\n",
    "    \"\"\"\n",
    "    # Flag for the device where the parameter is located\n",
    "    param_device = None\n",
    "\n",
    "    vec = []\n",
    "    for param in parameters:\n",
    "        # Ensure the parameters are located in the same device\n",
    "        param_device = param.grad\n",
    "\n",
    "        vec.append(param_device.view(-1))\n",
    "    return torch.cat(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd3a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(8.6241, grad_fn=<MseLossBackward0>) tensor([ 3.0351, -5.3492]) tensor([-0.6493, -0.4578], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(5.5159, grad_fn=<MseLossBackward0>) tensor([ 0.8309, -4.1325]) tensor([-0.6797, -0.4043], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(5.1969, grad_fn=<MseLossBackward0>) tensor([ 2.5751, -2.9683]) tensor([-0.6880, -0.3629], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(8.2065, grad_fn=<MseLossBackward0>) tensor([ 3.2179, -5.2606]) tensor([-0.7138, -0.3333], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(7.4282, grad_fn=<MseLossBackward0>) tensor([ 2.8184, -4.9636]) tensor([-0.7459, -0.2806], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(4.7501, grad_fn=<MseLossBackward0>) tensor([ 0.7722, -3.8343]) tensor([-0.7741, -0.2310], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(4.4767, grad_fn=<MseLossBackward0>) tensor([ 2.3913, -2.7542]) tensor([-0.7818, -0.1927], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(7.0685, grad_fn=<MseLossBackward0>) tensor([ 2.9874, -4.8818]) tensor([-0.8058, -0.1651], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(6.3981, grad_fn=<MseLossBackward0>) tensor([ 2.6171, -4.6059]) tensor([-0.8356, -0.1163], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(4.0906, grad_fn=<MseLossBackward0>) tensor([ 0.7177, -3.5576]) tensor([-0.8618, -0.0702], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(3.8563, grad_fn=<MseLossBackward0>) tensor([ 2.2206, -2.5556]) tensor([-0.8690, -0.0347], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(6.0882, grad_fn=<MseLossBackward0>) tensor([ 2.7733, -4.5302]) tensor([-0.8912, -0.0091], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(5.5109, grad_fn=<MseLossBackward0>) tensor([ 2.4301, -4.2739]) tensor([-0.9189,  0.0362], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(3.5227, grad_fn=<MseLossBackward0>) tensor([ 0.6669, -3.3009]) tensor([-0.9432,  0.0789], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(3.3219, grad_fn=<MseLossBackward0>) tensor([ 2.0621, -2.3713]) tensor([-0.9499,  0.1119], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(5.2439, grad_fn=<MseLossBackward0>) tensor([ 2.5746, -4.2040]) tensor([-0.9705,  0.1356], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(4.7467, grad_fn=<MseLossBackward0>) tensor([ 2.2565, -3.9659]) tensor([-0.9962,  0.1777], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(3.0336, grad_fn=<MseLossBackward0>) tensor([ 0.6198, -3.0627]) tensor([-1.0188,  0.2173], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(2.8616, grad_fn=<MseLossBackward0>) tensor([ 1.9149, -2.2003]) tensor([-1.0250,  0.2480], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(4.5167, grad_fn=<MseLossBackward0>) tensor([ 2.3900, -3.9012]) tensor([-1.0442,  0.2700], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(4.0885, grad_fn=<MseLossBackward0>) tensor([ 2.0953, -3.6801]) tensor([-1.0681,  0.3090], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(2.6125, grad_fn=<MseLossBackward0>) tensor([ 0.5759, -2.8418]) tensor([-1.0890,  0.3458], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(2.4650, grad_fn=<MseLossBackward0>) tensor([ 1.7781, -2.0417]) tensor([-1.0948,  0.3742], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(3.8904, grad_fn=<MseLossBackward0>) tensor([ 2.2188, -3.6203]) tensor([-1.1126,  0.3946], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(3.5215, grad_fn=<MseLossBackward0>) tensor([ 1.9455, -3.4149]) tensor([-1.1347,  0.4308], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(2.2498, grad_fn=<MseLossBackward0>) tensor([ 0.5352, -2.6367]) tensor([-1.1542,  0.4650], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(2.1234, grad_fn=<MseLossBackward0>) tensor([ 1.6511, -1.8945]) tensor([-1.1595,  0.4913], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(3.3508, grad_fn=<MseLossBackward0>) tensor([ 2.0597, -3.3596]) tensor([-1.1761,  0.5103], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(3.0332, grad_fn=<MseLossBackward0>) tensor([ 1.8065, -3.1688]) tensor([-1.1967,  0.5439], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.9374, grad_fn=<MseLossBackward0>) tensor([ 0.4973, -2.4465]) tensor([-1.2147,  0.5756], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.8291, grad_fn=<MseLossBackward0>) tensor([ 1.5332, -1.7579]) tensor([-1.2197,  0.6000], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(2.8861, grad_fn=<MseLossBackward0>) tensor([ 1.9121, -3.1177]) tensor([-1.2350,  0.6176], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(2.6126, grad_fn=<MseLossBackward0>) tensor([ 1.6774, -2.9405]) tensor([-1.2541,  0.6488], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.6685, grad_fn=<MseLossBackward0>) tensor([ 0.4621, -2.2700]) tensor([-1.2709,  0.6782], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.5757, grad_fn=<MseLossBackward0>) tensor([ 1.4237, -1.6312]) tensor([-1.2755,  0.7009], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(2.4859, grad_fn=<MseLossBackward0>) tensor([ 1.7750, -2.8931]) tensor([-1.2898,  0.7172], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(2.2503, grad_fn=<MseLossBackward0>) tensor([ 1.5574, -2.7286]) tensor([-1.3075,  0.7461], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.4368, grad_fn=<MseLossBackward0>) tensor([ 0.4294, -2.1062]) tensor([-1.3231,  0.7734], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.3573, grad_fn=<MseLossBackward0>) tensor([ 1.3220, -1.5136]) tensor([-1.3274,  0.7945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(2.1411, grad_fn=<MseLossBackward0>) tensor([ 1.6478, -2.6848]) tensor([-1.3406,  0.8096], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.9383, grad_fn=<MseLossBackward0>) tensor([ 1.4461, -2.5320]) tensor([-1.3571,  0.8365], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.2374, grad_fn=<MseLossBackward0>) tensor([ 0.3990, -1.9543]) tensor([-1.3716,  0.8618], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.1692, grad_fn=<MseLossBackward0>) tensor([ 1.2275, -1.4045]) tensor([-1.3755,  0.8813], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.8442, grad_fn=<MseLossBackward0>) tensor([ 1.5296, -2.4915]) tensor([-1.3878,  0.8954], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.6695, grad_fn=<MseLossBackward0>) tensor([ 1.3427, -2.3496]) tensor([-1.4031,  0.9203], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.0656, grad_fn=<MseLossBackward0>) tensor([ 0.3707, -1.8133]) tensor([-1.4165,  0.9438], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.0072, grad_fn=<MseLossBackward0>) tensor([ 1.1398, -1.3033]) tensor([-1.4203,  0.9619], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.5884, grad_fn=<MseLossBackward0>) tensor([ 1.4200, -2.3121]) tensor([-1.4316,  0.9750], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(1.4380, grad_fn=<MseLossBackward0>) tensor([ 1.2466, -2.1803]) tensor([-1.4458,  0.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.9176, grad_fn=<MseLossBackward0>) tensor([ 0.3445, -1.6825]) tensor([-1.4583,  1.0199], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.8676, grad_fn=<MseLossBackward0>) tensor([ 1.0583, -1.2094]) tensor([-1.4618,  1.0367], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(1.3681, grad_fn=<MseLossBackward0>) tensor([ 1.3181, -2.1456]) tensor([-1.4723,  1.0488], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(1.2386, grad_fn=<MseLossBackward0>) tensor([ 1.1575, -2.0233]) tensor([-1.4855,  1.0703], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.7902, grad_fn=<MseLossBackward0>) tensor([ 0.3201, -1.5611]) tensor([-1.4971,  1.0905], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.7474, grad_fn=<MseLossBackward0>) tensor([ 0.9827, -1.1222]) tensor([-1.5003,  1.1061], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(1.1784, grad_fn=<MseLossBackward0>) tensor([ 1.2236, -1.9911]) tensor([-1.5101,  1.1173], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(1.0669, grad_fn=<MseLossBackward0>) tensor([ 1.0747, -1.8775]) tensor([-1.5224,  1.1372], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.6805, grad_fn=<MseLossBackward0>) tensor([ 0.2974, -1.4485]) tensor([-1.5331,  1.1560], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.6438, grad_fn=<MseLossBackward0>) tensor([ 0.9125, -1.0414]) tensor([-1.5361,  1.1705], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(1.0150, grad_fn=<MseLossBackward0>) tensor([ 1.1359, -1.8477]) tensor([-1.5452,  1.1809], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.9190, grad_fn=<MseLossBackward0>) tensor([ 0.9978, -1.7423]) tensor([-1.5566,  1.1994], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.5861, grad_fn=<MseLossBackward0>) tensor([ 0.2763, -1.3440]) tensor([-1.5665,  1.2168], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.5546, grad_fn=<MseLossBackward0>) tensor([ 0.8472, -0.9663]) tensor([-1.5693,  1.2302], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.8742, grad_fn=<MseLossBackward0>) tensor([ 1.0544, -1.7147]) tensor([-1.5778,  1.2399], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.7915, grad_fn=<MseLossBackward0>) tensor([ 0.9264, -1.6168]) tensor([-1.5883,  1.2571], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.5047, grad_fn=<MseLossBackward0>) tensor([ 0.2567, -1.2471]) tensor([-1.5976,  1.2732], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.4777, grad_fn=<MseLossBackward0>) tensor([ 0.7867, -0.8967]) tensor([-1.6002,  1.2857], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.7529, grad_fn=<MseLossBackward0>) tensor([ 0.9788, -1.5912]) tensor([-1.6080,  1.2947], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.6818, grad_fn=<MseLossBackward0>) tensor([ 0.8601, -1.5004]) tensor([-1.6178,  1.3106], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.4346, grad_fn=<MseLossBackward0>) tensor([ 0.2385, -1.1571]) tensor([-1.6264,  1.3256], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.4115, grad_fn=<MseLossBackward0>) tensor([ 0.7304, -0.8321]) tensor([-1.6288,  1.3372], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.6485, grad_fn=<MseLossBackward0>) tensor([ 0.9086, -1.4766]) tensor([-1.6361,  1.3455], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.5873, grad_fn=<MseLossBackward0>) tensor([ 0.7985, -1.3923]) tensor([-1.6452,  1.3602], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.3743, grad_fn=<MseLossBackward0>) tensor([ 0.2216, -1.0736]) tensor([-1.6532,  1.3742], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.3545, grad_fn=<MseLossBackward0>) tensor([ 0.6782, -0.7721]) tensor([-1.6554,  1.3849], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.5586, grad_fn=<MseLossBackward0>) tensor([ 0.8434, -1.3703]) tensor([-1.6622,  1.3926], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.5058, grad_fn=<MseLossBackward0>) tensor([ 0.7413, -1.2921]) tensor([-1.6706,  1.4063], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.3223, grad_fn=<MseLossBackward0>) tensor([ 0.2059, -0.9962]) tensor([-1.6780,  1.4192], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.3054, grad_fn=<MseLossBackward0>) tensor([ 0.6297, -0.7165]) tensor([-1.6801,  1.4292], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.4811, grad_fn=<MseLossBackward0>) tensor([ 0.7829, -1.2716]) tensor([-1.6864,  1.4364], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.4357, grad_fn=<MseLossBackward0>) tensor([ 0.6883, -1.1990]) tensor([-1.6942,  1.4491], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.2776, grad_fn=<MseLossBackward0>) tensor([ 0.1913, -0.9243]) tensor([-1.7011,  1.4611], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.2631, grad_fn=<MseLossBackward0>) tensor([ 0.5847, -0.6649]) tensor([-1.7030,  1.4703], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.4144, grad_fn=<MseLossBackward0>) tensor([ 0.7267, -1.1801]) tensor([-1.7088,  1.4770], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.3753, grad_fn=<MseLossBackward0>) tensor([ 0.6390, -1.1127]) tensor([-1.7161,  1.4888], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.2390, grad_fn=<MseLossBackward0>) tensor([ 0.1777, -0.8576]) tensor([-1.7225,  1.4999], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.2266, grad_fn=<MseLossBackward0>) tensor([ 0.5428, -0.6170]) tensor([-1.7243,  1.5085], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.3569, grad_fn=<MseLossBackward0>) tensor([ 0.6746, -1.0951]) tensor([-1.7297,  1.5146], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.3233, grad_fn=<MseLossBackward0>) tensor([ 0.5932, -1.0326]) tensor([-1.7364,  1.5256], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.2058, grad_fn=<MseLossBackward0>) tensor([ 0.1651, -0.7958]) tensor([-1.7424,  1.5359], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1952, grad_fn=<MseLossBackward0>) tensor([ 0.5040, -0.5726]) tensor([-1.7440,  1.5439], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.3074, grad_fn=<MseLossBackward0>) tensor([ 0.6262, -1.0162]) tensor([-1.7491,  1.5496], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.2785, grad_fn=<MseLossBackward0>) tensor([ 0.5507, -0.9583]) tensor([-1.7553,  1.5598], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1773, grad_fn=<MseLossBackward0>) tensor([ 0.1534, -0.7384]) tensor([-1.7608,  1.5693], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1682, grad_fn=<MseLossBackward0>) tensor([ 0.4680, -0.5313]) tensor([-1.7624,  1.5767], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.2648, grad_fn=<MseLossBackward0>) tensor([ 0.5813, -0.9430]) tensor([-1.7671,  1.5820], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.2399, grad_fn=<MseLossBackward0>) tensor([ 0.5113, -0.8893]) tensor([-1.7729,  1.5915], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1526, grad_fn=<MseLossBackward0>) tensor([ 0.1425, -0.6851]) tensor([-1.7780,  1.6004], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1449, grad_fn=<MseLossBackward0>) tensor([ 0.4345, -0.4931]) tensor([-1.7794,  1.6072], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.2280, grad_fn=<MseLossBackward0>) tensor([ 0.5396, -0.8751]) tensor([-1.7837,  1.6121], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.2066, grad_fn=<MseLossBackward0>) tensor([ 0.4746, -0.8253]) tensor([-1.7891,  1.6209], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1314, grad_fn=<MseLossBackward0>) tensor([ 0.1324, -0.6357]) tensor([-1.7939,  1.6292], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1248, grad_fn=<MseLossBackward0>) tensor([ 0.4034, -0.4576]) tensor([-1.7952,  1.6355], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1964, grad_fn=<MseLossBackward0>) tensor([ 0.5008, -0.8121]) tensor([-1.7992,  1.6401], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1780, grad_fn=<MseLossBackward0>) tensor([ 0.4406, -0.7659]) tensor([-1.8043,  1.6482], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1132, grad_fn=<MseLossBackward0>) tensor([ 0.1230, -0.5898]) tensor([-1.8087,  1.6559], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1075, grad_fn=<MseLossBackward0>) tensor([ 0.3745, -0.4246]) tensor([-1.8099,  1.6618], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1692, grad_fn=<MseLossBackward0>) tensor([ 0.4649, -0.7536]) tensor([-1.8136,  1.6660], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.1533, grad_fn=<MseLossBackward0>) tensor([ 0.4090, -0.7108]) tensor([-1.8183,  1.6735], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0975, grad_fn=<MseLossBackward0>) tensor([ 0.1143, -0.5472]) tensor([-1.8224,  1.6807], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0926, grad_fn=<MseLossBackward0>) tensor([ 0.3477, -0.3941]) tensor([-1.8235,  1.6861], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.1457, grad_fn=<MseLossBackward0>) tensor([ 0.4315, -0.6994]) tensor([-1.8270,  1.6901], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.1321, grad_fn=<MseLossBackward0>) tensor([ 0.3797, -0.6596]) tensor([-1.8313,  1.6971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0839, grad_fn=<MseLossBackward0>) tensor([ 0.1062, -0.5077]) tensor([-1.8351,  1.7037], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0798, grad_fn=<MseLossBackward0>) tensor([ 0.3229, -0.3657]) tensor([-1.8362,  1.7087], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 tensor(0.1255, grad_fn=<MseLossBackward0>) tensor([ 0.4006, -0.6490]) tensor([-1.8394,  1.7124], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.1137, grad_fn=<MseLossBackward0>) tensor([ 0.3525, -0.6122]) tensor([-1.8434,  1.7189], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0723, grad_fn=<MseLossBackward0>) tensor([ 0.0986, -0.4711]) tensor([-1.8469,  1.7250], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0687, grad_fn=<MseLossBackward0>) tensor([ 0.2998, -0.3394]) tensor([-1.8479,  1.7297], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.1081, grad_fn=<MseLossBackward0>) tensor([ 0.3718, -0.6023]) tensor([-1.8509,  1.7331], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0980, grad_fn=<MseLossBackward0>) tensor([ 0.3272, -0.5681]) tensor([-1.8546,  1.7391], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0622, grad_fn=<MseLossBackward0>) tensor([ 0.0916, -0.4371]) tensor([-1.8579,  1.7448], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0592, grad_fn=<MseLossBackward0>) tensor([ 0.2783, -0.3149]) tensor([-1.8588,  1.7492], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0931, grad_fn=<MseLossBackward0>) tensor([ 0.3451, -0.5589]) tensor([-1.8616,  1.7523], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0844, grad_fn=<MseLossBackward0>) tensor([ 0.3037, -0.5273]) tensor([-1.8651,  1.7579], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0536, grad_fn=<MseLossBackward0>) tensor([ 0.0851, -0.4056]) tensor([-1.8681,  1.7632], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0510, grad_fn=<MseLossBackward0>) tensor([ 0.2584, -0.2923]) tensor([-1.8689,  1.7672], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0802, grad_fn=<MseLossBackward0>) tensor([ 0.3204, -0.5186]) tensor([-1.8715,  1.7702], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0727, grad_fn=<MseLossBackward0>) tensor([ 0.2819, -0.4893]) tensor([-1.8747,  1.7754], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0461, grad_fn=<MseLossBackward0>) tensor([ 0.0791, -0.3763]) tensor([-1.8776,  1.7803], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0440, grad_fn=<MseLossBackward0>) tensor([ 0.2399, -0.2713]) tensor([-1.8783,  1.7840], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0690, grad_fn=<MseLossBackward0>) tensor([ 0.2974, -0.4813]) tensor([-1.8807,  1.7867], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0626, grad_fn=<MseLossBackward0>) tensor([ 0.2617, -0.4542]) tensor([-1.8837,  1.7915], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0397, grad_fn=<MseLossBackward0>) tensor([ 0.0735, -0.3491]) tensor([-1.8863,  1.7961], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0379, grad_fn=<MseLossBackward0>) tensor([ 0.2227, -0.2517]) tensor([-1.8871,  1.7996], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0595, grad_fn=<MseLossBackward0>) tensor([ 0.2760, -0.4466]) tensor([-1.8893,  1.8021], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0540, grad_fn=<MseLossBackward0>) tensor([ 0.2429, -0.4215]) tensor([-1.8921,  1.8066], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0342, grad_fn=<MseLossBackward0>) tensor([ 0.0683, -0.3239]) tensor([-1.8945,  1.8108], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0326, grad_fn=<MseLossBackward0>) tensor([ 0.2068, -0.2336]) tensor([-1.8952,  1.8140], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0512, grad_fn=<MseLossBackward0>) tensor([ 0.2562, -0.4144]) tensor([-1.8972,  1.8163], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0465, grad_fn=<MseLossBackward0>) tensor([ 0.2255, -0.3912]) tensor([-1.8998,  1.8205], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0295, grad_fn=<MseLossBackward0>) tensor([ 0.0634, -0.3005]) tensor([-1.9021,  1.8244], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0281, grad_fn=<MseLossBackward0>) tensor([ 0.1920, -0.2168]) tensor([-1.9027,  1.8274], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0441, grad_fn=<MseLossBackward0>) tensor([ 0.2378, -0.3846]) tensor([-1.9046,  1.8296], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0400, grad_fn=<MseLossBackward0>) tensor([ 0.2093, -0.3631]) tensor([-1.9070,  1.8334], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0254, grad_fn=<MseLossBackward0>) tensor([ 0.0589, -0.2788]) tensor([-1.9091,  1.8371], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0242, grad_fn=<MseLossBackward0>) tensor([ 0.1783, -0.2012]) tensor([-1.9097,  1.8398], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0380, grad_fn=<MseLossBackward0>) tensor([ 0.2207, -0.3569]) tensor([-1.9114,  1.8419], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0345, grad_fn=<MseLossBackward0>) tensor([ 0.1943, -0.3370]) tensor([-1.9137,  1.8454], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0218, grad_fn=<MseLossBackward0>) tensor([ 0.0548, -0.2587]) tensor([-1.9156,  1.8488], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0209, grad_fn=<MseLossBackward0>) tensor([ 0.1655, -0.1868]) tensor([-1.9161,  1.8514], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0327, grad_fn=<MseLossBackward0>) tensor([ 0.2049, -0.3312]) tensor([-1.9178,  1.8532], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0297, grad_fn=<MseLossBackward0>) tensor([ 0.1803, -0.3128]) tensor([-1.9199,  1.8566], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0188, grad_fn=<MseLossBackward0>) tensor([ 0.0509, -0.2400]) tensor([-1.9217,  1.8597], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0180, grad_fn=<MseLossBackward0>) tensor([ 0.1537, -0.1733]) tensor([-1.9222,  1.8621], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0282, grad_fn=<MseLossBackward0>) tensor([ 0.1902, -0.3073]) tensor([-1.9237,  1.8638], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0256, grad_fn=<MseLossBackward0>) tensor([ 0.1674, -0.2903]) tensor([-1.9256,  1.8669], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0162, grad_fn=<MseLossBackward0>) tensor([ 0.0473, -0.2226]) tensor([-1.9273,  1.8698], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0155, grad_fn=<MseLossBackward0>) tensor([ 0.1427, -0.1609]) tensor([-1.9277,  1.8720], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0243, grad_fn=<MseLossBackward0>) tensor([ 0.1765, -0.2852]) tensor([-1.9292,  1.8736], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0221, grad_fn=<MseLossBackward0>) tensor([ 0.1553, -0.2694]) tensor([-1.9309,  1.8765], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0139, grad_fn=<MseLossBackward0>) tensor([ 0.0439, -0.2066]) tensor([-1.9325,  1.8792], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0133, grad_fn=<MseLossBackward0>) tensor([ 0.1325, -0.1493]) tensor([-1.9329,  1.8812], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0209, grad_fn=<MseLossBackward0>) tensor([ 0.1638, -0.2646]) tensor([-1.9343,  1.8827], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0190, grad_fn=<MseLossBackward0>) tensor([ 0.1442, -0.2501]) tensor([-1.9359,  1.8854], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0120, grad_fn=<MseLossBackward0>) tensor([ 0.0408, -0.1916]) tensor([-1.9373,  1.8879], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0115, grad_fn=<MseLossBackward0>) tensor([ 0.1230, -0.1386]) tensor([-1.9377,  1.8898], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0180, grad_fn=<MseLossBackward0>) tensor([ 0.1521, -0.2455]) tensor([-1.9390,  1.8912], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0164, grad_fn=<MseLossBackward0>) tensor([ 0.1338, -0.2321]) tensor([-1.9405,  1.8936], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0103, grad_fn=<MseLossBackward0>) tensor([ 0.0379, -0.1778]) tensor([-1.9418,  1.8960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0099, grad_fn=<MseLossBackward0>) tensor([ 0.1142, -0.1286]) tensor([-1.9422,  1.8977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0155, grad_fn=<MseLossBackward0>) tensor([ 0.1411, -0.2278]) tensor([-1.9434,  1.8990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0141, grad_fn=<MseLossBackward0>) tensor([ 0.1242, -0.2155]) tensor([-1.9448,  1.9013], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0089, grad_fn=<MseLossBackward0>) tensor([ 0.0352, -0.1649]) tensor([-1.9460,  1.9035], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0085, grad_fn=<MseLossBackward0>) tensor([ 0.1060, -0.1194]) tensor([-1.9464,  1.9051], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0133, grad_fn=<MseLossBackward0>) tensor([ 0.1310, -0.2114]) tensor([-1.9474,  1.9063], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0121, grad_fn=<MseLossBackward0>) tensor([ 0.1152, -0.2000]) tensor([-1.9487,  1.9084], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0077, grad_fn=<MseLossBackward0>) tensor([ 0.0328, -0.1530]) tensor([-1.9499,  1.9104], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0074, grad_fn=<MseLossBackward0>) tensor([ 0.0984, -0.1108]) tensor([-1.9502,  1.9119], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0115, grad_fn=<MseLossBackward0>) tensor([ 0.1216, -0.1962]) tensor([-1.9512,  1.9131], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0105, grad_fn=<MseLossBackward0>) tensor([ 0.1069, -0.1857]) tensor([-1.9524,  1.9150], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0066, grad_fn=<MseLossBackward0>) tensor([ 0.0304, -0.1419]) tensor([-1.9535,  1.9169], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0063, grad_fn=<MseLossBackward0>) tensor([ 0.0914, -0.1029]) tensor([-1.9538,  1.9183], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0099, grad_fn=<MseLossBackward0>) tensor([ 0.1128, -0.1820]) tensor([-1.9547,  1.9193], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0090, grad_fn=<MseLossBackward0>) tensor([ 0.0992, -0.1724]) tensor([-1.9558,  1.9211], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0057, grad_fn=<MseLossBackward0>) tensor([ 0.0283, -0.1316]) tensor([-1.9568,  1.9229], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0055, grad_fn=<MseLossBackward0>) tensor([ 0.0849, -0.0955]) tensor([-1.9571,  1.9242], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0085, grad_fn=<MseLossBackward0>) tensor([ 0.1047, -0.1689]) tensor([-1.9579,  1.9251], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0078, grad_fn=<MseLossBackward0>) tensor([ 0.0921, -0.1600]) tensor([-1.9590,  1.9268], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0049, grad_fn=<MseLossBackward0>) tensor([ 0.0263, -0.1221]) tensor([-1.9599,  1.9284], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 tensor(0.0047, grad_fn=<MseLossBackward0>) tensor([ 0.0788, -0.0886]) tensor([-1.9602,  1.9296], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0073, grad_fn=<MseLossBackward0>) tensor([ 0.0972, -0.1567]) tensor([-1.9610,  1.9305], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0067, grad_fn=<MseLossBackward0>) tensor([ 0.0855, -0.1485]) tensor([-1.9619,  1.9321], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0042, grad_fn=<MseLossBackward0>) tensor([ 0.0244, -0.1133]) tensor([-1.9628,  1.9336], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0041, grad_fn=<MseLossBackward0>) tensor([ 0.0732, -0.0823]) tensor([-1.9630,  1.9347], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0063, grad_fn=<MseLossBackward0>) tensor([ 0.0902, -0.1454]) tensor([-1.9638,  1.9355], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0058, grad_fn=<MseLossBackward0>) tensor([ 0.0793, -0.1379]) tensor([-1.9647,  1.9370], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0036, grad_fn=<MseLossBackward0>) tensor([ 0.0227, -0.1050]) tensor([-1.9655,  1.9384], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0035, grad_fn=<MseLossBackward0>) tensor([ 0.0679, -0.0764]) tensor([-1.9657,  1.9394], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0054, grad_fn=<MseLossBackward0>) tensor([ 0.0837, -0.1349]) tensor([-1.9664,  1.9402], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0050, grad_fn=<MseLossBackward0>) tensor([ 0.0736, -0.1280]) tensor([-1.9672,  1.9415], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0031, grad_fn=<MseLossBackward0>) tensor([ 0.0211, -0.0974]) tensor([-1.9679,  1.9428], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0030, grad_fn=<MseLossBackward0>) tensor([ 0.0631, -0.0709]) tensor([-1.9682,  1.9438], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0047, grad_fn=<MseLossBackward0>) tensor([ 0.0777, -0.1252]) tensor([-1.9688,  1.9445], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0043, grad_fn=<MseLossBackward0>) tensor([ 0.0683, -0.1189]) tensor([-1.9696,  1.9458], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0027, grad_fn=<MseLossBackward0>) tensor([ 0.0196, -0.0904]) tensor([-1.9702,  1.9469], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0026, grad_fn=<MseLossBackward0>) tensor([ 0.0586, -0.0658]) tensor([-1.9704,  1.9478], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0040, grad_fn=<MseLossBackward0>) tensor([ 0.0721, -0.1162]) tensor([-1.9710,  1.9485], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0037, grad_fn=<MseLossBackward0>) tensor([ 0.0633, -0.1103]) tensor([-1.9718,  1.9497], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0023, grad_fn=<MseLossBackward0>) tensor([ 0.0183, -0.0838]) tensor([-1.9724,  1.9508], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0544, -0.0611]) tensor([-1.9726,  1.9516], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0035, grad_fn=<MseLossBackward0>) tensor([ 0.0669, -0.1078]) tensor([-1.9731,  1.9522], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0032, grad_fn=<MseLossBackward0>) tensor([ 0.0588, -0.1025]) tensor([-1.9738,  1.9533], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0020, grad_fn=<MseLossBackward0>) tensor([ 0.0170, -0.0777]) tensor([-1.9744,  1.9543], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0505, -0.0567]) tensor([-1.9745,  1.9551], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0030, grad_fn=<MseLossBackward0>) tensor([ 0.0621, -0.1000]) tensor([-1.9750,  1.9557], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0027, grad_fn=<MseLossBackward0>) tensor([ 0.0545, -0.0951]) tensor([-1.9757,  1.9567], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0017, grad_fn=<MseLossBackward0>) tensor([ 0.0158, -0.0721]) tensor([-1.9762,  1.9576], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0017, grad_fn=<MseLossBackward0>) tensor([ 0.0469, -0.0527]) tensor([-1.9764,  1.9583], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0026, grad_fn=<MseLossBackward0>) tensor([ 0.0577, -0.0928]) tensor([-1.9768,  1.9589], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0024, grad_fn=<MseLossBackward0>) tensor([ 0.0506, -0.0883]) tensor([-1.9774,  1.9598], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0015, grad_fn=<MseLossBackward0>) tensor([ 0.0147, -0.0668]) tensor([-1.9779,  1.9607], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0435, -0.0489]) tensor([-1.9781,  1.9613], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0535, -0.0861]) tensor([-1.9785,  1.9618], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0020, grad_fn=<MseLossBackward0>) tensor([ 0.0469, -0.0820]) tensor([-1.9790,  1.9627], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0137, -0.0620]) tensor([-1.9795,  1.9635], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0404, -0.0454]) tensor([-1.9796,  1.9641], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0497, -0.0799]) tensor([-1.9800,  1.9646], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0018, grad_fn=<MseLossBackward0>) tensor([ 0.0435, -0.0762]) tensor([-1.9805,  1.9654], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0127, -0.0574]) tensor([-1.9810,  1.9661], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0376, -0.0422]) tensor([-1.9811,  1.9667], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0016, grad_fn=<MseLossBackward0>) tensor([ 0.0461, -0.0741]) tensor([-1.9815,  1.9671], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0015, grad_fn=<MseLossBackward0>) tensor([ 0.0404, -0.0707]) tensor([-1.9819,  1.9679], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0118, -0.0533]) tensor([-1.9823,  1.9686], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0349, -0.0391]) tensor([-1.9825,  1.9691], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0428, -0.0687]) tensor([-1.9828,  1.9695], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0374, -0.0657]) tensor([-1.9832,  1.9702], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0110, -0.0494]) tensor([-1.9836,  1.9709], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0324, -0.0364]) tensor([-1.9837,  1.9714], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0397, -0.0638]) tensor([-1.9840,  1.9717], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0347, -0.0610]) tensor([-1.9844,  1.9724], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0102, -0.0458]) tensor([-1.9848,  1.9730], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0301, -0.0338]) tensor([-1.9849,  1.9734], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0368, -0.0591]) tensor([-1.9852,  1.9738], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0322, -0.0567]) tensor([-1.9856,  1.9743], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0095, -0.0424]) tensor([-1.9859,  1.9749], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0279, -0.0314]) tensor([-1.9860,  1.9753], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0342, -0.0549]) tensor([-1.9863,  1.9757], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0298, -0.0527]) tensor([-1.9866,  1.9762], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0089, -0.0393]) tensor([-1.9869,  1.9767], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0260, -0.0291]) tensor([-1.9870,  1.9771], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0317, -0.0509]) tensor([-1.9872,  1.9774], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0277, -0.0489]) tensor([-1.9876,  1.9779], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0083, -0.0364]) tensor([-1.9878,  1.9784], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0241, -0.0271]) tensor([-1.9879,  1.9788], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0294, -0.0472]) tensor([-1.9882,  1.9790], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0256, -0.0455]) tensor([-1.9885,  1.9795], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0077, -0.0337]) tensor([-1.9887,  1.9800], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0224, -0.0251]) tensor([-1.9888,  1.9803], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0273, -0.0438]) tensor([-1.9890,  1.9806], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0238, -0.0422]) tensor([-1.9893,  1.9810], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0072, -0.0313]) tensor([-1.9895,  1.9814], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0208, -0.0233]) tensor([-1.9896,  1.9817], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0253, -0.0406]) tensor([-1.9898,  1.9820], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0220, -0.0393]) tensor([-1.9901,  1.9824], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0067, -0.0290]) tensor([-1.9903,  1.9828], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0193, -0.0217]) tensor([-1.9903,  1.9831], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0235, -0.0377]) tensor([-1.9905,  1.9833], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0204, -0.0365]) tensor([-1.9908,  1.9836], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0062, -0.0268]) tensor([-1.9910,  1.9840], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0180, -0.0202]) tensor([-1.9910,  1.9843], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0218, -0.0349]) tensor([-1.9912,  1.9845], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0189, -0.0339]) tensor([-1.9914,  1.9848], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0058, -0.0248]) tensor([-1.9916,  1.9852], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0167, -0.0187]) tensor([-1.9917,  1.9854], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0202, -0.0324]) tensor([-1.9919,  1.9856], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0175, -0.0315]) tensor([-1.9921,  1.9859], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0054, -0.0230]) tensor([-1.9922,  1.9862], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0155, -0.0174]) tensor([-1.9923,  1.9865], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0188, -0.0300]) tensor([-1.9924,  1.9866], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0162, -0.0293]) tensor([-1.9926,  1.9870], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0051, -0.0213]) tensor([-1.9928,  1.9872], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0144, -0.0162]) tensor([-1.9928,  1.9875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0174, -0.0278]) tensor([-1.9930,  1.9876], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0150, -0.0273]) tensor([-1.9932,  1.9879], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0047, -0.0197]) tensor([-1.9933,  1.9882], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0134, -0.0150]) tensor([-1.9934,  1.9884], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0162, -0.0258]) tensor([-1.9935,  1.9885], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0139, -0.0253]) tensor([-1.9937,  1.9888], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0044, -0.0182]) tensor([-1.9938,  1.9890], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0124, -0.0140]) tensor([-1.9938,  1.9892], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0150, -0.0239]) tensor([-1.9940,  1.9893], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0129, -0.0236]) tensor([-1.9941,  1.9896], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(9.7710e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0041, -0.0169]) tensor([-1.9942,  1.9898], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0116, -0.0130]) tensor([-1.9943,  1.9900], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0139, -0.0222]) tensor([-1.9944,  1.9901], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0119, -0.0219]) tensor([-1.9945,  1.9903], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(8.4047e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0038, -0.0156]) tensor([-1.9947,  1.9906], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(8.9281e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0107, -0.0121]) tensor([-1.9947,  1.9907], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0129, -0.0206]) tensor([-1.9948,  1.9908], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0110, -0.0204]) tensor([-1.9949,  1.9910], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(7.2303e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0144]) tensor([-1.9950,  1.9913], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(7.7438e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0100, -0.0112]) tensor([-1.9951,  1.9914], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0120, -0.0191]) tensor([-1.9952,  1.9915], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0102, -0.0190]) tensor([-1.9953,  1.9917], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(6.2214e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0133]) tensor([-1.9954,  1.9919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(6.7216e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0093, -0.0105]) tensor([-1.9954,  1.9920], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(9.5592e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0111, -0.0177]) tensor([-1.9955,  1.9921], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(9.3210e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0094, -0.0177]) tensor([-1.9956,  1.9923], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(5.3548e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0031, -0.0123]) tensor([-1.9957,  1.9925], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(5.8392e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0086, -0.0097]) tensor([-1.9958,  1.9926], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(8.2368e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0103, -0.0164]) tensor([-1.9959,  1.9927], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(8.0768e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0087, -0.0165]) tensor([-1.9960,  1.9929], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(4.6104e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0114]) tensor([-1.9960,  1.9930], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(5.0774e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0080, -0.0091]) tensor([-1.9961,  1.9931], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(7.0993e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0096, -0.0152]) tensor([-1.9962,  1.9932], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(7.0034e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0081, -0.0153]) tensor([-1.9962,  1.9934], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(3.9711e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0105]) tensor([-1.9963,  1.9935], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(4.4193e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0075, -0.0084]) tensor([-1.9964,  1.9936], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(6.1210e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0089, -0.0140]) tensor([-1.9964,  1.9937], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(6.0772e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0075, -0.0143]) tensor([-1.9965,  1.9939], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(3.4225e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0097]) tensor([-1.9966,  1.9940], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(3.8510e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0070, -0.0078]) tensor([-1.9966,  1.9941], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(5.2799e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0082, -0.0130]) tensor([-1.9967,  1.9942], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(5.2782e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0069, -0.0133]) tensor([-1.9968,  1.9943], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(2.9517e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0090]) tensor([-1.9968,  1.9944], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(3.3601e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0065, -0.0073]) tensor([-1.9969,  1.9945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(4.5567e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0076, -0.0120]) tensor([-1.9969,  1.9946], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(4.5885e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0064, -0.0124]) tensor([-1.9970,  1.9947], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(2.5477e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0083]) tensor([-1.9971,  1.9949], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(2.9359e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0060, -0.0068]) tensor([-1.9971,  1.9949], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(3.9348e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0071, -0.0112]) tensor([-1.9972,  1.9950], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(3.9929e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0059, -0.0116]) tensor([-1.9972,  1.9951], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(2.2011e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0076]) tensor([-1.9973,  1.9952], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(2.5691e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0056, -0.0063]) tensor([-1.9973,  1.9953], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(3.4003e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0066, -0.0103]) tensor([-1.9974,  1.9954], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(3.4787e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0054, -0.0108]) tensor([-1.9974,  1.9955], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(1.9040e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0070]) tensor([-1.9975,  1.9956], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(2.2520e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0052, -0.0059]) tensor([-1.9975,  1.9957], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(2.9408e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0061, -0.0096]) tensor([-1.9975,  1.9957], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(3.0347e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0050, -0.0101]) tensor([-1.9976,  1.9958], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(1.6493e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0065]) tensor([-1.9977,  1.9959], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(1.9779e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0049, -0.0055]) tensor([-1.9977,  1.9960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(2.5461e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0056, -0.0088]) tensor([-1.9977,  1.9960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(2.6513e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0046, -0.0094]) tensor([-1.9978,  1.9961], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(1.4312e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0059]) tensor([-1.9978,  1.9962], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(1.7408e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0045, -0.0051]) tensor([-1.9978,  1.9963], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(2.2070e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0052, -0.0082]) tensor([-1.9979,  1.9963], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(2.3201e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0088]) tensor([-1.9979,  1.9964], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(1.2444e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0017, -0.0055]) tensor([-1.9980,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(1.5355e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0048]) tensor([-1.9980,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(1.9156e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0048, -0.0076]) tensor([-1.9980,  1.9966], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(2.0338e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0082]) tensor([-1.9981,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(1.0845e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0050]) tensor([-1.9981,  1.9968], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(1.3579e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0045]) tensor([-1.9981,  1.9968], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(1.6655e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0045, -0.0070]) tensor([-1.9982,  1.9968], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.7864e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0077]) tensor([-1.9982,  1.9969], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(9.4771e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0046]) tensor([-1.9983,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.2041e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0037, -0.0042]) tensor([-1.9983,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.4507e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0065]) tensor([-1.9983,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.5726e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0033, -0.0072]) tensor([-1.9984,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(8.3076e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0014, -0.0042]) tensor([-1.9984,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.0709e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0039]) tensor([-1.9984,  1.9973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.2665e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0038, -0.0060]) tensor([-1.9984,  1.9973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.3877e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0030, -0.0067]) tensor([-1.9985,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(7.3086e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0039]) tensor([-1.9985,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(9.5552e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0032, -0.0036]) tensor([-1.9985,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.1083e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0055]) tensor([-1.9986,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(1.2278e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0063]) tensor([-1.9986,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(6.4556e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0035]) tensor([-1.9986,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(8.5550e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0030, -0.0034]) tensor([-1.9986,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(9.7262e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0033, -0.0051]) tensor([-1.9987,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(1.0895e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0025, -0.0059]) tensor([-1.9987,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(5.7274e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0012, -0.0032]) tensor([-1.9987,  1.9978], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(7.6869e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0032]) tensor([-1.9987,  1.9978], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(8.5631e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0031, -0.0047]) tensor([-1.9988,  1.9979], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(9.6970e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0055]) tensor([-1.9988,  1.9979], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(5.1069e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0011, -0.0029]) tensor([-1.9988,  1.9980], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(6.9346e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0030]) tensor([-1.9988,  1.9980], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(7.5663e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0043]) tensor([-1.9989,  1.9980], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(8.6609e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0052]) tensor([-1.9989,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(4.5789e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0011, -0.0027]) tensor([-1.9989,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(6.2817e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0028]) tensor([-1.9989,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(6.7126e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0040]) tensor([-1.9989,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(7.7629e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0048]) tensor([-1.9990,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(4.1290e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0024]) tensor([-1.9990,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(5.7135e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0026]) tensor([-1.9990,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(5.9797e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0037]) tensor([-1.9990,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(6.9845e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0045]) tensor([-1.9990,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(3.7467e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0022]) tensor([-1.9991,  1.9984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(5.2199e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0025]) tensor([-1.9991,  1.9984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(5.3529e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0034]) tensor([-1.9991,  1.9984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(6.3096e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0043]) tensor([-1.9991,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(3.4220e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0009, -0.0020]) tensor([-1.9991,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(4.7904e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0023]) tensor([-1.9991,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(4.8167e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0031]) tensor([-1.9992,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(5.7244e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0040]) tensor([-1.9992,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(3.1469e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0009, -0.0018]) tensor([-1.9992,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(4.4169e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0022]) tensor([-1.9992,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(4.3582e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0029]) tensor([-1.9992,  1.9987], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "dataloader = DataLoader(MyDataset(datapoints[19][\"features\"], datapoints[19][\"label\"]), batch_size=50, shuffle=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    for (x, y) in dataloader:\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        print(y.size())\n",
    "        print(yhat.size())\n",
    "        loss = criterion(yhat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        print(i, loss, grads_to_vector(model.parameters()), parameters_to_vector(model.parameters()))\n",
    "        #optimizer.step()\n",
    "        new_model = parameters_to_vector(model.parameters()) - lr * grads_to_vector(model.parameters())\n",
    "        vector_to_parameters(parameters=model.parameters(), vec=new_model)\n",
    "        #if i % 50 ==0:\n",
    "            #lr *= 0.9\n",
    "            \n",
    "\n",
    "#parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb22da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9992,  1.9987], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52396ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, alpha, lamda, epochs, projection_list, projected_weights):\n",
    "        self.train_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=batchSize, shuffle=True)\n",
    "        #self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def train(self, model):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5)\n",
    "\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for i, (data, labels) in zip(range(1), self.train_loader):\n",
    "                data, labels = data, labels\n",
    "                optimizer.zero_grad() \n",
    "                output = model(data)  \n",
    "                loss = criterion(output, labels)\n",
    "                #loss += mu/2 * torch.norm(client_param.data - server_param.data)**2\n",
    "                loss.backward()\n",
    "                grads = grads_to_vector(model.parameters())\n",
    "                #optimizer.step()\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                weights = parameters_to_vector(model.parameters())\n",
    "                mat_vec_sum = torch.zeros_like(weights)\n",
    "                for j in G.neighbors(model.user_id):\n",
    "                    mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(torch.transpose(projection_list[model.user_id][j], 0, 1), \n",
    "                                                         projected_weights[j][model.user_id] - projected_weights[model.user_id][j]))\n",
    "                \n",
    "                model_update = parameters_to_vector(model.parameters()) - alpha * (grads + lamda * mat_vec_sum)\n",
    "                \n",
    "            vector_to_parameters(parameters=model.parameters(), vec=model_update)\n",
    "                \n",
    "\n",
    "            train_loss = train_loss/self.batchSize#len(self.train_loader.dataset) \n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "        total_loss = e_loss#sum(e_loss)/len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eeef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing projection matrices\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "#temp = MLP_Net()\n",
    "projection_list = []\n",
    "projected_weights = []\n",
    "\n",
    "def update_ProjWeight(projection_list, projected_weights, first_run=True):\n",
    "    #projected_weights = []\n",
    "    for i in range(no_users):\n",
    "        neighbors_mat = []\n",
    "        neighbors_weights = []\n",
    "        for j in range(no_users):\n",
    "            if j in G.neighbors(i):\n",
    "                with torch.no_grad():\n",
    "                    if first_run == True:\n",
    "                        row, column = parameters_to_vector(models[j].parameters()).size()[0], parameters_to_vector(models[i].parameters()).size()[0]\n",
    "                        mat = torch.zeros((row, column))\n",
    "                        mat.fill_diagonal_(1.0 + 1.0 * float(np.random.randn(1)))\n",
    "                        neighbors_mat.append(mat)\n",
    "                        neighbors_weights.append(torch.matmul(mat, parameters_to_vector(models[j].parameters())))\n",
    "                    else:\n",
    "                        neighbors_weights.append(torch.matmul(projection_list[j][i], parameters_to_vector(models[j].parameters())))\n",
    "            else:\n",
    "                neighbors_mat.append(0)\n",
    "                neighbors_weights.append(0)\n",
    "        if first_run == True:\n",
    "            projection_list.append(neighbors_mat)\n",
    "        projected_weights.append(neighbors_weights)\n",
    "\n",
    "update_ProjWeight(projection_list, projected_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a69ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, tensor([[1.3085, 0.0000],\n",
      "        [0.0000, 1.3085]]), 0, 0, 0, 0, 0, 0, tensor([[1.9988, 0.0000],\n",
      "        [0.0000, 1.9988]]), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(projection_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion): \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data, labels\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        #_, pred = torch.max(output, 1)\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d1a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3277,  0.5009])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.6554,  1.0017], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "with torch.no_grad():    \n",
    "    params = parameters_to_vector(model.parameters())\n",
    "\n",
    "    print(params)\n",
    "\n",
    "params *= 2.\n",
    "\n",
    "vector_to_parameters(parameters=model.parameters(), vec=params)\n",
    "\n",
    "parameters_to_vector(model.parameters())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71472693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.53691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:00<01:24, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.50647\n",
      "Training_loss 8.48446\n",
      "Training_loss 8.46137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:00<01:07, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.43439\n",
      "Training_loss 8.40751\n",
      "Training_loss 8.38230\n",
      "Training_loss 8.35159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:00<01:06, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.32468\n",
      "Training_loss 8.29733\n",
      "Training_loss 8.26364\n",
      "Training_loss 8.22429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 14/1000 [00:00<01:08, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.18889\n",
      "Training_loss 8.16615\n",
      "Training_loss 8.14193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [00:01<01:11, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.11008\n",
      "Training_loss 8.07618\n",
      "Training_loss 8.05248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [00:01<01:08, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.02467\n",
      "Training_loss 7.99321\n",
      "Training_loss 7.97352\n",
      "Training_loss 7.94662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 24/1000 [00:01<01:11, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.93593\n",
      "Training_loss 7.91291\n",
      "Training_loss 7.88255\n",
      "Training_loss 7.86045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [00:02<01:14, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.83667\n",
      "Training_loss 7.79859\n",
      "Training_loss 7.76782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [00:02<01:15, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.73411\n",
      "Training_loss 7.70441\n",
      "Training_loss 7.68147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 34/1000 [00:02<01:15, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.65026\n",
      "Training_loss 7.62230\n",
      "Training_loss 7.58741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 38/1000 [00:02<01:13, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.53979\n",
      "Training_loss 7.52302\n",
      "Training_loss 7.50935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 40/1000 [00:02<01:11, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.45978\n",
      "Training_loss 7.43086\n",
      "Training_loss 7.40335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1000 [00:03<01:11, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.36912\n",
      "Training_loss 7.35492\n",
      "Training_loss 7.33801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [00:03<01:08, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.30465\n",
      "Training_loss 7.27307\n",
      "Training_loss 7.25318\n",
      "Training_loss 7.22973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:03<01:06, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.20441\n",
      "Training_loss 7.18038\n",
      "Training_loss 7.14980\n",
      "Training_loss 7.13858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 54/1000 [00:03<01:05, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.10972\n",
      "Training_loss 7.08152\n",
      "Training_loss 7.05124\n",
      "Training_loss 7.02060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1000 [00:04<01:01, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.00358\n",
      "Training_loss 6.98601\n",
      "Training_loss 6.95102\n",
      "Training_loss 6.93605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [00:04<01:02, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.91638\n",
      "Training_loss 6.89594\n",
      "Training_loss 6.86498\n",
      "Training_loss 6.84423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [00:04<01:02, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.81761\n",
      "Training_loss 6.78604\n",
      "Training_loss 6.77470\n",
      "Training_loss 6.76127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [00:05<00:59, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.74288\n",
      "Training_loss 6.71135\n",
      "Training_loss 6.70047\n",
      "Training_loss 6.67736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 76/1000 [00:05<00:59, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.65368\n",
      "Training_loss 6.62872\n",
      "Training_loss 6.61086\n",
      "Training_loss 6.56217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/1000 [00:05<00:59, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.53720\n",
      "Training_loss 6.51075\n",
      "Training_loss 6.47649\n",
      "Training_loss 6.44346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 84/1000 [00:05<00:57, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.41593\n",
      "Training_loss 6.39321\n",
      "Training_loss 6.37660\n",
      "Training_loss 6.35080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 86/1000 [00:05<00:55, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.33055\n",
      "Training_loss 6.30087\n",
      "Training_loss 6.27387\n",
      "Training_loss 6.25189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 92/1000 [00:06<00:53, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.22711\n",
      "Training_loss 6.21607\n",
      "Training_loss 6.19113\n",
      "Training_loss 6.16444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 96/1000 [00:06<00:54, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.13723\n",
      "Training_loss 6.12529\n",
      "Training_loss 6.10034\n",
      "Training_loss 6.09140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:06<00:55, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.06879\n",
      "Training_loss 6.03514\n",
      "Training_loss 6.01335\n",
      "Training_loss 5.99191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 104/1000 [00:07<00:55, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.97330\n",
      "Training_loss 5.95453\n",
      "Training_loss 5.94468\n",
      "Training_loss 5.92892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 108/1000 [00:07<00:56, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.91718\n",
      "Training_loss 5.88854\n",
      "Training_loss 5.85534\n",
      "Training_loss 5.83398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 112/1000 [00:07<00:58, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.80110\n",
      "Training_loss 5.78101\n",
      "Training_loss 5.75630\n",
      "Training_loss 5.74330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 116/1000 [00:07<00:55, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.72354\n",
      "Training_loss 5.70970\n",
      "Training_loss 5.68980\n",
      "Training_loss 5.66677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 118/1000 [00:08<00:57, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.64562\n",
      "Training_loss 5.61231\n",
      "Training_loss 5.58614\n",
      "Training_loss 5.57135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:08<00:53, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.55332\n",
      "Training_loss 5.52777\n",
      "Training_loss 5.50763\n",
      "Training_loss 5.48502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [00:08<00:55, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.45723\n",
      "Training_loss 5.44289\n",
      "Training_loss 5.42510\n",
      "Training_loss 5.41361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 132/1000 [00:08<00:57, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.39770\n",
      "Training_loss 5.38450\n",
      "Training_loss 5.35864\n",
      "Training_loss 5.33350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 136/1000 [00:09<00:54, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.32284\n",
      "Training_loss 5.29642\n",
      "Training_loss 5.28191\n",
      "Training_loss 5.26348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/1000 [00:09<00:54, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.24431\n",
      "Training_loss 5.22736\n",
      "Training_loss 5.20469\n",
      "Training_loss 5.18715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 144/1000 [00:09<00:54, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.17151\n",
      "Training_loss 5.15822\n",
      "Training_loss 5.13066\n",
      "Training_loss 5.10689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 148/1000 [00:09<00:54, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.08043\n",
      "Training_loss 5.06337\n",
      "Training_loss 5.04528\n",
      "Training_loss 5.03559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:10<00:53, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.01624\n",
      "Training_loss 4.99349\n",
      "Training_loss 4.97360\n",
      "Training_loss 4.95149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 156/1000 [00:10<00:52, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.94138\n",
      "Training_loss 4.92291\n",
      "Training_loss 4.90604\n",
      "Training_loss 4.88910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 160/1000 [00:10<00:51, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.87165\n",
      "Training_loss 4.85788\n",
      "Training_loss 4.83795\n",
      "Training_loss 4.82127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 164/1000 [00:10<00:51, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.79676\n",
      "Training_loss 4.77904\n",
      "Training_loss 4.76502\n",
      "Training_loss 4.74172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 168/1000 [00:11<00:50, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.72580\n",
      "Training_loss 4.71046\n",
      "Training_loss 4.69683\n",
      "Training_loss 4.67900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 172/1000 [00:11<00:52, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.66254\n",
      "Training_loss 4.64259\n",
      "Training_loss 4.62258\n",
      "Training_loss 4.60830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 176/1000 [00:11<00:54, 15.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.59461\n",
      "Training_loss 4.57397\n",
      "Training_loss 4.54999\n",
      "Training_loss 4.53601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 180/1000 [00:11<00:52, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.51853\n",
      "Training_loss 4.50320\n",
      "Training_loss 4.49664\n",
      "Training_loss 4.47420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 184/1000 [00:12<00:50, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.46220\n",
      "Training_loss 4.44535\n",
      "Training_loss 4.43628\n",
      "Training_loss 4.42334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 186/1000 [00:12<00:50, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.41055\n",
      "Training_loss 4.39400\n",
      "Training_loss 4.38205\n",
      "Training_loss 4.36930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 192/1000 [00:12<00:49, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.35683\n",
      "Training_loss 4.34267\n",
      "Training_loss 4.32071\n",
      "Training_loss 4.30028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 196/1000 [00:12<00:52, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.27776\n",
      "Training_loss 4.26581\n",
      "Training_loss 4.25335\n",
      "Training_loss 4.23154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [00:13<00:51, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.21983\n",
      "Training_loss 4.20555\n",
      "Training_loss 4.18681\n",
      "Training_loss 4.17373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 204/1000 [00:13<00:49, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.15265\n",
      "Training_loss 4.14199\n",
      "Training_loss 4.12524\n",
      "Training_loss 4.11405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 208/1000 [00:13<00:50, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.09854\n",
      "Training_loss 4.08381\n",
      "Training_loss 4.07613\n",
      "Training_loss 4.06689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 212/1000 [00:13<00:50, 15.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.05440\n",
      "Training_loss 4.04533\n",
      "Training_loss 4.03191\n",
      "Training_loss 4.01942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 216/1000 [00:14<00:47, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.00880\n",
      "Training_loss 4.00402\n",
      "Training_loss 3.98111\n",
      "Training_loss 3.96858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/1000 [00:14<00:48, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.94865\n",
      "Training_loss 3.93408\n",
      "Training_loss 3.91627\n",
      "Training_loss 3.89682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 222/1000 [00:14<00:48, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.88215\n",
      "Training_loss 3.87202\n",
      "Training_loss 3.86013\n",
      "Training_loss 3.84227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 226/1000 [00:14<00:48, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training_loss 3.83166\n",
      "Training_loss 3.81614\n",
      "Training_loss 3.80061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 230/1000 [00:15<00:47, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.78881\n",
      "Training_loss 3.77715\n",
      "Training_loss 3.75231\n",
      "Training_loss 3.73579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 234/1000 [00:15<00:46, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.71815\n",
      "Training_loss 3.70276\n",
      "Training_loss 3.68372\n",
      "Training_loss 3.67026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 238/1000 [00:15<00:46, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.65922\n",
      "Training_loss 3.64106\n",
      "Training_loss 3.62640\n",
      "Training_loss 3.60493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [00:15<00:48, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.58978\n",
      "Training_loss 3.57777\n",
      "Training_loss 3.57027\n",
      "Training_loss 3.55377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 246/1000 [00:16<00:47, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.54456\n",
      "Training_loss 3.53539\n",
      "Training_loss 3.52044\n",
      "Training_loss 3.50918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/1000 [00:16<00:47, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.50057\n",
      "Training_loss 3.49570\n",
      "Training_loss 3.48187\n",
      "Training_loss 3.47280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 254/1000 [00:16<00:47, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.46451\n",
      "Training_loss 3.45233\n",
      "Training_loss 3.44322\n",
      "Training_loss 3.42917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 258/1000 [00:16<00:47, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.41623\n",
      "Training_loss 3.40341\n",
      "Training_loss 3.39638\n",
      "Training_loss 3.37459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 262/1000 [00:17<00:46, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.36256\n",
      "Training_loss 3.34842\n",
      "Training_loss 3.32810\n",
      "Training_loss 3.31511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 266/1000 [00:17<00:45, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.30073\n",
      "Training_loss 3.28665\n",
      "Training_loss 3.27383\n",
      "Training_loss 3.26219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 270/1000 [00:17<00:45, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.25034\n",
      "Training_loss 3.23890\n",
      "Training_loss 3.22401\n",
      "Training_loss 3.21134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 274/1000 [00:17<00:53, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.19939\n",
      "Training_loss 3.18785\n",
      "Training_loss 3.17590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 278/1000 [00:18<00:51, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.16254\n",
      "Training_loss 3.15371\n",
      "Training_loss 3.14878\n",
      "Training_loss 3.13651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 282/1000 [00:18<00:51, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.12520\n",
      "Training_loss 3.10973\n",
      "Training_loss 3.09338\n",
      "Training_loss 3.08032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 284/1000 [00:18<00:52, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.06962\n",
      "Training_loss 3.05725\n",
      "Training_loss 3.04717\n",
      "Training_loss 3.03612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 288/1000 [00:18<00:50, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.02467\n",
      "Training_loss 3.01423\n",
      "Training_loss 3.00132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 292/1000 [00:19<00:50, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.98739\n",
      "Training_loss 2.96840\n",
      "Training_loss 2.95660\n",
      "Training_loss 2.94346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 296/1000 [00:19<00:47, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.93136\n",
      "Training_loss 2.92289\n",
      "Training_loss 2.91227\n",
      "Training_loss 2.90307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [00:19<00:48, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.88917\n",
      "Training_loss 2.87633\n",
      "Training_loss 2.86806\n",
      "Training_loss 2.85848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [00:20<00:49, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.84988\n",
      "Training_loss 2.84030\n",
      "Training_loss 2.83073\n",
      "Training_loss 2.82200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 308/1000 [00:20<00:46, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.81414\n",
      "Training_loss 2.80373\n",
      "Training_loss 2.79261\n",
      "Training_loss 2.78545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 312/1000 [00:20<00:43, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.77543\n",
      "Training_loss 2.76386\n",
      "Training_loss 2.75420\n",
      "Training_loss 2.74428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 316/1000 [00:20<00:43, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.73583\n",
      "Training_loss 2.72690\n",
      "Training_loss 2.71679\n",
      "Training_loss 2.70798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 320/1000 [00:21<00:42, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.69829\n",
      "Training_loss 2.68216\n",
      "Training_loss 2.66913\n",
      "Training_loss 2.66181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 324/1000 [00:21<00:48, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.65296\n",
      "Training_loss 2.64419\n",
      "Training_loss 2.62972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 326/1000 [00:21<00:51, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.62353\n",
      "Training_loss 2.61245\n",
      "Training_loss 2.60558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/1000 [00:21<00:50, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.59728\n",
      "Training_loss 2.58324\n",
      "Training_loss 2.57515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 332/1000 [00:21<00:52, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.57081\n",
      "Training_loss 2.55815\n",
      "Training_loss 2.54522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 336/1000 [00:22<00:51, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.53583\n",
      "Training_loss 2.52628\n",
      "Training_loss 2.51770\n",
      "Training_loss 2.51269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 340/1000 [00:22<00:46, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.50460\n",
      "Training_loss 2.49793\n",
      "Training_loss 2.49057\n",
      "Training_loss 2.48363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 344/1000 [00:22<00:42, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.47267\n",
      "Training_loss 2.45921\n",
      "Training_loss 2.44927\n",
      "Training_loss 2.44101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 348/1000 [00:23<00:42, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.43201\n",
      "Training_loss 2.42177\n",
      "Training_loss 2.41336\n",
      "Training_loss 2.40805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [00:23<00:41, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.39834\n",
      "Training_loss 2.38827\n",
      "Training_loss 2.37312\n",
      "Training_loss 2.36031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 356/1000 [00:23<00:39, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.35539\n",
      "Training_loss 2.34616\n",
      "Training_loss 2.33910\n",
      "Training_loss 2.33013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 360/1000 [00:23<00:39, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.32302\n",
      "Training_loss 2.31591\n",
      "Training_loss 2.30341\n",
      "Training_loss 2.29503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 364/1000 [00:24<00:39, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.28671\n",
      "Training_loss 2.27615\n",
      "Training_loss 2.26851\n",
      "Training_loss 2.25971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 368/1000 [00:24<00:41, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.25298\n",
      "Training_loss 2.24261\n",
      "Training_loss 2.23430\n",
      "Training_loss 2.22389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 372/1000 [00:24<00:38, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.21300\n",
      "Training_loss 2.20751\n",
      "Training_loss 2.19871\n",
      "Training_loss 2.18981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 376/1000 [00:24<00:40, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.17972\n",
      "Training_loss 2.17814\n",
      "Training_loss 2.16600\n",
      "Training_loss 2.15901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 380/1000 [00:25<00:39, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.14923\n",
      "Training_loss 2.14152\n",
      "Training_loss 2.13281\n",
      "Training_loss 2.12809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 384/1000 [00:25<00:40, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.11885\n",
      "Training_loss 2.11126\n",
      "Training_loss 2.10291\n",
      "Training_loss 2.09488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 388/1000 [00:25<00:39, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.08659\n",
      "Training_loss 2.07891\n",
      "Training_loss 2.07413\n",
      "Training_loss 2.06346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 392/1000 [00:25<00:38, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.05548\n",
      "Training_loss 2.04398\n",
      "Training_loss 2.03777\n",
      "Training_loss 2.02864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 396/1000 [00:26<00:37, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.02221\n",
      "Training_loss 2.01397\n",
      "Training_loss 2.00822\n",
      "Training_loss 1.99957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [00:26<00:39, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.99370\n",
      "Training_loss 1.98733\n",
      "Training_loss 1.97495\n",
      "Training_loss 1.96807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 404/1000 [00:26<00:38, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.96157\n",
      "Training_loss 1.95390\n",
      "Training_loss 1.94866\n",
      "Training_loss 1.93939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 408/1000 [00:26<00:38, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.93451\n",
      "Training_loss 1.92526\n",
      "Training_loss 1.91919\n",
      "Training_loss 1.91116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 412/1000 [00:27<00:38, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.90252\n",
      "Training_loss 1.89012\n",
      "Training_loss 1.88440\n",
      "Training_loss 1.87624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 416/1000 [00:27<00:44, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.86726\n",
      "Training_loss 1.86209\n",
      "Training_loss 1.85333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 420/1000 [00:27<00:41, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.84630\n",
      "Training_loss 1.83914\n",
      "Training_loss 1.83137\n",
      "Training_loss 1.82721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 422/1000 [00:27<00:39, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.81911\n",
      "Training_loss 1.81461\n",
      "Training_loss 1.81072\n",
      "Training_loss 1.80446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 426/1000 [00:28<00:38, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.80004\n",
      "Training_loss 1.79520\n",
      "Training_loss 1.78640\n",
      "Training_loss 1.78187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 432/1000 [00:28<00:38, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.77602\n",
      "Training_loss 1.77103\n",
      "Training_loss 1.76686\n",
      "Training_loss 1.76130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 436/1000 [00:28<00:36, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.75693\n",
      "Training_loss 1.75311\n",
      "Training_loss 1.74811\n",
      "Training_loss 1.74341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 440/1000 [00:29<00:35, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.73488\n",
      "Training_loss 1.72779\n",
      "Training_loss 1.72152\n",
      "Training_loss 1.71292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 444/1000 [00:29<00:36, 15.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.70791\n",
      "Training_loss 1.70124\n",
      "Training_loss 1.69714\n",
      "Training_loss 1.68778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 448/1000 [00:29<00:36, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.68043\n",
      "Training_loss 1.67534\n",
      "Training_loss 1.66875\n",
      "Training_loss 1.66373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 450/1000 [00:29<00:36, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.65741\n",
      "Training_loss 1.64715\n",
      "Training_loss 1.63977\n",
      "Training_loss 1.63386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 456/1000 [00:30<00:34, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.62816\n",
      "Training_loss 1.62266\n",
      "Training_loss 1.61668\n",
      "Training_loss 1.60731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 460/1000 [00:30<00:34, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.60390\n",
      "Training_loss 1.59863\n",
      "Training_loss 1.59161\n",
      "Training_loss 1.58554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 462/1000 [00:30<00:39, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.58237\n",
      "Training_loss 1.57855\n",
      "Training_loss 1.57343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 466/1000 [00:30<00:40, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.57005\n",
      "Training_loss 1.56447\n",
      "Training_loss 1.55799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 468/1000 [00:31<00:39, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.55192\n",
      "Training_loss 1.54240\n",
      "Training_loss 1.54059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 472/1000 [00:31<00:36, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.53516\n",
      "Training_loss 1.52861\n",
      "Training_loss 1.52529\n",
      "Training_loss 1.51765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 476/1000 [00:31<00:37, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.50956\n",
      "Training_loss 1.50267\n",
      "Training_loss 1.49624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 478/1000 [00:31<00:36, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.49109\n",
      "Training_loss 1.48701\n",
      "Training_loss 1.48138\n",
      "Training_loss 1.47816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 482/1000 [00:31<00:35, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.47464\n",
      "Training_loss 1.46946\n",
      "Training_loss 1.46034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 486/1000 [00:32<00:39, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.45268\n",
      "Training_loss 1.44825\n",
      "Training_loss 1.44234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 488/1000 [00:32<00:42, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.43812\n",
      "Training_loss 1.43463\n",
      "Training_loss 1.42719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 490/1000 [00:32<00:43, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.41907\n",
      "Training_loss 1.41288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 494/1000 [00:32<00:39, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.40724\n",
      "Training_loss 1.40289\n",
      "Training_loss 1.39763\n",
      "Training_loss 1.38828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 498/1000 [00:33<00:39, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.38360\n",
      "Training_loss 1.37864\n",
      "Training_loss 1.37417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 500/1000 [00:33<00:43, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.36807\n",
      "Training_loss 1.36397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 502/1000 [00:33<00:51,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.36005\n",
      "Training_loss 1.35516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 504/1000 [00:33<00:50,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.35028\n",
      "Training_loss 1.34465\n",
      "Training_loss 1.33989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 508/1000 [00:34<00:49,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.33571\n",
      "Training_loss 1.33145\n",
      "Training_loss 1.32547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 510/1000 [00:34<00:49,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.31956\n",
      "Training_loss 1.31403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 512/1000 [00:34<00:53,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.31003\n",
      "Training_loss 1.30344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 515/1000 [00:35<00:47, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.29940\n",
      "Training_loss 1.29308\n",
      "Training_loss 1.28860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 517/1000 [00:35<00:43, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.28175\n",
      "Training_loss 1.27638\n",
      "Training_loss 1.27132\n",
      "Training_loss 1.26594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 521/1000 [00:35<00:35, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.25938\n",
      "Training_loss 1.25592\n",
      "Training_loss 1.24949\n",
      "Training_loss 1.24487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 527/1000 [00:35<00:31, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.23983\n",
      "Training_loss 1.23370\n",
      "Training_loss 1.22975\n",
      "Training_loss 1.22583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [00:36<00:30, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.22149\n",
      "Training_loss 1.21644\n",
      "Training_loss 1.21346\n",
      "Training_loss 1.20953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 535/1000 [00:36<00:28, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.20645\n",
      "Training_loss 1.20358\n",
      "Training_loss 1.19871\n",
      "Training_loss 1.19422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 539/1000 [00:36<00:27, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.18967\n",
      "Training_loss 1.18530\n",
      "Training_loss 1.18169\n",
      "Training_loss 1.17783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 543/1000 [00:36<00:26, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.17340\n",
      "Training_loss 1.17141\n",
      "Training_loss 1.16658\n",
      "Training_loss 1.16208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 547/1000 [00:37<00:27, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.15755\n",
      "Training_loss 1.15182\n",
      "Training_loss 1.14836\n",
      "Training_loss 1.14416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 549/1000 [00:37<00:27, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.14073\n",
      "Training_loss 1.13561\n",
      "Training_loss 1.13016\n",
      "Training_loss 1.12678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 552/1000 [00:37<00:26, 17.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.12098\n",
      "Training_loss 1.11562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 556/1000 [00:37<00:30, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.11196\n",
      "Training_loss 1.10860\n",
      "Training_loss 1.10529\n",
      "Training_loss 1.10102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 560/1000 [00:37<00:28, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.09695\n",
      "Training_loss 1.09337\n",
      "Training_loss 1.08907\n",
      "Training_loss 1.08614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 564/1000 [00:38<00:26, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.08315\n",
      "Training_loss 1.08054\n",
      "Training_loss 1.07763\n",
      "Training_loss 1.07296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 568/1000 [00:38<00:26, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.06680\n",
      "Training_loss 1.06369\n",
      "Training_loss 1.06183\n",
      "Training_loss 1.05913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 572/1000 [00:38<00:26, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.05353\n",
      "Training_loss 1.04853\n",
      "Training_loss 1.04514\n",
      "Training_loss 1.04013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 576/1000 [00:38<00:25, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.03680\n",
      "Training_loss 1.03099\n",
      "Training_loss 1.02556\n",
      "Training_loss 1.02160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 580/1000 [00:39<00:30, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.01924\n",
      "Training_loss 1.01561\n",
      "Training_loss 1.01110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 582/1000 [00:39<00:32, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.00578\n",
      "Training_loss 1.00221\n",
      "Training_loss 1.00003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 586/1000 [00:39<00:29, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.99775\n",
      "Training_loss 0.99461\n",
      "Training_loss 0.99093\n",
      "Training_loss 0.98758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 590/1000 [00:39<00:32, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.98430\n",
      "Training_loss 0.97963\n",
      "Training_loss 0.97599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 592/1000 [00:40<00:33, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.97338\n",
      "Training_loss 0.96738\n",
      "Training_loss 0.96282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 596/1000 [00:40<00:31, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.95898\n",
      "Training_loss 0.95337\n",
      "Training_loss 0.95101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 598/1000 [00:40<00:40, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.94629\n",
      "Training_loss 0.94292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 600/1000 [00:40<00:38, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.93807\n",
      "Training_loss 0.93476\n",
      "Training_loss 0.93143\n",
      "Training_loss 0.92739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 606/1000 [00:41<00:29, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.92394\n",
      "Training_loss 0.91965\n",
      "Training_loss 0.91535\n",
      "Training_loss 0.91274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 609/1000 [00:41<00:27, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.90648\n",
      "Training_loss 0.90258\n",
      "Training_loss 0.90011\n",
      "Training_loss 0.89781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 613/1000 [00:41<00:27, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.89344\n",
      "Training_loss 0.88984\n",
      "Training_loss 0.88615\n",
      "Training_loss 0.88160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 617/1000 [00:42<00:29, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.88001\n",
      "Training_loss 0.87684\n",
      "Training_loss 0.87253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 619/1000 [00:42<00:27, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.86984\n",
      "Training_loss 0.86691\n",
      "Training_loss 0.86330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 621/1000 [00:42<00:31, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.85912\n",
      "Training_loss 0.85494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 623/1000 [00:42<00:35, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.85138\n",
      "Training_loss 0.84926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 626/1000 [00:43<00:47,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.84637\n",
      "Training_loss 0.84470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 627/1000 [00:43<00:53,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.84111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 628/1000 [00:43<01:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.83978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 630/1000 [00:44<01:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.83714\n",
      "Training_loss 0.83520\n",
      "Training_loss 0.83070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 634/1000 [00:44<00:38,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.82783\n",
      "Training_loss 0.82261\n",
      "Training_loss 0.81892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 638/1000 [00:44<00:27, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.81631\n",
      "Training_loss 0.81176\n",
      "Training_loss 0.80796\n",
      "Training_loss 0.80380\n",
      "Training_loss 0.79952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 642/1000 [00:44<00:24, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.79631\n",
      "Training_loss 0.79311\n",
      "Training_loss 0.78991\n",
      "Training_loss 0.78591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 646/1000 [00:45<00:28, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.78243\n",
      "Training_loss 0.78001\n",
      "Training_loss 0.77719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 648/1000 [00:45<00:29, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.77474\n",
      "Training_loss 0.77305\n",
      "Training_loss 0.77062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [00:45<00:29, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.76809\n",
      "Training_loss 0.76625\n",
      "Training_loss 0.76460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 654/1000 [00:45<00:32, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.76165\n",
      "Training_loss 0.75833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 656/1000 [00:46<00:34,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.75595\n",
      "Training_loss 0.75317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 658/1000 [00:46<00:36,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.75012\n",
      "Training_loss 0.74806\n",
      "Training_loss 0.74468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 662/1000 [00:46<00:30, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.74204\n",
      "Training_loss 0.73997\n",
      "Training_loss 0.73766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 664/1000 [00:46<00:33,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.73618\n",
      "Training_loss 0.73253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 666/1000 [00:47<00:38,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.72995\n",
      "Training_loss 0.72813\n",
      "Training_loss 0.72557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 670/1000 [00:47<00:35,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.72266\n",
      "Training_loss 0.71849\n",
      "Training_loss 0.71640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 672/1000 [00:47<00:35,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.71373\n",
      "Training_loss 0.71080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 675/1000 [00:48<00:31, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.70791\n",
      "Training_loss 0.70537\n",
      "Training_loss 0.70259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 677/1000 [00:48<00:28, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.70025\n",
      "Training_loss 0.69783\n",
      "Training_loss 0.69647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 681/1000 [00:48<00:25, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.69290\n",
      "Training_loss 0.69111\n",
      "Training_loss 0.68800\n",
      "Training_loss 0.68660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 685/1000 [00:48<00:22, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.68445\n",
      "Training_loss 0.68146\n",
      "Training_loss 0.67944\n",
      "Training_loss 0.67541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 689/1000 [00:49<00:22, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.67259\n",
      "Training_loss 0.67024\n",
      "Training_loss 0.66783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 691/1000 [00:49<00:23, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.66631\n",
      "Training_loss 0.66368\n",
      "Training_loss 0.66132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 695/1000 [00:49<00:22, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65878\n",
      "Training_loss 0.65571\n",
      "Training_loss 0.65336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 697/1000 [00:49<00:23, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65053\n",
      "Training_loss 0.64663\n",
      "Training_loss 0.64478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [00:50<00:23, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.64303\n",
      "Training_loss 0.64126\n",
      "Training_loss 0.63938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 703/1000 [00:50<00:23, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.63807\n",
      "Training_loss 0.63544\n",
      "Training_loss 0.63331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 707/1000 [00:50<00:22, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.63096\n",
      "Training_loss 0.62882\n",
      "Training_loss 0.62635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 711/1000 [00:50<00:21, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.62344\n",
      "Training_loss 0.62114\n",
      "Training_loss 0.61778\n",
      "Training_loss 0.61524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 713/1000 [00:50<00:20, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.61374\n",
      "Training_loss 0.61180\n",
      "Training_loss 0.60911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 717/1000 [00:51<00:20, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.60637\n",
      "Training_loss 0.60340\n",
      "Training_loss 0.60164\n",
      "Training_loss 0.60006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 721/1000 [00:51<00:20, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59801\n",
      "Training_loss 0.59624\n",
      "Training_loss 0.59461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 725/1000 [00:51<00:19, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59278\n",
      "Training_loss 0.59036\n",
      "Training_loss 0.58694\n",
      "Training_loss 0.58503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 729/1000 [00:52<00:18, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.58378\n",
      "Training_loss 0.58057\n",
      "Training_loss 0.57924\n",
      "Training_loss 0.57729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 733/1000 [00:52<00:17, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.57495\n",
      "Training_loss 0.57259\n",
      "Training_loss 0.57008\n",
      "Training_loss 0.56843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 735/1000 [00:52<00:16, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.56573\n",
      "Training_loss 0.56343\n",
      "Training_loss 0.56158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 739/1000 [00:52<00:18, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.55989\n",
      "Training_loss 0.55846\n",
      "Training_loss 0.55643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 743/1000 [00:52<00:17, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.55484\n",
      "Training_loss 0.55298\n",
      "Training_loss 0.55124\n",
      "Training_loss 0.54930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 747/1000 [00:53<00:16, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54736\n",
      "Training_loss 0.54457\n",
      "Training_loss 0.54203\n",
      "Training_loss 0.53991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 749/1000 [00:53<00:17, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.53776\n",
      "Training_loss 0.53451\n",
      "Training_loss 0.53254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 753/1000 [00:53<00:16, 15.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.53042\n",
      "Training_loss 0.52823\n",
      "Training_loss 0.52688\n",
      "Training_loss 0.52475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 757/1000 [00:53<00:15, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52215\n",
      "Training_loss 0.51969\n",
      "Training_loss 0.51813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 761/1000 [00:54<00:16, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.51644\n",
      "Training_loss 0.51454\n",
      "Training_loss 0.51288\n",
      "Training_loss 0.51197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 765/1000 [00:54<00:14, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50900\n",
      "Training_loss 0.50769\n",
      "Training_loss 0.50625\n",
      "Training_loss 0.50494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 767/1000 [00:54<00:15, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50368\n",
      "Training_loss 0.50149\n",
      "Training_loss 0.50080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 769/1000 [00:54<00:16, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49892\n",
      "Training_loss 0.49687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 771/1000 [00:54<00:21, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49495\n",
      "Training_loss 0.49282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 775/1000 [00:55<00:21, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49114\n",
      "Training_loss 0.49010\n",
      "Training_loss 0.48840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 777/1000 [00:55<00:20, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48713\n",
      "Training_loss 0.48536\n",
      "Training_loss 0.48392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 781/1000 [00:55<00:18, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48168\n",
      "Training_loss 0.47998\n",
      "Training_loss 0.47682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 785/1000 [00:56<00:16, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47539\n",
      "Training_loss 0.47345\n",
      "Training_loss 0.47231\n",
      "Training_loss 0.47010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 789/1000 [00:56<00:15, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46838\n",
      "Training_loss 0.46745\n",
      "Training_loss 0.46626\n",
      "Training_loss 0.46407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 793/1000 [00:56<00:14, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46226\n",
      "Training_loss 0.46096\n",
      "Training_loss 0.45885\n",
      "Training_loss 0.45760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 797/1000 [00:56<00:13, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45555\n",
      "Training_loss 0.45416\n",
      "Training_loss 0.45187\n",
      "Training_loss 0.45109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [00:57<00:12, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.44882\n",
      "Training_loss 0.44779\n",
      "Training_loss 0.44616\n",
      "Training_loss 0.44510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 805/1000 [00:57<00:12, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.44361\n",
      "Training_loss 0.44278\n",
      "Training_loss 0.44138\n",
      "Training_loss 0.43935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 809/1000 [00:57<00:11, 16.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43830\n",
      "Training_loss 0.43581\n",
      "Training_loss 0.43331\n",
      "Training_loss 0.43125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 812/1000 [00:57<00:11, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42938\n",
      "Training_loss 0.42616\n",
      "Training_loss 0.42428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 814/1000 [00:57<00:12, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42232\n",
      "Training_loss 0.42076\n",
      "Training_loss 0.41967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 818/1000 [00:58<00:12, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41757\n",
      "Training_loss 0.41618\n",
      "Training_loss 0.41463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 820/1000 [00:58<00:12, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41365\n",
      "Training_loss 0.41245\n",
      "Training_loss 0.41120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 824/1000 [00:58<00:11, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40956\n",
      "Training_loss 0.40752\n",
      "Training_loss 0.40534\n",
      "Training_loss 0.40415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 826/1000 [00:58<00:11, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training_loss 0.40325\n",
      "Training_loss 0.40128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 830/1000 [00:59<00:11, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39946\n",
      "Training_loss 0.39781\n",
      "Training_loss 0.39601\n",
      "Training_loss 0.39451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 834/1000 [00:59<00:11, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39286\n",
      "Training_loss 0.39103\n",
      "Training_loss 0.38955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 838/1000 [00:59<00:10, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38825\n",
      "Training_loss 0.38708\n",
      "Training_loss 0.38592\n",
      "Training_loss 0.38431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 842/1000 [00:59<00:09, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38326\n",
      "Training_loss 0.38176\n",
      "Training_loss 0.37983\n",
      "Training_loss 0.37902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 846/1000 [01:00<00:09, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37796\n",
      "Training_loss 0.37740\n",
      "Training_loss 0.37670\n",
      "Training_loss 0.37538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/1000 [01:00<00:08, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37376\n",
      "Training_loss 0.37279\n",
      "Training_loss 0.37125\n",
      "Training_loss 0.37018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 854/1000 [01:00<00:09, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36925\n",
      "Training_loss 0.36787\n",
      "Training_loss 0.36679\n",
      "Training_loss 0.36523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 858/1000 [01:00<00:09, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36425\n",
      "Training_loss 0.36258\n",
      "Training_loss 0.36113\n",
      "Training_loss 0.36003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 860/1000 [01:00<00:09, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35840\n",
      "Training_loss 0.35750\n",
      "Training_loss 0.35644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 864/1000 [01:01<00:08, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35516\n",
      "Training_loss 0.35433\n",
      "Training_loss 0.35283\n",
      "Training_loss 0.35113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 868/1000 [01:01<00:08, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35055\n",
      "Training_loss 0.34934\n",
      "Training_loss 0.34781\n",
      "Training_loss 0.34639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 873/1000 [01:01<00:07, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34504\n",
      "Training_loss 0.34425\n",
      "Training_loss 0.34293\n",
      "Training_loss 0.34239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 877/1000 [01:02<00:07, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34138\n",
      "Training_loss 0.34007\n",
      "Training_loss 0.33920\n",
      "Training_loss 0.33832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 881/1000 [01:02<00:07, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33712\n",
      "Training_loss 0.33591\n",
      "Training_loss 0.33479\n",
      "Training_loss 0.33301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 885/1000 [01:02<00:07, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33202\n",
      "Training_loss 0.33126\n",
      "Training_loss 0.32901\n",
      "Training_loss 0.32843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 889/1000 [01:02<00:06, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32697\n",
      "Training_loss 0.32526\n",
      "Training_loss 0.32430\n",
      "Training_loss 0.32283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 893/1000 [01:03<00:06, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32168\n",
      "Training_loss 0.32063\n",
      "Training_loss 0.31992\n",
      "Training_loss 0.31906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 895/1000 [01:03<00:06, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31812\n",
      "Training_loss 0.31758\n",
      "Training_loss 0.31680\n",
      "Training_loss 0.31623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [01:03<00:06, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31533\n",
      "Training_loss 0.31437\n",
      "Training_loss 0.31316\n",
      "Training_loss 0.31206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 905/1000 [01:03<00:05, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31080\n",
      "Training_loss 0.31015\n",
      "Training_loss 0.30915\n",
      "Training_loss 0.30803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 909/1000 [01:04<00:05, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30735\n",
      "Training_loss 0.30621\n",
      "Training_loss 0.30533\n",
      "Training_loss 0.30416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 911/1000 [01:04<00:05, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30338\n",
      "Training_loss 0.30220\n",
      "Training_loss 0.30120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 915/1000 [01:04<00:06, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30073\n",
      "Training_loss 0.29963\n",
      "Training_loss 0.29857\n",
      "Training_loss 0.29761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 919/1000 [01:04<00:05, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29636\n",
      "Training_loss 0.29536\n",
      "Training_loss 0.29415\n",
      "Training_loss 0.29317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 923/1000 [01:05<00:05, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29206\n",
      "Training_loss 0.29093\n",
      "Training_loss 0.29007\n",
      "Training_loss 0.28896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 927/1000 [01:05<00:04, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28798\n",
      "Training_loss 0.28665\n",
      "Training_loss 0.28583\n",
      "Training_loss 0.28501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 931/1000 [01:05<00:04, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28401\n",
      "Training_loss 0.28281\n",
      "Training_loss 0.28227\n",
      "Training_loss 0.28082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 933/1000 [01:05<00:06, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27952\n",
      "Training_loss 0.27800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 935/1000 [01:06<00:06,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 937/1000 [01:06<00:11,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27592\n",
      "Training_loss 0.27485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 939/1000 [01:07<00:09,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27368\n",
      "Training_loss 0.27250\n",
      "Training_loss 0.27174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 943/1000 [01:07<00:06,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27064\n",
      "Training_loss 0.26959\n",
      "Training_loss 0.26838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 945/1000 [01:07<00:06,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26713\n",
      "Training_loss 0.26618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 947/1000 [01:07<00:06,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26504\n",
      "Training_loss 0.26398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 949/1000 [01:08<00:05,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26315\n",
      "Training_loss 0.26241\n",
      "Training_loss 0.26188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 951/1000 [01:08<00:05,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26058\n",
      "Training_loss 0.25911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 955/1000 [01:08<00:04,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25807\n",
      "Training_loss 0.25711\n",
      "Training_loss 0.25624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 959/1000 [01:08<00:03, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25521\n",
      "Training_loss 0.25461\n",
      "Training_loss 0.25397\n",
      "Training_loss 0.25341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 963/1000 [01:09<00:02, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25307\n",
      "Training_loss 0.25245\n",
      "Training_loss 0.25138\n",
      "Training_loss 0.25017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 965/1000 [01:09<00:02, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24956\n",
      "Training_loss 0.24858\n",
      "Training_loss 0.24783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 969/1000 [01:09<00:02, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24668\n",
      "Training_loss 0.24576\n",
      "Training_loss 0.24495\n",
      "Training_loss 0.24396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 973/1000 [01:09<00:01, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24324\n",
      "Training_loss 0.24265\n",
      "Training_loss 0.24156\n",
      "Training_loss 0.24045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 977/1000 [01:10<00:01, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23966\n",
      "Training_loss 0.23880\n",
      "Training_loss 0.23824\n",
      "Training_loss 0.23686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [01:10<00:01, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23607\n",
      "Training_loss 0.23547\n",
      "Training_loss 0.23462\n",
      "Training_loss 0.23337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 985/1000 [01:10<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23220\n",
      "Training_loss 0.23105\n",
      "Training_loss 0.23036\n",
      "Training_loss 0.22968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 987/1000 [01:10<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22913\n",
      "Training_loss 0.22799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 991/1000 [01:11<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22703\n",
      "Training_loss 0.22644\n",
      "Training_loss 0.22525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 993/1000 [01:11<00:00, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22485\n",
      "Training_loss 0.22425\n",
      "Training_loss 0.22357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 997/1000 [01:11<00:00, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22246\n",
      "Training_loss 0.22206\n",
      "Training_loss 0.22131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:11<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22047\n",
      "Training_loss 0.21985\n",
      "Training_loss 0.21894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#global_model = CNN_Net().cuda()\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "dummy_models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "\n",
    "#model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "for curr_round in tqdm(range(1, it+1)):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        dummy_models[i].load_state_dict(models[i].state_dict())\n",
    "        local_update = ClientUpdate(dataset=datapoints[i], batchSize=batch_size, alpha=alpha, lamda=lamda, epochs=1, projection_list=projection_list, projected_weights=projected_weights)\n",
    "        weights, loss = local_update.train(dummy_models[i])\n",
    "        w.append(weights)\n",
    "        local_loss.append(loss)\n",
    "        models[i].load_state_dict(w[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Update prjection matrix\n",
    "    \n",
    "    #print(projection_list[0], projected_weights[0])\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        weights = parameters_to_vector(models[i].parameters())\n",
    "        for j in G.neighbors(i):\n",
    "            weights = parameters_to_vector(model.parameters())\n",
    "            mat_vec_sum = torch.zeros_like(weights)\n",
    "            for k in G.neighbors(i):\n",
    "                mat_vec_sum = torch.add(mat_vec_sum, projected_weights[k][i] - projected_weights[i][k])\n",
    "            #print(torch.outer(mat_vec_sum, weights))\n",
    "\n",
    "            projection_list[i][j] = torch.add(projection_list[i][j], -1 * eta * lamda * mat_vec_sum)\n",
    "                                         \n",
    "    projected_weights = []                                          \n",
    "    update_ProjWeight(projection_list, projected_weights, first_run=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "\n",
    "    local_test_acc = []\n",
    "    local_test_loss = []\n",
    "    for k in range(no_users):\n",
    "      \n",
    "      g_loss = testing(models[i], datapoints[i], 50, criterion)\n",
    "      local_test_loss.append(g_loss)\n",
    "    \n",
    "        \n",
    "\n",
    "    g_loss = sum(local_test_loss) / len(local_test_loss)\n",
    "    #g_accuracy = sum(local_test_acc) / len(local_test_acc)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_loss.append(g_loss)\n",
    "    #test_accuracy.append(g_accuracy)\n",
    "    print(\"Training_loss %2.5f\"% (test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff0ff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6937,  1.6237], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot.plot(test_loss)\n",
    "parameters_to_vector(models[19].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "679d15ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for j in G.neighbors(0):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c76fd36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7929, 1.7246], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_vector(models[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f4dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " tensor([[1.3097e+00, 9.0023e-04],\n",
       "         [1.2513e-03, 1.3094e+00]]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " tensor([[2.0000e+00, 9.0023e-04],\n",
       "         [1.2513e-03, 1.9997e+00]]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e98c0b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " tensor([2.9306, 2.7995]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " tensor([3.7994, 3.5854]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf9ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = np.asarray(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dade085",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( 'test_loss', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb16136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
