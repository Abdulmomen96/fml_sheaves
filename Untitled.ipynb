{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d5d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7617ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph implementation\n",
    "def generate_graph(cluster_sizes=[100,100], pin=0.5, pout=0.01, seed=0):\n",
    "    \"\"\"Generate a random connected graph\"\"\"\n",
    "    probs = np.array([[pin, pout],[pout, pin]])\n",
    "    while True:\n",
    "        g = nx.stochastic_block_model(cluster_sizes, probs)\n",
    "        if nx.algorithms.components.is_connected(g):\n",
    "            return g\n",
    "\n",
    "\n",
    "cluster_sizes = [10, 10]\n",
    "pin = 0.5\n",
    "pout = 0.01\n",
    "seed = 0\n",
    "alpha = 1e-3\n",
    "lamda = 1e-3\n",
    "eta = 1e-3\n",
    "no_users = sum(cluster_sizes)\n",
    "batch_size = 20\n",
    "epochs = 1\n",
    "it = 1000\n",
    "G = generate_graph(cluster_sizes, pin, pout, seed)\n",
    "\n",
    "#nx.draw(G, with_labels=True, node_size=100, alpha=1, linewidths=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809e7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.16666667 0.         0.         0.2        0.125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.16666667 0.         0.         0.         0.16666667 0.125\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.125\n",
      "  0.2        0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.2        0.16666667 0.         0.         0.         0.\n",
      "  0.         0.2        0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.125      0.125      0.         0.\n",
      "  0.         0.125      0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125     ]\n",
      " [0.         0.16666667 0.         0.2        0.         0.\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2        0.125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.         0.14285714 0.14285714 0.14285714 0.125\n",
      "  0.14285714 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.14285714\n",
      "  0.         0.         0.         0.125      0.14285714 0.14285714\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.14285714\n",
      "  0.125      0.         0.         0.125      0.         0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.125      0.         0.14285714 0.125      0.         0.14285714\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.125      0.125\n",
      "  0.         0.125      0.         0.125      0.125      0.125\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.125      0.         0.16666667 0.125      0.16666667 0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14285714\n",
      "  0.         0.16666667 0.         0.         0.2        0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.125      0.125\n",
      "  0.125      0.125      0.         0.         0.         0.125\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.125      0.16666667 0.2        0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.14285714\n",
      "  0.125      0.         0.         0.125      0.         0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11111111 0.11111111 0.11111111 0.\n",
      "  0.11111111 0.11111111 0.11111111 0.11111111 0.         0.11111111\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.16666667 0.         0.16666667 0.         0.125\n",
      "  0.         0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "[[0.34166667 0.16666667 0.         0.         0.2        0.125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.16666667 0.20833333 0.         0.         0.16666667 0.125\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.         0.73214286 0.         0.         0.125\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.36547619 0.         0.125\n",
      "  0.2        0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.2        0.16666667 0.         0.         0.29047619 0.\n",
      "  0.         0.2        0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.125      0.125      0.         0.125\n",
      "  0.         0.125      0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125     ]\n",
      " [0.         0.16666667 0.         0.2        0.         0.\n",
      "  0.49047619 0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2        0.125\n",
      "  0.         0.50833333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.         0.14285714 0.14285714 0.14285714 0.125\n",
      "  0.14285714 0.         0.19246032 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.19246032 0.14285714 0.14285714\n",
      "  0.         0.         0.         0.125      0.14285714 0.14285714\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.3531746  0.14285714\n",
      "  0.125      0.         0.         0.125      0.         0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.17857143\n",
      "  0.125      0.         0.14285714 0.125      0.         0.14285714\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.125      0.125\n",
      "  0.13888889 0.125      0.         0.125      0.125      0.125\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.125      0.30555556 0.16666667 0.125      0.16666667 0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14285714\n",
      "  0.         0.16666667 0.37936508 0.         0.2        0.\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.125      0.125\n",
      "  0.125      0.125      0.         0.13888889 0.         0.125\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.125      0.16666667 0.2        0.         0.36547619 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.14285714\n",
      "  0.125      0.         0.         0.125      0.         0.3531746\n",
      "  0.11111111 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11111111 0.11111111 0.11111111 0.\n",
      "  0.11111111 0.11111111 0.11111111 0.11111111 0.         0.11111111\n",
      "  0.11111111 0.        ]\n",
      " [0.16666667 0.16666667 0.         0.16666667 0.         0.125\n",
      "  0.         0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20833333]]\n"
     ]
    }
   ],
   "source": [
    "# Metropolis weights \n",
    "number_nodes = G.number_of_nodes()\n",
    "weights = np.zeros([number_nodes, number_nodes])\n",
    "for edge in G.edges():\n",
    "  i, j = edge[0], edge[1]\n",
    "  weights[i - 1][j - 1] = 1 / (1 + np.max([G.degree(i), G.degree(j)]))\n",
    "  weights[j - 1][i - 1] = weights[i - 1][j - 1]\n",
    "\n",
    "print(weights)\n",
    "\n",
    "weights = weights + np.diag(1 - np.sum(weights, axis=0))\n",
    "\n",
    "metropolis_weights = weights\n",
    "print(metropolis_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654ab72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    transforms_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "    mnist_data_train = datasets.MNIST('./data/mnist', train=True, download=True, transform=transforms_mnist)\n",
    "    mnist_data_test = datasets.MNIST('./data/mnist', train=False, download=True, transform=transforms_mnist)\n",
    "\n",
    "    return mnist_data_train, mnist_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f67564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees(A):\n",
    "    \"\"\"Return the degrees of each node of a graph from its adjacency matrix\"\"\"\n",
    "    return np.sum(A, axis=0).reshape(A.shape[0], 1)\n",
    "\n",
    "def node_degree(n, G):\n",
    "    cnt = 0\n",
    "    for i in G.neighbors(n):\n",
    "        cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def get_neighbors(n, G):\n",
    "    neighbors_list = []\n",
    "    for i in G.neighbors(n):\n",
    "        neighbors_list.append(int(i))\n",
    "    return neighbors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc31eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = {}\n",
    "count = 0\n",
    "W1 = np.array([2, 2])\n",
    "W2 = np.array([-2, 2])\n",
    "W = [W1, W2]\n",
    "m = 200\n",
    "n = 2\n",
    "noise_sd = 0.001\n",
    "for i, cluster_size in enumerate(cluster_sizes):\n",
    "    for j in range(cluster_size):\n",
    "        features = np.random.normal(loc=0.0, scale=1.0, size=(m, n))\n",
    "        label = np.dot(features, W[i]) + np.random.normal(0,noise_sd)\n",
    "        datapoints[count] = {\n",
    "                'features': features,\n",
    "                'degree': node_degree(count, G),\n",
    "                'label': label,\n",
    "                'neighbors': get_neighbors(count, G)\n",
    "            }\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self, user_id):\n",
    "        super(MLP_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 1, bias=False)\n",
    "        #self.fc2 = nn.Linear(4, 1, bias=False)\n",
    "        #self.fc3 = nn.Linear(200, 10)\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        output = self.fc1(x)\n",
    "        #output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93f4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "\n",
    "def grads_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:\n",
    "    r\"\"\"Convert parameters to one vector\n",
    "\n",
    "    Args:\n",
    "        parameters (Iterable[Tensor]): an iterator of Tensors that are the\n",
    "            parameters of a model.\n",
    "\n",
    "    Returns:\n",
    "        The parameters represented by a single vector\n",
    "    \"\"\"\n",
    "    # Flag for the device where the parameter is located\n",
    "    param_device = None\n",
    "\n",
    "    vec = []\n",
    "    for param in parameters:\n",
    "        # Ensure the parameters are located in the same device\n",
    "        param_device = param.grad\n",
    "\n",
    "        vec.append(param_device.view(-1))\n",
    "    return torch.cat(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd3a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(2.1245, grad_fn=<MseLossBackward0>) tensor([ 1.4364, -1.5385]) tensor([-0.6163,  0.5302], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(3.6712, grad_fn=<MseLossBackward0>) tensor([ 2.8876, -2.3296]) tensor([-0.6306,  0.5456], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(5.6275, grad_fn=<MseLossBackward0>) tensor([ 3.5589, -4.5308]) tensor([-0.6595,  0.5689], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(2.9868, grad_fn=<MseLossBackward0>) tensor([ 2.1828, -2.2554]) tensor([-0.6951,  0.6142], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(1.8272, grad_fn=<MseLossBackward0>) tensor([ 1.3317, -1.4271]) tensor([-0.7169,  0.6368], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(3.1573, grad_fn=<MseLossBackward0>) tensor([ 2.6775, -2.1608]) tensor([-0.7303,  0.6510], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(4.8401, grad_fn=<MseLossBackward0>) tensor([ 3.3002, -4.2022]) tensor([-0.7570,  0.6726], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(2.5688, grad_fn=<MseLossBackward0>) tensor([ 2.0239, -2.0920]) tensor([-0.7900,  0.7147], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(1.5715, grad_fn=<MseLossBackward0>) tensor([ 1.2347, -1.3238]) tensor([-0.8103,  0.7356], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(2.7153, grad_fn=<MseLossBackward0>) tensor([ 2.4827, -2.0042]) tensor([-0.8226,  0.7488], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(4.1628, grad_fn=<MseLossBackward0>) tensor([ 3.0603, -3.8975]) tensor([-0.8474,  0.7689], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(2.2093, grad_fn=<MseLossBackward0>) tensor([ 1.8766, -1.9405]) tensor([-0.8780,  0.8078], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(1.3516, grad_fn=<MseLossBackward0>) tensor([ 1.1448, -1.2279]) tensor([-0.8968,  0.8272], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(2.3352, grad_fn=<MseLossBackward0>) tensor([ 2.3021, -1.8589]) tensor([-0.9083,  0.8395], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(3.5804, grad_fn=<MseLossBackward0>) tensor([ 2.8378, -3.6148]) tensor([-0.9313,  0.8581], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(1.9001, grad_fn=<MseLossBackward0>) tensor([ 1.7400, -1.7999]) tensor([-0.9597,  0.8943], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(1.1624, grad_fn=<MseLossBackward0>) tensor([ 1.0614, -1.1390]) tensor([-0.9771,  0.9123], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(2.0084, grad_fn=<MseLossBackward0>) tensor([ 2.1346, -1.7242]) tensor([-0.9877,  0.9236], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(3.0794, grad_fn=<MseLossBackward0>) tensor([ 2.6315, -3.3527]) tensor([-1.0090,  0.9409], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(1.6341, grad_fn=<MseLossBackward0>) tensor([ 1.6133, -1.6695]) tensor([-1.0353,  0.9744], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(0.9998, grad_fn=<MseLossBackward0>) tensor([ 0.9841, -1.0566]) tensor([-1.0515,  0.9911], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(1.7272, grad_fn=<MseLossBackward0>) tensor([ 1.9793, -1.5993]) tensor([-1.0613,  1.0017], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(2.6485, grad_fn=<MseLossBackward0>) tensor([ 2.4402, -3.1095]) tensor([-1.0811,  1.0177], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(1.4054, grad_fn=<MseLossBackward0>) tensor([ 1.4959, -1.5485]) tensor([-1.1055,  1.0488], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(0.8598, grad_fn=<MseLossBackward0>) tensor([ 0.9124, -0.9801]) tensor([-1.1205,  1.0642], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(1.4855, grad_fn=<MseLossBackward0>) tensor([ 1.8353, -1.4834]) tensor([-1.1296,  1.0740], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(2.2779, grad_fn=<MseLossBackward0>) tensor([ 2.2628, -2.8840]) tensor([-1.1479,  1.0889], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(1.2087, grad_fn=<MseLossBackward0>) tensor([ 1.3870, -1.4363]) tensor([-1.1706,  1.1177], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(0.7395, grad_fn=<MseLossBackward0>) tensor([ 0.8460, -0.9091]) tensor([-1.1844,  1.1321], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.2775, grad_fn=<MseLossBackward0>) tensor([ 1.7017, -1.3759]) tensor([-1.1929,  1.1412], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.9592, grad_fn=<MseLossBackward0>) tensor([ 2.0983, -2.6749]) tensor([-1.2099,  1.1549], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.0396, grad_fn=<MseLossBackward0>) tensor([ 1.2860, -1.3322]) tensor([-1.2309,  1.1817], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(0.6360, grad_fn=<MseLossBackward0>) tensor([ 0.7844, -0.8433]) tensor([-1.2438,  1.1950], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.0987, grad_fn=<MseLossBackward0>) tensor([ 1.5779, -1.2761]) tensor([-1.2516,  1.2034], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.6851, grad_fn=<MseLossBackward0>) tensor([ 1.9458, -2.4809]) tensor([-1.2674,  1.2162], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(0.8941, grad_fn=<MseLossBackward0>) tensor([ 1.1924, -1.2357]) tensor([-1.2868,  1.2410], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(0.5470, grad_fn=<MseLossBackward0>) tensor([ 0.7273, -0.7822]) tensor([-1.2988,  1.2534], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(0.9449, grad_fn=<MseLossBackward0>) tensor([ 1.4631, -1.1837]) tensor([-1.3060,  1.2612], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.4493, grad_fn=<MseLossBackward0>) tensor([ 1.8043, -2.3010]) tensor([-1.3207,  1.2730], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(0.7689, grad_fn=<MseLossBackward0>) tensor([ 1.1056, -1.1461]) tensor([-1.3387,  1.2960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(0.4705, grad_fn=<MseLossBackward0>) tensor([ 0.6743, -0.7255]) tensor([-1.3498,  1.3075], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(0.8126, grad_fn=<MseLossBackward0>) tensor([ 1.3567, -1.0979]) tensor([-1.3565,  1.3147], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.2465, grad_fn=<MseLossBackward0>) tensor([ 1.6732, -2.1341]) tensor([-1.3701,  1.3257], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(0.6613, grad_fn=<MseLossBackward0>) tensor([ 1.0252, -1.0631]) tensor([-1.3868,  1.3471], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.4046, grad_fn=<MseLossBackward0>) tensor([ 0.6252, -0.6730]) tensor([-1.3971,  1.3577], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.6989, grad_fn=<MseLossBackward0>) tensor([ 1.2580, -1.0183]) tensor([-1.4033,  1.3644], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.0721, grad_fn=<MseLossBackward0>) tensor([ 1.5515, -1.9793]) tensor([-1.4159,  1.3746], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.5687, grad_fn=<MseLossBackward0>) tensor([ 0.9506, -0.9860]) tensor([-1.4314,  1.3944], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.3480, grad_fn=<MseLossBackward0>) tensor([ 0.5797, -0.6243]) tensor([-1.4409,  1.4043], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.6011, grad_fn=<MseLossBackward0>) tensor([ 1.1664, -0.9445]) tensor([-1.4467,  1.4105], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.9221, grad_fn=<MseLossBackward0>) tensor([ 1.4388, -1.8358]) tensor([-1.4584,  1.4200], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.4891, grad_fn=<MseLossBackward0>) tensor([ 0.8814, -0.9146]) tensor([-1.4728,  1.4383], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.2993, grad_fn=<MseLossBackward0>) tensor([ 0.5375, -0.5790]) tensor([-1.4816,  1.4475], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.5169, grad_fn=<MseLossBackward0>) tensor([ 1.0816, -0.8760]) tensor([-1.4869,  1.4532], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.7931, grad_fn=<MseLossBackward0>) tensor([ 1.3342, -1.7026]) tensor([-1.4978,  1.4620], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.4207, grad_fn=<MseLossBackward0>) tensor([ 0.8172, -0.8483]) tensor([-1.5111,  1.4790], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.2574, grad_fn=<MseLossBackward0>) tensor([ 0.4984, -0.5371]) tensor([-1.5193,  1.4875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.4446, grad_fn=<MseLossBackward0>) tensor([ 1.0029, -0.8126]) tensor([-1.5243,  1.4929], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.6821, grad_fn=<MseLossBackward0>) tensor([ 1.2372, -1.5792]) tensor([-1.5343,  1.5010], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.3618, grad_fn=<MseLossBackward0>) tensor([ 0.7578, -0.7868]) tensor([-1.5467,  1.5168], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.2214, grad_fn=<MseLossBackward0>) tensor([ 0.4621, -0.4982]) tensor([-1.5542,  1.5247], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.3823, grad_fn=<MseLossBackward0>) tensor([ 0.9299, -0.7537]) tensor([-1.5589,  1.5297], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.5867, grad_fn=<MseLossBackward0>) tensor([ 1.1473, -1.4646]) tensor([-1.5682,  1.5372], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.3112, grad_fn=<MseLossBackward0>) tensor([ 0.7026, -0.7298]) tensor([-1.5796,  1.5518], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.1904, grad_fn=<MseLossBackward0>) tensor([ 0.4284, -0.4621]) tensor([-1.5867,  1.5591], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.3288, grad_fn=<MseLossBackward0>) tensor([ 0.8623, -0.6990]) tensor([-1.5909,  1.5638], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.5046, grad_fn=<MseLossBackward0>) tensor([ 1.0639, -1.3584]) tensor([-1.5996,  1.5707], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.2676, grad_fn=<MseLossBackward0>) tensor([ 0.6515, -0.6769]) tensor([-1.6102,  1.5843], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.1638, grad_fn=<MseLossBackward0>) tensor([ 0.3972, -0.4287]) tensor([-1.6167,  1.5911], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.2828, grad_fn=<MseLossBackward0>) tensor([ 0.7995, -0.6484]) tensor([-1.6207,  1.5954], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.4340, grad_fn=<MseLossBackward0>) tensor([ 0.9865, -1.2599]) tensor([-1.6287,  1.6019], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.2302, grad_fn=<MseLossBackward0>) tensor([ 0.6041, -0.6278]) tensor([-1.6386,  1.6145], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.1409, grad_fn=<MseLossBackward0>) tensor([ 0.3683, -0.3976]) tensor([-1.6446,  1.6207], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.2432, grad_fn=<MseLossBackward0>) tensor([ 0.7414, -0.6014]) tensor([-1.6483,  1.6247], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.3733, grad_fn=<MseLossBackward0>) tensor([ 0.9148, -1.1685]) tensor([-1.6557,  1.6307], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.1979, grad_fn=<MseLossBackward0>) tensor([ 0.5601, -0.5823]) tensor([-1.6648,  1.6424], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.1212, grad_fn=<MseLossBackward0>) tensor([ 0.3415, -0.3688]) tensor([-1.6704,  1.6482], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.2092, grad_fn=<MseLossBackward0>) tensor([ 0.6874, -0.5578]) tensor([-1.6739,  1.6519], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.3210, grad_fn=<MseLossBackward0>) tensor([ 0.8483, -1.0838]) tensor([-1.6807,  1.6575], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.1702, grad_fn=<MseLossBackward0>) tensor([ 0.5194, -0.5401]) tensor([-1.6892,  1.6684], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.1042, grad_fn=<MseLossBackward0>) tensor([ 0.3167, -0.3421]) tensor([-1.6944,  1.6738], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.1799, grad_fn=<MseLossBackward0>) tensor([ 0.6374, -0.5174]) tensor([-1.6976,  1.6772], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.2761, grad_fn=<MseLossBackward0>) tensor([ 0.7867, -1.0052]) tensor([-1.7039,  1.6823], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.1464, grad_fn=<MseLossBackward0>) tensor([ 0.4816, -0.5009]) tensor([-1.7118,  1.6924], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.0896, grad_fn=<MseLossBackward0>) tensor([ 0.2936, -0.3173]) tensor([-1.7166,  1.6974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.1547, grad_fn=<MseLossBackward0>) tensor([ 0.5910, -0.4799]) tensor([-1.7196,  1.7006], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.2375, grad_fn=<MseLossBackward0>) tensor([ 0.7295, -0.9323]) tensor([-1.7255,  1.7054], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.1259, grad_fn=<MseLossBackward0>) tensor([ 0.4465, -0.4646]) tensor([-1.7328,  1.7147], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.0771, grad_fn=<MseLossBackward0>) tensor([ 0.2723, -0.2943]) tensor([-1.7372,  1.7193], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1331, grad_fn=<MseLossBackward0>) tensor([ 0.5480, -0.4451]) tensor([-1.7400,  1.7223], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.2043, grad_fn=<MseLossBackward0>) tensor([ 0.6764, -0.8647]) tensor([-1.7454,  1.7267], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1083, grad_fn=<MseLossBackward0>) tensor([ 0.4140, -0.4309]) tensor([-1.7522,  1.7354], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.0663, grad_fn=<MseLossBackward0>) tensor([ 0.2524, -0.2730]) tensor([-1.7563,  1.7397], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1144, grad_fn=<MseLossBackward0>) tensor([ 0.5082, -0.4128]) tensor([-1.7589,  1.7424], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1757, grad_fn=<MseLossBackward0>) tensor([ 0.6273, -0.8020]) tensor([-1.7639,  1.7466], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.0931, grad_fn=<MseLossBackward0>) tensor([ 0.3839, -0.3997]) tensor([-1.7702,  1.7546], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.0570, grad_fn=<MseLossBackward0>) tensor([ 0.2341, -0.2532]) tensor([-1.7741,  1.7586], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.0984, grad_fn=<MseLossBackward0>) tensor([ 0.4712, -0.3829]) tensor([-1.7764,  1.7611], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1511, grad_fn=<MseLossBackward0>) tensor([ 0.5817, -0.7438]) tensor([-1.7811,  1.7649], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.0801, grad_fn=<MseLossBackward0>) tensor([ 0.3560, -0.3707]) tensor([-1.7869,  1.7724], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.0490, grad_fn=<MseLossBackward0>) tensor([ 0.2170, -0.2349]) tensor([-1.7905,  1.7761], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.0846, grad_fn=<MseLossBackward0>) tensor([ 0.4369, -0.3552]) tensor([-1.7927,  1.7784], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1300, grad_fn=<MseLossBackward0>) tensor([ 0.5394, -0.6899]) tensor([-1.7970,  1.7820], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.0689, grad_fn=<MseLossBackward0>) tensor([ 0.3301, -0.3438]) tensor([-1.8024,  1.7889], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.0422, grad_fn=<MseLossBackward0>) tensor([ 0.2013, -0.2179]) tensor([-1.8057,  1.7923], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.0728, grad_fn=<MseLossBackward0>) tensor([ 0.4051, -0.3294]) tensor([-1.8077,  1.7945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1118, grad_fn=<MseLossBackward0>) tensor([ 0.5002, -0.6398]) tensor([-1.8118,  1.7978], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.0592, grad_fn=<MseLossBackward0>) tensor([ 0.3061, -0.3189]) tensor([-1.8168,  1.8042], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0363, grad_fn=<MseLossBackward0>) tensor([ 0.1866, -0.2021]) tensor([-1.8199,  1.8074], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0626, grad_fn=<MseLossBackward0>) tensor([ 0.3756, -0.3056]) tensor([-1.8217,  1.8094], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0961, grad_fn=<MseLossBackward0>) tensor([ 0.4638, -0.5934]) tensor([-1.8255,  1.8125], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0509, grad_fn=<MseLossBackward0>) tensor([ 0.2838, -0.2957]) tensor([-1.8301,  1.8184], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0312, grad_fn=<MseLossBackward0>) tensor([ 0.1730, -0.1874]) tensor([-1.8329,  1.8213], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0538, grad_fn=<MseLossBackward0>) tensor([ 0.3483, -0.2834]) tensor([-1.8347,  1.8232], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0827, grad_fn=<MseLossBackward0>) tensor([ 0.4301, -0.5504]) tensor([-1.8382,  1.8261], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 tensor(0.0438, grad_fn=<MseLossBackward0>) tensor([ 0.2632, -0.2743]) tensor([-1.8425,  1.8316], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0268, grad_fn=<MseLossBackward0>) tensor([ 0.1605, -0.1738]) tensor([-1.8451,  1.8343], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0463, grad_fn=<MseLossBackward0>) tensor([ 0.3230, -0.2629]) tensor([-1.8467,  1.8360], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0711, grad_fn=<MseLossBackward0>) tensor([ 0.3989, -0.5105]) tensor([-1.8499,  1.8387], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0377, grad_fn=<MseLossBackward0>) tensor([ 0.2440, -0.2544]) tensor([-1.8539,  1.8438], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0231, grad_fn=<MseLossBackward0>) tensor([ 0.1488, -0.1612]) tensor([-1.8564,  1.8463], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0398, grad_fn=<MseLossBackward0>) tensor([ 0.2995, -0.2438]) tensor([-1.8578,  1.8479], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0612, grad_fn=<MseLossBackward0>) tensor([ 0.3699, -0.4735]) tensor([-1.8608,  1.8504], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0324, grad_fn=<MseLossBackward0>) tensor([ 0.2263, -0.2359]) tensor([-1.8645,  1.8551], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0199, grad_fn=<MseLossBackward0>) tensor([ 0.1380, -0.1496]) tensor([-1.8668,  1.8575], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0342, grad_fn=<MseLossBackward0>) tensor([ 0.2777, -0.2262]) tensor([-1.8682,  1.8590], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0526, grad_fn=<MseLossBackward0>) tensor([ 0.3430, -0.4391]) tensor([-1.8710,  1.8612], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0279, grad_fn=<MseLossBackward0>) tensor([ 0.2098, -0.2188]) tensor([-1.8744,  1.8656], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0171, grad_fn=<MseLossBackward0>) tensor([ 0.1279, -0.1387]) tensor([-1.8765,  1.8678], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0295, grad_fn=<MseLossBackward0>) tensor([ 0.2575, -0.2098]) tensor([-1.8778,  1.8692], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0453, grad_fn=<MseLossBackward0>) tensor([ 0.3180, -0.4073]) tensor([-1.8803,  1.8713], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0240, grad_fn=<MseLossBackward0>) tensor([ 0.1946, -0.2029]) tensor([-1.8835,  1.8754], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0147, grad_fn=<MseLossBackward0>) tensor([ 0.1186, -0.1287]) tensor([-1.8855,  1.8774], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0253, grad_fn=<MseLossBackward0>) tensor([ 0.2387, -0.1946]) tensor([-1.8867,  1.8787], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0389, grad_fn=<MseLossBackward0>) tensor([ 0.2949, -0.3778]) tensor([-1.8890,  1.8806], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0206, grad_fn=<MseLossBackward0>) tensor([ 0.1804, -0.1882]) tensor([-1.8920,  1.8844], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0126, grad_fn=<MseLossBackward0>) tensor([ 0.1100, -0.1193]) tensor([-1.8938,  1.8863], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0218, grad_fn=<MseLossBackward0>) tensor([ 0.2213, -0.1805]) tensor([-1.8949,  1.8875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0335, grad_fn=<MseLossBackward0>) tensor([ 0.2735, -0.3504]) tensor([-1.8971,  1.8893], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0177, grad_fn=<MseLossBackward0>) tensor([ 0.1673, -0.1745]) tensor([-1.8998,  1.8928], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0109, grad_fn=<MseLossBackward0>) tensor([ 0.1020, -0.1107]) tensor([-1.9015,  1.8945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0187, grad_fn=<MseLossBackward0>) tensor([ 0.2052, -0.1674]) tensor([-1.9025,  1.8956], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0288, grad_fn=<MseLossBackward0>) tensor([ 0.2536, -0.3250]) tensor([-1.9046,  1.8973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0152, grad_fn=<MseLossBackward0>) tensor([ 0.1551, -0.1619]) tensor([-1.9071,  1.9006], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0093, grad_fn=<MseLossBackward0>) tensor([ 0.0946, -0.1027]) tensor([-1.9087,  1.9022], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0161, grad_fn=<MseLossBackward0>) tensor([ 0.1903, -0.1553]) tensor([-1.9096,  1.9032], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0248, grad_fn=<MseLossBackward0>) tensor([ 0.2352, -0.3014]) tensor([-1.9115,  1.9048], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0131, grad_fn=<MseLossBackward0>) tensor([ 0.1438, -0.1501]) tensor([-1.9139,  1.9078], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0080, grad_fn=<MseLossBackward0>) tensor([ 0.0877, -0.0952]) tensor([-1.9153,  1.9093], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0139, grad_fn=<MseLossBackward0>) tensor([ 0.1764, -0.1440]) tensor([-1.9162,  1.9102], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0213, grad_fn=<MseLossBackward0>) tensor([ 0.2181, -0.2796]) tensor([-1.9180,  1.9117], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0113, grad_fn=<MseLossBackward0>) tensor([ 0.1334, -0.1392]) tensor([-1.9201,  1.9145], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0069, grad_fn=<MseLossBackward0>) tensor([ 0.0813, -0.0883]) tensor([-1.9215,  1.9159], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0119, grad_fn=<MseLossBackward0>) tensor([ 0.1636, -0.1336]) tensor([-1.9223,  1.9167], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0183, grad_fn=<MseLossBackward0>) tensor([ 0.2022, -0.2593]) tensor([-1.9239,  1.9181], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0097, grad_fn=<MseLossBackward0>) tensor([ 0.1237, -0.1291]) tensor([-1.9259,  1.9207], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0059, grad_fn=<MseLossBackward0>) tensor([ 0.0754, -0.0819]) tensor([-1.9272,  1.9220], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0102, grad_fn=<MseLossBackward0>) tensor([ 0.1517, -0.1239]) tensor([-1.9279,  1.9228], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0158, grad_fn=<MseLossBackward0>) tensor([ 0.1875, -0.2405]) tensor([-1.9294,  1.9240], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0083, grad_fn=<MseLossBackward0>) tensor([ 0.1147, -0.1197]) tensor([-1.9313,  1.9264], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0051, grad_fn=<MseLossBackward0>) tensor([ 0.0700, -0.0760]) tensor([-1.9325,  1.9276], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0088, grad_fn=<MseLossBackward0>) tensor([ 0.1406, -0.1149]) tensor([-1.9332,  1.9284], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0136, grad_fn=<MseLossBackward0>) tensor([ 0.1739, -0.2231]) tensor([-1.9346,  1.9295], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0072, grad_fn=<MseLossBackward0>) tensor([ 0.1064, -0.1110]) tensor([-1.9363,  1.9318], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0044, grad_fn=<MseLossBackward0>) tensor([ 0.0649, -0.0705]) tensor([-1.9374,  1.9329], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0076, grad_fn=<MseLossBackward0>) tensor([ 0.1304, -0.1066]) tensor([-1.9380,  1.9336], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0117, grad_fn=<MseLossBackward0>) tensor([ 0.1613, -0.2069]) tensor([-1.9393,  1.9346], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0062, grad_fn=<MseLossBackward0>) tensor([ 0.0986, -0.1030]) tensor([-1.9409,  1.9367], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0038, grad_fn=<MseLossBackward0>) tensor([ 0.0602, -0.0654]) tensor([-1.9419,  1.9377], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0065, grad_fn=<MseLossBackward0>) tensor([ 0.1209, -0.0989]) tensor([-1.9425,  1.9384], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0100, grad_fn=<MseLossBackward0>) tensor([ 0.1495, -0.1919]) tensor([-1.9437,  1.9394], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0053, grad_fn=<MseLossBackward0>) tensor([ 0.0915, -0.0955]) tensor([-1.9452,  1.9413], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0033, grad_fn=<MseLossBackward0>) tensor([ 0.0558, -0.0606]) tensor([-1.9462,  1.9423], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0056, grad_fn=<MseLossBackward0>) tensor([ 0.1121, -0.0917]) tensor([-1.9467,  1.9429], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0086, grad_fn=<MseLossBackward0>) tensor([ 0.1387, -0.1780]) tensor([-1.9478,  1.9438], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0046, grad_fn=<MseLossBackward0>) tensor([ 0.0848, -0.0885]) tensor([-1.9492,  1.9456], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0028, grad_fn=<MseLossBackward0>) tensor([ 0.0517, -0.0562]) tensor([-1.9501,  1.9464], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0048, grad_fn=<MseLossBackward0>) tensor([ 0.1039, -0.0851]) tensor([-1.9506,  1.9470], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0074, grad_fn=<MseLossBackward0>) tensor([ 0.1286, -0.1651]) tensor([-1.9516,  1.9479], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0039, grad_fn=<MseLossBackward0>) tensor([ 0.0786, -0.0821]) tensor([-1.9529,  1.9495], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0024, grad_fn=<MseLossBackward0>) tensor([ 0.0480, -0.0521]) tensor([-1.9537,  1.9503], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0041, grad_fn=<MseLossBackward0>) tensor([ 0.0964, -0.0789]) tensor([-1.9542,  1.9508], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0064, grad_fn=<MseLossBackward0>) tensor([ 0.1192, -0.1531]) tensor([-1.9551,  1.9516], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0034, grad_fn=<MseLossBackward0>) tensor([ 0.0729, -0.0761]) tensor([-1.9563,  1.9532], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0021, grad_fn=<MseLossBackward0>) tensor([ 0.0445, -0.0484]) tensor([-1.9571,  1.9539], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0036, grad_fn=<MseLossBackward0>) tensor([ 0.0893, -0.0732]) tensor([-1.9575,  1.9544], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0055, grad_fn=<MseLossBackward0>) tensor([ 0.1106, -0.1420]) tensor([-1.9584,  1.9551], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0029, grad_fn=<MseLossBackward0>) tensor([ 0.0676, -0.0706]) tensor([-1.9595,  1.9566], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0018, grad_fn=<MseLossBackward0>) tensor([ 0.0413, -0.0449]) tensor([-1.9602,  1.9573], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0031, grad_fn=<MseLossBackward0>) tensor([ 0.0828, -0.0679]) tensor([-1.9606,  1.9577], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0047, grad_fn=<MseLossBackward0>) tensor([ 0.1025, -0.1317]) tensor([-1.9614,  1.9584], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0025, grad_fn=<MseLossBackward0>) tensor([ 0.0627, -0.0654]) tensor([-1.9624,  1.9597], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0015, grad_fn=<MseLossBackward0>) tensor([ 0.0383, -0.0416]) tensor([-1.9631,  1.9604], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0026, grad_fn=<MseLossBackward0>) tensor([ 0.0768, -0.0630]) tensor([-1.9635,  1.9608], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0041, grad_fn=<MseLossBackward0>) tensor([ 0.0951, -0.1222]) tensor([-1.9642,  1.9614], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0021, grad_fn=<MseLossBackward0>) tensor([ 0.0582, -0.0607]) tensor([-1.9652,  1.9626], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0355, -0.0386]) tensor([-1.9658,  1.9632], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0023, grad_fn=<MseLossBackward0>) tensor([ 0.0712, -0.0584]) tensor([-1.9661,  1.9636], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0035, grad_fn=<MseLossBackward0>) tensor([ 0.0882, -0.1134]) tensor([-1.9668,  1.9642], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0018, grad_fn=<MseLossBackward0>) tensor([ 0.0539, -0.0563]) tensor([-1.9677,  1.9653], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0329, -0.0358]) tensor([-1.9682,  1.9659], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0020, grad_fn=<MseLossBackward0>) tensor([ 0.0660, -0.0542]) tensor([-1.9686,  1.9663], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0030, grad_fn=<MseLossBackward0>) tensor([ 0.0818, -0.1051]) tensor([-1.9692,  1.9668], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0016, grad_fn=<MseLossBackward0>) tensor([ 0.0500, -0.0522]) tensor([-1.9701,  1.9679], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0306, -0.0332]) tensor([-1.9706,  1.9684], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0017, grad_fn=<MseLossBackward0>) tensor([ 0.0612, -0.0503]) tensor([-1.9709,  1.9687], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0026, grad_fn=<MseLossBackward0>) tensor([ 0.0758, -0.0975]) tensor([-1.9715,  1.9692], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0464, -0.0484]) tensor([-1.9722,  1.9702], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0283, -0.0308]) tensor([-1.9727,  1.9707], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0567, -0.0467]) tensor([-1.9730,  1.9710], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0703, -0.0905]) tensor([-1.9735,  1.9715], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0430, -0.0448]) tensor([-1.9742,  1.9724], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0263, -0.0285]) tensor([-1.9747,  1.9728], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0526, -0.0433]) tensor([-1.9749,  1.9731], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0652, -0.0839]) tensor([-1.9755,  1.9735], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0399, -0.0416]) tensor([-1.9761,  1.9744], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0244, -0.0265]) tensor([-1.9765,  1.9748], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0488, -0.0402]) tensor([-1.9768,  1.9750], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0016, grad_fn=<MseLossBackward0>) tensor([ 0.0604, -0.0778]) tensor([-1.9772,  1.9754], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0370, -0.0385]) tensor([-1.9779,  1.9762], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0226, -0.0245]) tensor([-1.9782,  1.9766], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0452, -0.0373]) tensor([-1.9784,  1.9769], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0560, -0.0722]) tensor([-1.9789,  1.9772], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0343, -0.0357]) tensor([-1.9795,  1.9779], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0210, -0.0228]) tensor([-1.9798,  1.9783], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0419, -0.0346]) tensor([-1.9800,  1.9785], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0520, -0.0670]) tensor([-1.9804,  1.9789], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0318, -0.0331]) tensor([-1.9810,  1.9795], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0195, -0.0211]) tensor([-1.9813,  1.9799], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0388, -0.0321]) tensor([-1.9815,  1.9801], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0482, -0.0621]) tensor([-1.9819,  1.9804], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0295, -0.0307]) tensor([-1.9823,  1.9810], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0181, -0.0196]) tensor([-1.9826,  1.9813], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0360, -0.0298]) tensor([-1.9828,  1.9815], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0447, -0.0576]) tensor([-1.9832,  1.9818], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0274, -0.0284]) tensor([-1.9836,  1.9824], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0168, -0.0182]) tensor([-1.9839,  1.9827], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0334, -0.0276]) tensor([-1.9841,  1.9829], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0414, -0.0535]) tensor([-1.9844,  1.9832], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0254, -0.0264]) tensor([-1.9848,  1.9837], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0156, -0.0168]) tensor([-1.9851,  1.9840], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0309, -0.0256]) tensor([-1.9852,  1.9841], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0384, -0.0496]) tensor([-1.9855,  1.9844], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0235, -0.0244]) tensor([-1.9859,  1.9849], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0144, -0.0156]) tensor([-1.9861,  1.9851], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0287, -0.0238]) tensor([-1.9863,  1.9853], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0356, -0.0460]) tensor([-1.9866,  1.9855], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0218, -0.0226]) tensor([-1.9869,  1.9860], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0134, -0.0145]) tensor([-1.9872,  1.9862], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0266, -0.0221]) tensor([-1.9873,  1.9863], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0330, -0.0427]) tensor([-1.9876,  1.9866], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0203, -0.0210]) tensor([-1.9879,  1.9870], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0124, -0.0134]) tensor([-1.9881,  1.9872], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0246, -0.0205]) tensor([-1.9882,  1.9873], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0306, -0.0396]) tensor([-1.9885,  1.9875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0188, -0.0194]) tensor([-1.9888,  1.9879], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0115, -0.0124]) tensor([-1.9889,  1.9881], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0228, -0.0190]) tensor([-1.9891,  1.9883], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0284, -0.0368]) tensor([-1.9893,  1.9884], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0174, -0.0180]) tensor([-1.9896,  1.9888], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0107, -0.0115]) tensor([-1.9898,  1.9890], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0211, -0.0176]) tensor([-1.9899,  1.9891], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0263, -0.0341]) tensor([-1.9901,  1.9893], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0162, -0.0167]) tensor([-1.9903,  1.9896], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0099, -0.0107]) tensor([-1.9905,  1.9898], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0196, -0.0164]) tensor([-1.9906,  1.9899], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0244, -0.0316]) tensor([-1.9908,  1.9901], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0150, -0.0154]) tensor([-1.9910,  1.9904], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(8.8728e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0092, -0.0099]) tensor([-1.9912,  1.9905], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0182, -0.0152]) tensor([-1.9913,  1.9906], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0226, -0.0294]) tensor([-1.9915,  1.9908], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0139, -0.0143]) tensor([-1.9917,  1.9911], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(7.6464e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0086, -0.0092]) tensor([-1.9918,  1.9912], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0168, -0.0141]) tensor([-1.9919,  1.9913], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0210, -0.0272]) tensor([-1.9921,  1.9914], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0129, -0.0132]) tensor([-1.9923,  1.9917], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(6.5912e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0080, -0.0085]) tensor([-1.9924,  1.9919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0156, -0.0131]) tensor([-1.9925,  1.9919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0195, -0.0253]) tensor([-1.9927,  1.9921], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(8.9752e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0120, -0.0123]) tensor([-1.9928,  1.9923], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(5.6832e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0074, -0.0079]) tensor([-1.9930,  1.9924], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(9.6140e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0144, -0.0121]) tensor([-1.9930,  1.9925], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0180, -0.0235]) tensor([-1.9932,  1.9926], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(7.7180e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0111, -0.0114]) tensor([-1.9934,  1.9929], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(4.9021e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0069, -0.0073]) tensor([-1.9935,  1.9930], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(8.2767e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0134, -0.0113]) tensor([-1.9935,  1.9931], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0167, -0.0218]) tensor([-1.9937,  1.9932], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(6.6376e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0103, -0.0105]) tensor([-1.9938,  1.9934], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(4.2299e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0064, -0.0068]) tensor([-1.9939,  1.9935], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(7.1265e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0124, -0.0105]) tensor([-1.9940,  1.9936], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0155, -0.0202]) tensor([-1.9941,  1.9937], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(5.7089e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0096, -0.0097]) tensor([-1.9943,  1.9939], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(3.6515e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0059, -0.0063]) tensor([-1.9944,  1.9940], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(6.1374e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0115, -0.0097]) tensor([-1.9944,  1.9940], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(9.5198e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0144, -0.0188]) tensor([-1.9946,  1.9941], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(4.9110e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0089, -0.0090]) tensor([-1.9947,  1.9943], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(3.1537e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0055, -0.0058]) tensor([-1.9948,  1.9944], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(5.2868e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0106, -0.0090]) tensor([-1.9949,  1.9945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(8.2032e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0133, -0.0174]) tensor([-1.9950,  1.9946], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(4.2253e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0082, -0.0083]) tensor([-1.9951,  1.9947], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(2.7253e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0051, -0.0054]) tensor([-1.9952,  1.9948], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(4.5555e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0098, -0.0084]) tensor([-1.9952,  1.9949], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(7.0706e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0124, -0.0162]) tensor([-1.9953,  1.9950], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(3.6362e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0076, -0.0077]) tensor([-1.9954,  1.9951], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(2.3567e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0048, -0.0050]) tensor([-1.9955,  1.9952], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(3.9265e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0091, -0.0078]) tensor([-1.9956,  1.9952], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(6.0960e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0115, -0.0150]) tensor([-1.9957,  1.9953], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(3.1301e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0071, -0.0071]) tensor([-1.9958,  1.9955], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(2.0394e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0044, -0.0046]) tensor([-1.9958,  1.9955], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(3.3855e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0084, -0.0072]) tensor([-1.9959,  1.9956], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(5.2574e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0106, -0.0139]) tensor([-1.9960,  1.9957], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(2.6953e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0066, -0.0066]) tensor([-1.9961,  1.9958], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(1.7664e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0041, -0.0043]) tensor([-1.9961,  1.9959], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(2.9204e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0078, -0.0067]) tensor([-1.9962,  1.9959], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(4.5359e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0098, -0.0129]) tensor([-1.9963,  1.9960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(2.3220e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0061, -0.0061]) tensor([-1.9964,  1.9961], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(1.5313e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0038, -0.0040]) tensor([-1.9964,  1.9962], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(2.5205e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0072, -0.0062]) tensor([-1.9965,  1.9962], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(3.9150e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0091, -0.0120]) tensor([-1.9965,  1.9963], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(2.0012e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0057, -0.0056]) tensor([-1.9966,  1.9964], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(1.3290e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0037]) tensor([-1.9967,  1.9964], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(2.1767e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0067, -0.0058]) tensor([-1.9967,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(3.3807e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0085, -0.0112]) tensor([-1.9968,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(1.7256e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0053, -0.0052]) tensor([-1.9969,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(1.1548e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0033, -0.0034]) tensor([-1.9969,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(1.8808e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0062, -0.0054]) tensor([-1.9970,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(2.9206e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0078, -0.0104]) tensor([-1.9970,  1.9968], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(1.4891e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0049, -0.0048]) tensor([-1.9971,  1.9969], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(1.0048e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0031, -0.0032]) tensor([-1.9971,  1.9969], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(1.6266e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0057, -0.0050]) tensor([-1.9972,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(2.5249e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0073, -0.0096]) tensor([-1.9972,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(1.2860e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0045, -0.0044]) tensor([-1.9973,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(8.7567e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0029]) tensor([-1.9974,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(1.4080e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0053, -0.0047]) tensor([-1.9974,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(2.1843e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0067, -0.0089]) tensor([-1.9974,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(1.1117e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0041]) tensor([-1.9975,  1.9973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 tensor(7.6455e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0027, -0.0027]) tensor([-1.9975,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(1.2200e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0049, -0.0043]) tensor([-1.9976,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(1.8910e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0062, -0.0083]) tensor([-1.9976,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(9.6200e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0038]) tensor([-1.9977,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(6.6884e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0025, -0.0025]) tensor([-1.9977,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(1.0583e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0045, -0.0040]) tensor([-1.9977,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(1.6388e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0058, -0.0077]) tensor([-1.9978,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(8.3365e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0035]) tensor([-1.9978,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(5.8640e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0023]) tensor([-1.9979,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(9.1946e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0037]) tensor([-1.9979,  1.9978], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(1.4216e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0054, -0.0072]) tensor([-1.9979,  1.9978], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(7.2348e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0032]) tensor([-1.9980,  1.9979], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(5.1542e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0022]) tensor([-1.9980,  1.9979], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(7.9999e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0035]) tensor([-1.9981,  1.9979], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(1.2347e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0050, -0.0067]) tensor([-1.9981,  1.9980], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(6.2897e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0031, -0.0029]) tensor([-1.9981,  1.9980], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(4.5427e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0020]) tensor([-1.9982,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(6.9730e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0032]) tensor([-1.9982,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(1.0737e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0046, -0.0062]) tensor([-1.9982,  1.9981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(5.4789e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0027]) tensor([-1.9983,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(4.0155e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0018]) tensor([-1.9983,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(6.0890e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0033, -0.0030]) tensor([-1.9983,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(9.3495e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0043, -0.0058]) tensor([-1.9984,  1.9982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(4.7829e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0027, -0.0025]) tensor([-1.9984,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(3.5615e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0017]) tensor([-1.9984,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(5.3300e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0030, -0.0028]) tensor([-1.9984,  1.9983], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(8.1566e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0040, -0.0054]) tensor([-1.9985,  1.9984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(4.1872e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0025, -0.0023]) tensor([-1.9985,  1.9984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(3.1701e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0016]) tensor([-1.9985,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(4.6770e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0026]) tensor([-1.9986,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(7.1285e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0037, -0.0050]) tensor([-1.9986,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(3.6763e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0021]) tensor([-1.9986,  1.9985], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(2.8329e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0015]) tensor([-1.9986,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(4.1159e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0024]) tensor([-1.9987,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(6.2431e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0046]) tensor([-1.9987,  1.9986], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(3.2383e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0019]) tensor([-1.9987,  1.9987], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(2.5422e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0014, -0.0014]) tensor([-1.9987,  1.9987], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(3.6332e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0023]) tensor([-1.9988,  1.9987], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(5.4804e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0031, -0.0043]) tensor([-1.9988,  1.9987], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(2.8633e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0018]) tensor([-1.9988,  1.9988], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(2.2914e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0013]) tensor([-1.9988,  1.9988], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(3.2183e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0021]) tensor([-1.9988,  1.9988], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(4.8229e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0040]) tensor([-1.9989,  1.9988], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(2.5420e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0016]) tensor([-1.9989,  1.9988], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(2.0752e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0012]) tensor([-1.9989,  1.9989], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(2.8615e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0020]) tensor([-1.9989,  1.9989], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(4.2574e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0027, -0.0037]) tensor([-1.9990,  1.9989], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(2.2672e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0015]) tensor([-1.9990,  1.9989], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(1.8890e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0012, -0.0011]) tensor([-1.9990,  1.9989], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(2.5555e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0019, -0.0018]) tensor([-1.9990,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(3.7695e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0025, -0.0035]) tensor([-1.9990,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(2.0320e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0014]) tensor([-1.9991,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(1.7282e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0011, -0.0010]) tensor([-1.9991,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(2.2920e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0017, -0.0017]) tensor([-1.9991,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(3.3492e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0032]) tensor([-1.9991,  1.9990], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(1.8309e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0012]) tensor([-1.9991,  1.9991], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(1.5894e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0009]) tensor([-1.9991,  1.9991], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(2.0657e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0016]) tensor([-1.9991,  1.9991], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(2.9872e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0030]) tensor([-1.9992,  1.9991], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(1.6592e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0014, -0.0011]) tensor([-1.9992,  1.9991], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(1.4697e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0008]) tensor([-1.9992,  1.9992], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(1.8713e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0015]) tensor([-1.9992,  1.9992], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(2.6753e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0028]) tensor([-1.9992,  1.9992], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(1.5123e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0010]) tensor([-1.9992,  1.9992], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "dataloader = DataLoader(MyDataset(datapoints[19][\"features\"], datapoints[19][\"label\"]), batch_size=50, shuffle=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    for (x, y) in dataloader:\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        print(y.size())\n",
    "        print(yhat.size())\n",
    "        loss = criterion(yhat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        print(i, loss, grads_to_vector(model.parameters()), parameters_to_vector(model.parameters()))\n",
    "        #optimizer.step()\n",
    "        new_model = parameters_to_vector(model.parameters()) - lr * grads_to_vector(model.parameters())\n",
    "        vector_to_parameters(parameters=model.parameters(), vec=new_model)\n",
    "        #if i % 50 ==0:\n",
    "            #lr *= 0.9\n",
    "            \n",
    "\n",
    "#parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb22da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9993,  1.9992], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52396ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, alpha, lamda, epochs, projection_list, projected_weights):\n",
    "        self.train_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=batchSize, shuffle=True)\n",
    "        #self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def train(self, model):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5)\n",
    "\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for i, (data, labels) in zip(range(1), self.train_loader):\n",
    "                data, labels = data, labels\n",
    "                optimizer.zero_grad() \n",
    "                output = model(data)  \n",
    "                loss = criterion(output, labels)\n",
    "                #loss += mu/2 * torch.norm(client_param.data - server_param.data)**2\n",
    "                loss.backward()\n",
    "                grads = grads_to_vector(model.parameters())\n",
    "                #optimizer.step()\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                weights = parameters_to_vector(model.parameters())\n",
    "                mat_vec_sum = torch.zeros_like(weights)\n",
    "                for j in G.neighbors(model.user_id):\n",
    "                    mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(torch.transpose(projection_list[model.user_id][j], 0, 1), \n",
    "                                                         projected_weights[j][model.user_id] - projected_weights[model.user_id][j]))\n",
    "                \n",
    "                model_update = parameters_to_vector(model.parameters()) - alpha * (grads + lamda * mat_vec_sum)\n",
    "                \n",
    "            vector_to_parameters(parameters=model.parameters(), vec=model_update)\n",
    "                \n",
    "\n",
    "            train_loss = train_loss/self.batchSize#len(self.train_loader.dataset) \n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "        total_loss = e_loss#sum(e_loss)/len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eeef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing projection matrices\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "#temp = MLP_Net()\n",
    "projection_list = []\n",
    "projected_weights = []\n",
    "\n",
    "def update_ProjWeight(projection_list, projected_weights, first_run=True):\n",
    "    #projected_weights = []\n",
    "    for i in range(no_users):\n",
    "        neighbors_mat = []\n",
    "        neighbors_weights = []\n",
    "        for j in range(no_users):\n",
    "            if j in G.neighbors(i):\n",
    "                with torch.no_grad():\n",
    "                    if first_run == True:\n",
    "                        row, column = parameters_to_vector(models[j].parameters()).size()[0], parameters_to_vector(models[i].parameters()).size()[0]\n",
    "                        mat = torch.zeros((row, column))\n",
    "                        mat.fill_diagonal_(1.0)\n",
    "                        neighbors_mat.append(mat)\n",
    "                        neighbors_weights.append(torch.matmul(mat, parameters_to_vector(models[j].parameters())))\n",
    "                    else:\n",
    "                        neighbors_weights.append(torch.matmul(projection_list[j][i], parameters_to_vector(models[j].parameters())))\n",
    "            else:\n",
    "                neighbors_mat.append(0)\n",
    "                neighbors_weights.append(0)\n",
    "        if first_run == True:\n",
    "            projection_list.append(neighbors_mat)\n",
    "        projected_weights.append(neighbors_weights)\n",
    "\n",
    "update_ProjWeight(projection_list, projected_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion): \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data, labels\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        #_, pred = torch.max(output, 1)\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3239, 0.5274])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6478, 1.0547], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "with torch.no_grad():    \n",
    "    params = parameters_to_vector(model.parameters())\n",
    "\n",
    "    print(params)\n",
    "\n",
    "params *= 2.\n",
    "\n",
    "vector_to_parameters(parameters=model.parameters(), vec=params)\n",
    "\n",
    "parameters_to_vector(model.parameters())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71472693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<01:50,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.66938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:00<02:04,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.63382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [00:00<01:35, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.58794\n",
      "Training_loss 7.54415\n",
      "Training_loss 7.51700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [00:00<01:37, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.48543\n",
      "Training_loss 7.44289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1000 [00:00<01:32, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.41001\n",
      "Training_loss 7.39108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [00:00<01:39, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.35850\n",
      "Training_loss 7.32449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1000 [00:01<01:34, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.28578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 14/1000 [00:01<01:31, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.27153\n",
      "Training_loss 7.25119\n",
      "Training_loss 7.22573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 16/1000 [00:01<01:37, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.19036\n",
      "Training_loss 7.15395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 18/1000 [00:01<01:35, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.10490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 20/1000 [00:01<01:30, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.07572\n",
      "Training_loss 7.04940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 22/1000 [00:02<01:46,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.03318\n",
      "Training_loss 7.00368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [00:02<02:12,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.97759\n",
      "Training_loss 6.95628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 25/1000 [00:02<02:27,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.93860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [00:03<02:45,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.92376\n",
      "Training_loss 6.88579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 29/1000 [00:03<02:14,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.86636\n",
      "Training_loss 6.82787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [00:03<02:17,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.79167\n",
      "Training_loss 6.76155\n",
      "Training_loss 6.74735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [00:04<01:40,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.71490\n",
      "Training_loss 6.69961\n",
      "Training_loss 6.67529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [00:04<01:48,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.63101\n",
      "Training_loss 6.61465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [00:04<01:46,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.59375\n",
      "Training_loss 6.57700\n",
      "Training_loss 6.55431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1000 [00:04<01:59,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.53114\n",
      "Training_loss 6.51237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [00:05<01:45,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.49960\n",
      "Training_loss 6.47463\n",
      "Training_loss 6.45845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 47/1000 [00:05<02:04,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.43327\n",
      "Training_loss 6.41988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [00:05<01:46,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.38324\n",
      "Training_loss 6.34597\n",
      "Training_loss 6.33319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 52/1000 [00:05<01:31, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.31291\n",
      "Training_loss 6.30274\n",
      "Training_loss 6.27738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1000 [00:06<01:22, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.25458\n",
      "Training_loss 6.23749\n",
      "Training_loss 6.20079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 58/1000 [00:06<01:21, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.18184\n",
      "Training_loss 6.15995\n",
      "Training_loss 6.14081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [00:06<01:19, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.11848\n",
      "Training_loss 6.09975\n",
      "Training_loss 6.08842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 64/1000 [00:06<01:17, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.05299\n",
      "Training_loss 6.03839\n",
      "Training_loss 6.01895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [00:07<01:12, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.99520\n",
      "Training_loss 5.96377\n",
      "Training_loss 5.92494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 70/1000 [00:07<01:23, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.90830\n",
      "Training_loss 5.88502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 72/1000 [00:07<01:19, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.86818\n",
      "Training_loss 5.86060\n",
      "Training_loss 5.84697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 76/1000 [00:08<01:26, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.81102\n",
      "Training_loss 5.79529\n",
      "Training_loss 5.77081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 78/1000 [00:08<01:22, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.75656\n",
      "Training_loss 5.72931\n",
      "Training_loss 5.72049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 82/1000 [00:08<01:18, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.69106\n",
      "Training_loss 5.67608\n",
      "Training_loss 5.65470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 84/1000 [00:08<01:14, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.63342\n",
      "Training_loss 5.60888\n",
      "Training_loss 5.58936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 88/1000 [00:08<01:12, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.55627\n",
      "Training_loss 5.54420\n",
      "Training_loss 5.52328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 90/1000 [00:09<01:13, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.50934\n",
      "Training_loss 5.48127\n",
      "Training_loss 5.44762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 94/1000 [00:09<01:09, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.42876\n",
      "Training_loss 5.39388\n",
      "Training_loss 5.36778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 96/1000 [00:09<01:15, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.35043\n",
      "Training_loss 5.32617\n",
      "Training_loss 5.30910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:09<01:14, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.27313\n",
      "Training_loss 5.25621\n",
      "Training_loss 5.24240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 102/1000 [00:10<01:13, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.22229\n",
      "Training_loss 5.19939\n",
      "Training_loss 5.17631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 106/1000 [00:10<01:09, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.14540\n",
      "Training_loss 5.11177\n",
      "Training_loss 5.10116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 108/1000 [00:10<01:11, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.08887\n",
      "Training_loss 5.06665\n",
      "Training_loss 5.05402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 112/1000 [00:10<01:14, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.04481\n",
      "Training_loss 5.01658\n",
      "Training_loss 5.00831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 114/1000 [00:11<01:10, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.99054\n",
      "Training_loss 4.97097\n",
      "Training_loss 4.96004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 118/1000 [00:11<01:09, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.94527\n",
      "Training_loss 4.93555\n",
      "Training_loss 4.91050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 120/1000 [00:11<01:10, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.88593\n",
      "Training_loss 4.87183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 122/1000 [00:11<01:22, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.86356\n",
      "Training_loss 4.83620\n",
      "Training_loss 4.81506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 124/1000 [00:11<01:19, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.80220\n",
      "Training_loss 4.78663\n",
      "Training_loss 4.77673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [00:12<01:31,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.75759\n",
      "Training_loss 4.74285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 130/1000 [00:12<01:38,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.73096\n",
      "Training_loss 4.71262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 132/1000 [00:12<01:38,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.69023\n",
      "Training_loss 4.67720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 134/1000 [00:13<01:39,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.66408\n",
      "Training_loss 4.63458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 136/1000 [00:13<02:10,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.61796\n",
      "Training_loss 4.59683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 138/1000 [00:13<01:54,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.57515\n",
      "Training_loss 4.55787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/1000 [00:14<01:44,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.53684\n",
      "Training_loss 4.52114\n",
      "Training_loss 4.50612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 144/1000 [00:14<01:25, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.48499\n",
      "Training_loss 4.46352\n",
      "Training_loss 4.43714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 146/1000 [00:14<01:18, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.41981\n",
      "Training_loss 4.40316\n",
      "Training_loss 4.37533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/1000 [00:14<01:14, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.35664\n",
      "Training_loss 4.33814\n",
      "Training_loss 4.32648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 152/1000 [00:15<01:13, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.30788\n",
      "Training_loss 4.28676\n",
      "Training_loss 4.27367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 156/1000 [00:15<01:12, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.25098\n",
      "Training_loss 4.24071\n",
      "Training_loss 4.22964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 158/1000 [00:15<01:10, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.21681\n",
      "Training_loss 4.20414\n",
      "Training_loss 4.18714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 162/1000 [00:15<01:06, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.16645\n",
      "Training_loss 4.15028\n",
      "Training_loss 4.13474\n",
      "Training_loss 4.12154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 166/1000 [00:16<01:05, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.10904\n",
      "Training_loss 4.09824\n",
      "Training_loss 4.08547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 168/1000 [00:16<01:07, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.07086\n",
      "Training_loss 4.05886\n",
      "Training_loss 4.04720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 170/1000 [00:16<01:16, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.03238\n",
      "Training_loss 4.01539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 172/1000 [00:16<01:24,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.99536\n",
      "Training_loss 3.97440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 175/1000 [00:17<01:30,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.95770\n",
      "Training_loss 3.93635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 177/1000 [00:17<01:27,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.92177\n",
      "Training_loss 3.91010\n",
      "Training_loss 3.88750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [00:17<01:15, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.86505\n",
      "Training_loss 3.85583\n",
      "Training_loss 3.84256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 183/1000 [00:17<01:15, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.82641\n",
      "Training_loss 3.82158\n",
      "Training_loss 3.80880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 187/1000 [00:18<01:11, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.79915\n",
      "Training_loss 3.78885\n",
      "Training_loss 3.77756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 189/1000 [00:18<01:09, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.76092\n",
      "Training_loss 3.74438\n",
      "Training_loss 3.72641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 193/1000 [00:18<01:05, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.71424\n",
      "Training_loss 3.69866\n",
      "Training_loss 3.68808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 195/1000 [00:18<01:04, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.67606\n",
      "Training_loss 3.65650\n",
      "Training_loss 3.65189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 199/1000 [00:19<01:02, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.63818\n",
      "Training_loss 3.63249\n",
      "Training_loss 3.62254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 201/1000 [00:19<01:06, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.61113\n",
      "Training_loss 3.59112\n",
      "Training_loss 3.57676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 205/1000 [00:19<01:12, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.56336\n",
      "Training_loss 3.55792\n",
      "Training_loss 3.54122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 207/1000 [00:19<01:18, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.53361\n",
      "Training_loss 3.51646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 209/1000 [00:20<01:18, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.50720\n",
      "Training_loss 3.49791\n",
      "Training_loss 3.48268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 213/1000 [00:20<01:13, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.47607\n",
      "Training_loss 3.47013\n",
      "Training_loss 3.45952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 215/1000 [00:20<01:17, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.44835\n",
      "Training_loss 3.43226\n",
      "Training_loss 3.41945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 218/1000 [00:21<01:20,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.39657\n",
      "Training_loss 3.38300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/1000 [00:21<01:22,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.36250\n",
      "Training_loss 3.34240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 222/1000 [00:21<01:32,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.33057\n",
      "Training_loss 3.31619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [00:21<01:31,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.29098\n",
      "Training_loss 3.27809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 227/1000 [00:22<01:22,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.26271\n",
      "Training_loss 3.25484\n",
      "Training_loss 3.22771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 229/1000 [00:22<01:13, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.21084\n",
      "Training_loss 3.19650\n",
      "Training_loss 3.18246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 231/1000 [00:22<01:13, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.17197\n",
      "Training_loss 3.15198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 234/1000 [00:22<01:21,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.14099\n",
      "Training_loss 3.13206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 236/1000 [00:23<01:22,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.12641\n",
      "Training_loss 3.11834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 238/1000 [00:23<01:24,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.10728\n",
      "Training_loss 3.09099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 240/1000 [00:23<01:28,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.07769\n",
      "Training_loss 3.06821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 242/1000 [00:23<01:27,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.05714\n",
      "Training_loss 3.04636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 244/1000 [00:23<01:32,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.03169\n",
      "Training_loss 3.02164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 246/1000 [00:24<01:21,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.01513\n",
      "Training_loss 3.01107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 248/1000 [00:24<01:22,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.00141\n",
      "Training_loss 2.99333\n",
      "Training_loss 2.98335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:24<01:07, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.97527\n",
      "Training_loss 2.95707\n",
      "Training_loss 2.94873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 254/1000 [00:24<01:03, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.93607\n",
      "Training_loss 2.92476\n",
      "Training_loss 2.90634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 258/1000 [00:25<01:01, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.89547\n",
      "Training_loss 2.88008\n",
      "Training_loss 2.87087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 260/1000 [00:25<01:00, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.85891\n",
      "Training_loss 2.85052\n",
      "Training_loss 2.83475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 264/1000 [00:25<01:04, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.83008\n",
      "Training_loss 2.82046\n",
      "Training_loss 2.81078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 266/1000 [00:25<01:08, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.80116\n",
      "Training_loss 2.79517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 268/1000 [00:26<01:07, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.78923\n",
      "Training_loss 2.77781\n",
      "Training_loss 2.76956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 272/1000 [00:26<01:03, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.75753\n",
      "Training_loss 2.75053\n",
      "Training_loss 2.73787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 274/1000 [00:26<01:02, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.72248\n",
      "Training_loss 2.71355\n",
      "Training_loss 2.69260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 278/1000 [00:26<01:01, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.68225\n",
      "Training_loss 2.67643\n",
      "Training_loss 2.66979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 280/1000 [00:27<01:03, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.66196\n",
      "Training_loss 2.65410\n",
      "Training_loss 2.64426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 282/1000 [00:27<01:20,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.63399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 284/1000 [00:27<01:33,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.62316\n",
      "Training_loss 2.61589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 286/1000 [00:28<01:33,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.60538\n",
      "Training_loss 2.59149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 288/1000 [00:28<01:30,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.58023\n",
      "Training_loss 2.57541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 291/1000 [00:28<01:15,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.56280\n",
      "Training_loss 2.54453\n",
      "Training_loss 2.53252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 293/1000 [00:28<01:31,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.52093\n",
      "Training_loss 2.51105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 296/1000 [00:29<01:18,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.50014\n",
      "Training_loss 2.49014\n",
      "Training_loss 2.48258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 298/1000 [00:29<01:21,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.47039\n",
      "Training_loss 2.45793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [00:29<01:22,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.44527\n",
      "Training_loss 2.43964\n",
      "Training_loss 2.42595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 303/1000 [00:30<01:22,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.42211\n",
      "Training_loss 2.41707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 306/1000 [00:30<01:09, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.40942\n",
      "Training_loss 2.40263\n",
      "Training_loss 2.39337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 308/1000 [00:30<01:03, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.38424\n",
      "Training_loss 2.37675\n",
      "Training_loss 2.36727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 310/1000 [00:30<01:05, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.36093\n",
      "Training_loss 2.35098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 314/1000 [00:31<01:07, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.33639\n",
      "Training_loss 2.32690\n",
      "Training_loss 2.32194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 318/1000 [00:31<00:58, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.31622\n",
      "Training_loss 2.30691\n",
      "Training_loss 2.30037\n",
      "Training_loss 2.29547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 320/1000 [00:31<00:59, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.28384\n",
      "Training_loss 2.27795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 322/1000 [00:31<01:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.27129\n",
      "Training_loss 2.26496\n",
      "Training_loss 2.25769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 326/1000 [00:32<00:59, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.25004\n",
      "Training_loss 2.23576\n",
      "Training_loss 2.22798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 328/1000 [00:32<01:01, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.22396\n",
      "Training_loss 2.21475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 330/1000 [00:32<01:05, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.20142\n",
      "Training_loss 2.19654\n",
      "Training_loss 2.18889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 334/1000 [00:32<00:59, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.18079\n",
      "Training_loss 2.16906\n",
      "Training_loss 2.16267\n",
      "Training_loss 2.15716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 337/1000 [00:33<01:14,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.15123\n",
      "Training_loss 2.14498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 339/1000 [00:33<01:08,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.14209\n",
      "Training_loss 2.13630\n",
      "Training_loss 2.13022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 343/1000 [00:33<00:59, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.12440\n",
      "Training_loss 2.11831\n",
      "Training_loss 2.11120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 345/1000 [00:34<00:57, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.09956\n",
      "Training_loss 2.09132\n",
      "Training_loss 2.08569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 349/1000 [00:34<00:59, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.07957\n",
      "Training_loss 2.07263\n",
      "Training_loss 2.06808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 351/1000 [00:34<01:02, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.05878\n",
      "Training_loss 2.05355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 353/1000 [00:34<01:03, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.04413\n",
      "Training_loss 2.03827\n",
      "Training_loss 2.03184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 357/1000 [00:35<01:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.02165\n",
      "Training_loss 2.01782\n",
      "Training_loss 2.00447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 359/1000 [00:35<00:58, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.99367\n",
      "Training_loss 1.98783\n",
      "Training_loss 1.97739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 363/1000 [00:35<00:57, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.96984\n",
      "Training_loss 1.95883\n",
      "Training_loss 1.95388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 365/1000 [00:35<00:55, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.94325\n",
      "Training_loss 1.93767\n",
      "Training_loss 1.93143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 369/1000 [00:36<00:56, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.92752\n",
      "Training_loss 1.92334\n",
      "Training_loss 1.91447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 371/1000 [00:36<00:54, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.90701\n",
      "Training_loss 1.89359\n",
      "Training_loss 1.88433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 375/1000 [00:36<00:53, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.87447\n",
      "Training_loss 1.86373\n",
      "Training_loss 1.85759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 377/1000 [00:36<00:52, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.84824\n",
      "Training_loss 1.84296\n",
      "Training_loss 1.83520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [00:37<00:52, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.82549\n",
      "Training_loss 1.81726\n",
      "Training_loss 1.80877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 383/1000 [00:37<00:52, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.79908\n",
      "Training_loss 1.79462\n",
      "Training_loss 1.78950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 387/1000 [00:37<00:50, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.78564\n",
      "Training_loss 1.77870\n",
      "Training_loss 1.77133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 389/1000 [00:37<00:49, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.76475\n",
      "Training_loss 1.75852\n",
      "Training_loss 1.75226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 393/1000 [00:38<00:49, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.74502\n",
      "Training_loss 1.73775\n",
      "Training_loss 1.73412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 395/1000 [00:38<00:52, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.72972\n",
      "Training_loss 1.72419\n",
      "Training_loss 1.72152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 399/1000 [00:38<00:49, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.71000\n",
      "Training_loss 1.70749\n",
      "Training_loss 1.70349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 401/1000 [00:38<00:48, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.69757\n",
      "Training_loss 1.68832\n",
      "Training_loss 1.68286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 405/1000 [00:39<00:51, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.67442\n",
      "Training_loss 1.66939\n",
      "Training_loss 1.65989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 407/1000 [00:39<00:52, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.65321\n",
      "Training_loss 1.64411\n",
      "Training_loss 1.63986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 411/1000 [00:39<00:51, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.63543\n",
      "Training_loss 1.63156\n",
      "Training_loss 1.62800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 413/1000 [00:39<00:51, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.61762\n",
      "Training_loss 1.61352\n",
      "Training_loss 1.61001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 417/1000 [00:40<00:49, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.60249\n",
      "Training_loss 1.59771\n",
      "Training_loss 1.59299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 419/1000 [00:40<00:48, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.58731\n",
      "Training_loss 1.58125\n",
      "Training_loss 1.57546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 423/1000 [00:40<00:47, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.56951\n",
      "Training_loss 1.56196\n",
      "Training_loss 1.55868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 425/1000 [00:40<00:45, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.55286\n",
      "Training_loss 1.54930\n",
      "Training_loss 1.54323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 429/1000 [00:41<00:46, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.53674\n",
      "Training_loss 1.52758\n",
      "Training_loss 1.52233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 431/1000 [00:41<00:50, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.51751\n",
      "Training_loss 1.51225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 433/1000 [00:41<00:50, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.50636\n",
      "Training_loss 1.50058\n",
      "Training_loss 1.49858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 437/1000 [00:41<00:47, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.49311\n",
      "Training_loss 1.48935\n",
      "Training_loss 1.48404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 439/1000 [00:42<00:46, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.48004\n",
      "Training_loss 1.47227\n",
      "Training_loss 1.46561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 443/1000 [00:42<00:48, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.45904\n",
      "Training_loss 1.45410\n",
      "Training_loss 1.44962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 445/1000 [00:42<00:47, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.44118\n",
      "Training_loss 1.43690\n",
      "Training_loss 1.43235\n",
      "Training_loss 1.42843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 449/1000 [00:42<00:45, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.42256\n",
      "Training_loss 1.41922\n",
      "Training_loss 1.41328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 453/1000 [00:43<00:45, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.40922\n",
      "Training_loss 1.40205\n",
      "Training_loss 1.39836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 455/1000 [00:43<00:46, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.39376\n",
      "Training_loss 1.38840\n",
      "Training_loss 1.38484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 459/1000 [00:43<00:47, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.37981\n",
      "Training_loss 1.37426\n",
      "Training_loss 1.37152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 461/1000 [00:44<00:47, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.36854\n",
      "Training_loss 1.36101\n",
      "Training_loss 1.35453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 465/1000 [00:44<00:49, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.34937\n",
      "Training_loss 1.34716\n",
      "Training_loss 1.34507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 467/1000 [00:44<00:52, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.33974\n",
      "Training_loss 1.33631\n",
      "Training_loss 1.33056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 471/1000 [00:45<00:53,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.32379\n",
      "Training_loss 1.31985\n",
      "Training_loss 1.31524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 473/1000 [00:45<00:50, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.31124\n",
      "Training_loss 1.30517\n",
      "Training_loss 1.30075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 475/1000 [00:45<00:51, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.29604\n",
      "Training_loss 1.28892\n",
      "Training_loss 1.28252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 479/1000 [00:45<00:50, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.27796\n",
      "Training_loss 1.27509\n",
      "Training_loss 1.26945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 483/1000 [00:46<00:47, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.26566\n",
      "Training_loss 1.26232\n",
      "Training_loss 1.25656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 485/1000 [00:46<00:45, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.25242\n",
      "Training_loss 1.24842\n",
      "Training_loss 1.24357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 489/1000 [00:46<00:45, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.24002\n",
      "Training_loss 1.23610\n",
      "Training_loss 1.23447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 491/1000 [00:46<00:43, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.23146\n",
      "Training_loss 1.22802\n",
      "Training_loss 1.22330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 495/1000 [00:47<00:46, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.21955\n",
      "Training_loss 1.21463\n",
      "Training_loss 1.20922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 497/1000 [00:47<00:45, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.20437\n",
      "Training_loss 1.19977\n",
      "Training_loss 1.19682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [00:47<00:44, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.18984\n",
      "Training_loss 1.18616\n",
      "Training_loss 1.18161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 503/1000 [00:47<00:43, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.17851\n",
      "Training_loss 1.17325\n",
      "Training_loss 1.17109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 507/1000 [00:48<00:41, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.16660\n",
      "Training_loss 1.16226\n",
      "Training_loss 1.15840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 509/1000 [00:48<00:40, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.15318\n",
      "Training_loss 1.14794\n",
      "Training_loss 1.14250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 513/1000 [00:48<00:39, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.13880\n",
      "Training_loss 1.13547\n",
      "Training_loss 1.13064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 515/1000 [00:48<00:39, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.12562\n",
      "Training_loss 1.11964\n",
      "Training_loss 1.11321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 517/1000 [00:49<00:40, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.10990\n",
      "Training_loss 1.10607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 519/1000 [00:49<00:43, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.10109\n",
      "Training_loss 1.09592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 523/1000 [00:49<00:43, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.09293\n",
      "Training_loss 1.08965\n",
      "Training_loss 1.08580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 525/1000 [00:49<00:44, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.08212\n",
      "Training_loss 1.07953\n",
      "Training_loss 1.07609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 529/1000 [00:50<00:40, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.07315\n",
      "Training_loss 1.06746\n",
      "Training_loss 1.06450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 531/1000 [00:50<00:40, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.06201\n",
      "Training_loss 1.05741\n",
      "Training_loss 1.05449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 535/1000 [00:50<00:41, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.05054\n",
      "Training_loss 1.04399\n",
      "Training_loss 1.03770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 537/1000 [00:50<00:40, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.03493\n",
      "Training_loss 1.03091\n",
      "Training_loss 1.02796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 541/1000 [00:51<00:39, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.02476\n",
      "Training_loss 1.02080\n",
      "Training_loss 1.01681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 543/1000 [00:51<00:39, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.01381\n",
      "Training_loss 1.00990\n",
      "Training_loss 1.00561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 547/1000 [00:51<00:39, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.00179\n",
      "Training_loss 0.99941\n",
      "Training_loss 0.99435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 549/1000 [00:51<00:40, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.98998\n",
      "Training_loss 0.98712\n",
      "Training_loss 0.98304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 553/1000 [00:52<00:38, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.98012\n",
      "Training_loss 0.97682\n",
      "Training_loss 0.97126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 555/1000 [00:52<00:38, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.96799\n",
      "Training_loss 0.96526\n",
      "Training_loss 0.96067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 559/1000 [00:52<00:37, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.95949\n",
      "Training_loss 0.95625\n",
      "Training_loss 0.95238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 561/1000 [00:52<00:36, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.94661\n",
      "Training_loss 0.94285\n",
      "Training_loss 0.93825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 565/1000 [00:53<00:35, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.93653\n",
      "Training_loss 0.93253\n",
      "Training_loss 0.92441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 567/1000 [00:53<00:35, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.91914\n",
      "Training_loss 0.91615\n",
      "Training_loss 0.91050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 571/1000 [00:53<00:34, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.90440\n",
      "Training_loss 0.90006\n",
      "Training_loss 0.89594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 573/1000 [00:53<00:34, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.89319\n",
      "Training_loss 0.88786\n",
      "Training_loss 0.88610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 577/1000 [00:54<00:34, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.88385\n",
      "Training_loss 0.88233\n",
      "Training_loss 0.87946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 579/1000 [00:54<00:34, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.87679\n",
      "Training_loss 0.87335\n",
      "Training_loss 0.86917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 583/1000 [00:54<00:36, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.86698\n",
      "Training_loss 0.86534\n",
      "Training_loss 0.86286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 585/1000 [00:54<00:35, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.85543\n",
      "Training_loss 0.85170\n",
      "Training_loss 0.84993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 589/1000 [00:55<00:35, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.84900\n",
      "Training_loss 0.84571\n",
      "Training_loss 0.84222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 591/1000 [00:55<00:34, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.84075\n",
      "Training_loss 0.83514\n",
      "Training_loss 0.83096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 595/1000 [00:55<00:33, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.82806\n",
      "Training_loss 0.82591\n",
      "Training_loss 0.82274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 597/1000 [00:55<00:32, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.81864\n",
      "Training_loss 0.81523\n",
      "Training_loss 0.80931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [00:56<00:33, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.80660\n",
      "Training_loss 0.80314\n",
      "Training_loss 0.80020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 603/1000 [00:56<00:32, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.79804\n",
      "Training_loss 0.79656\n",
      "Training_loss 0.79475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 607/1000 [00:56<00:32, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.79234\n",
      "Training_loss 0.78979\n",
      "Training_loss 0.78837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 609/1000 [00:56<00:31, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.78568\n",
      "Training_loss 0.78263\n",
      "Training_loss 0.77988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 613/1000 [00:57<00:31, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.77665\n",
      "Training_loss 0.77554\n",
      "Training_loss 0.77174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 615/1000 [00:57<00:31, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.76977\n",
      "Training_loss 0.76713\n",
      "Training_loss 0.76439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 619/1000 [00:57<00:32, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.76016\n",
      "Training_loss 0.75901\n",
      "Training_loss 0.75728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 621/1000 [00:57<00:31, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.75515\n",
      "Training_loss 0.75230\n",
      "Training_loss 0.74950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 625/1000 [00:58<00:33, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.74711\n",
      "Training_loss 0.74248\n",
      "Training_loss 0.74110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 627/1000 [00:58<00:32, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.73794\n",
      "Training_loss 0.73421\n",
      "Training_loss 0.73012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 631/1000 [00:58<00:31, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.72849\n",
      "Training_loss 0.72609\n",
      "Training_loss 0.72299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 633/1000 [00:58<00:31, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.71784\n",
      "Training_loss 0.71598\n",
      "Training_loss 0.71464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 637/1000 [00:59<00:30, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.71349\n",
      "Training_loss 0.71024\n",
      "Training_loss 0.70745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 639/1000 [00:59<00:30, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.70552\n",
      "Training_loss 0.70317\n",
      "Training_loss 0.70080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 643/1000 [00:59<00:31, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.69935\n",
      "Training_loss 0.69593\n",
      "Training_loss 0.69207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 645/1000 [01:00<00:31, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.68932\n",
      "Training_loss 0.68654\n",
      "Training_loss 0.68367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 647/1000 [01:00<00:31, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.68176\n",
      "Training_loss 0.67851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [01:00<00:32, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.67495\n",
      "Training_loss 0.67270\n",
      "Training_loss 0.67003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 653/1000 [01:00<00:31, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.66803\n",
      "Training_loss 0.66567\n",
      "Training_loss 0.66220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 657/1000 [01:01<00:31, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.66047\n",
      "Training_loss 0.65804\n",
      "Training_loss 0.65485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 659/1000 [01:01<00:31, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65151\n",
      "Training_loss 0.64975\n",
      "Training_loss 0.64695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 663/1000 [01:01<00:29, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.64242\n",
      "Training_loss 0.63925\n",
      "Training_loss 0.63622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 665/1000 [01:01<00:28, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.63416\n",
      "Training_loss 0.63238\n",
      "Training_loss 0.63030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 669/1000 [01:02<00:27, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.62935\n",
      "Training_loss 0.62545\n",
      "Training_loss 0.62377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 671/1000 [01:02<00:26, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.62214\n",
      "Training_loss 0.61986\n",
      "Training_loss 0.61566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 675/1000 [01:02<00:28, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.61488\n",
      "Training_loss 0.61182\n",
      "Training_loss 0.60856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 677/1000 [01:02<00:30, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.60711\n",
      "Training_loss 0.60406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 679/1000 [01:03<00:33,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.60166\n",
      "Training_loss 0.60027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 681/1000 [01:03<00:37,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59871\n",
      "Training_loss 0.59779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 683/1000 [01:03<00:41,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59583\n",
      "Training_loss 0.59292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 685/1000 [01:03<00:40,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59006\n",
      "Training_loss 0.58804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 688/1000 [01:04<00:36,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.58654\n",
      "Training_loss 0.58361\n",
      "Training_loss 0.58133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 690/1000 [01:04<00:39,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.57959\n",
      "Training_loss 0.57751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 692/1000 [01:04<00:33,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.57590\n",
      "Training_loss 0.57331\n",
      "Training_loss 0.57020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 695/1000 [01:05<00:31,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.56860\n",
      "Training_loss 0.56537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 698/1000 [01:05<00:28, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.56230\n",
      "Training_loss 0.55872\n",
      "Training_loss 0.55489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 700/1000 [01:05<00:28, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.55254\n",
      "Training_loss 0.55143\n",
      "Training_loss 0.54974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 704/1000 [01:05<00:27, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54828\n",
      "Training_loss 0.54553\n",
      "Training_loss 0.54320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 706/1000 [01:06<00:26, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54124\n",
      "Training_loss 0.53948\n",
      "Training_loss 0.53751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 710/1000 [01:06<00:26, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.53515\n",
      "Training_loss 0.53328\n",
      "Training_loss 0.53086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 712/1000 [01:06<00:25, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52909\n",
      "Training_loss 0.52710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 714/1000 [01:06<00:28, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52619\n",
      "Training_loss 0.52409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 716/1000 [01:07<00:28,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52216\n",
      "Training_loss 0.52035\n",
      "Training_loss 0.51831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 718/1000 [01:07<00:27, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.51595\n",
      "Training_loss 0.51408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 722/1000 [01:07<00:27, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.51281\n",
      "Training_loss 0.51093\n",
      "Training_loss 0.50834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 724/1000 [01:07<00:25, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50719\n",
      "Training_loss 0.50455\n",
      "Training_loss 0.50337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 728/1000 [01:08<00:25, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50135\n",
      "Training_loss 0.49967\n",
      "Training_loss 0.49873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 730/1000 [01:08<00:24, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49605\n",
      "Training_loss 0.49504\n",
      "Training_loss 0.49253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 734/1000 [01:08<00:22, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48967\n",
      "Training_loss 0.48802\n",
      "Training_loss 0.48707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 736/1000 [01:08<00:23, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48527\n",
      "Training_loss 0.48400\n",
      "Training_loss 0.48206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 740/1000 [01:09<00:22, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47961\n",
      "Training_loss 0.47879\n",
      "Training_loss 0.47701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 742/1000 [01:09<00:21, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47495\n",
      "Training_loss 0.47380\n",
      "Training_loss 0.47238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 746/1000 [01:09<00:21, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47087\n",
      "Training_loss 0.47019\n",
      "Training_loss 0.46905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 748/1000 [01:09<00:21, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46850\n",
      "Training_loss 0.46672\n",
      "Training_loss 0.46496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [01:10<00:20, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46362\n",
      "Training_loss 0.46221\n",
      "Training_loss 0.46088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 754/1000 [01:10<00:20, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45891\n",
      "Training_loss 0.45628\n",
      "Training_loss 0.45448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 758/1000 [01:10<00:19, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45265\n",
      "Training_loss 0.45098\n",
      "Training_loss 0.44972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 760/1000 [01:10<00:19, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.44666\n",
      "Training_loss 0.44504\n",
      "Training_loss 0.44361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 764/1000 [01:11<00:21, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.44227\n",
      "Training_loss 0.44123\n",
      "Training_loss 0.43931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 766/1000 [01:11<00:20, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43779\n",
      "Training_loss 0.43600\n",
      "Training_loss 0.43383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 770/1000 [01:11<00:20, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43234\n",
      "Training_loss 0.42929\n",
      "Training_loss 0.42712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 772/1000 [01:11<00:20, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42586\n",
      "Training_loss 0.42427\n",
      "Training_loss 0.42257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 776/1000 [01:12<00:19, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42188\n",
      "Training_loss 0.42095\n",
      "Training_loss 0.41907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 778/1000 [01:12<00:20, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41727\n",
      "Training_loss 0.41615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 780/1000 [01:12<00:22,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41486\n",
      "Training_loss 0.41313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 782/1000 [01:12<00:23,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41215\n",
      "Training_loss 0.41051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 784/1000 [01:13<00:24,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40899\n",
      "Training_loss 0.40725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 786/1000 [01:13<00:24,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40463\n",
      "Training_loss 0.40352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 789/1000 [01:13<00:21,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40095\n",
      "Training_loss 0.39941\n",
      "Training_loss 0.39805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 791/1000 [01:13<00:20, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39630\n",
      "Training_loss 0.39523\n",
      "Training_loss 0.39404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 795/1000 [01:14<00:18, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39185\n",
      "Training_loss 0.38972\n",
      "Training_loss 0.38758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 797/1000 [01:14<00:18, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38623\n",
      "Training_loss 0.38497\n",
      "Training_loss 0.38380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [01:14<00:16, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38248\n",
      "Training_loss 0.38159\n",
      "Training_loss 0.38083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 803/1000 [01:14<00:16, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37949\n",
      "Training_loss 0.37826\n",
      "Training_loss 0.37746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 807/1000 [01:15<00:17, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37660\n",
      "Training_loss 0.37595\n",
      "Training_loss 0.37483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 809/1000 [01:15<00:16, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37339\n",
      "Training_loss 0.37170\n",
      "Training_loss 0.37085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 813/1000 [01:15<00:16, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37029\n",
      "Training_loss 0.36900\n",
      "Training_loss 0.36765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 815/1000 [01:16<00:16, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36671\n",
      "Training_loss 0.36531\n",
      "Training_loss 0.36383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 819/1000 [01:16<00:16, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36329\n",
      "Training_loss 0.36146\n",
      "Training_loss 0.36039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 821/1000 [01:16<00:16, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35911\n",
      "Training_loss 0.35755\n",
      "Training_loss 0.35675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 823/1000 [01:16<00:16, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35534\n",
      "Training_loss 0.35363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 825/1000 [01:16<00:16, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35182\n",
      "Training_loss 0.35073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 827/1000 [01:17<00:16, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34962\n",
      "Training_loss 0.34843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 831/1000 [01:17<00:16, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34603\n",
      "Training_loss 0.34438\n",
      "Training_loss 0.34271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 833/1000 [01:17<00:15, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34154\n",
      "Training_loss 0.34101\n",
      "Training_loss 0.33853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 837/1000 [01:18<00:14, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33783\n",
      "Training_loss 0.33700\n",
      "Training_loss 0.33581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 839/1000 [01:18<00:13, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33507\n",
      "Training_loss 0.33402\n",
      "Training_loss 0.33309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 843/1000 [01:18<00:13, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33182\n",
      "Training_loss 0.33008\n",
      "Training_loss 0.32894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 845/1000 [01:18<00:13, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32750\n",
      "Training_loss 0.32659\n",
      "Training_loss 0.32577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 849/1000 [01:19<00:12, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32494\n",
      "Training_loss 0.32406\n",
      "Training_loss 0.32216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 851/1000 [01:19<00:13, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32157\n",
      "Training_loss 0.32022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 853/1000 [01:19<00:13, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31940\n",
      "Training_loss 0.31854\n",
      "Training_loss 0.31751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 857/1000 [01:19<00:12, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31692\n",
      "Training_loss 0.31560\n",
      "Training_loss 0.31451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 859/1000 [01:20<00:12, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31321\n",
      "Training_loss 0.31229\n",
      "Training_loss 0.31169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 863/1000 [01:20<00:12, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31101\n",
      "Training_loss 0.30999\n",
      "Training_loss 0.30842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 865/1000 [01:20<00:11, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30760\n",
      "Training_loss 0.30618\n",
      "Training_loss 0.30509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 869/1000 [01:20<00:11, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30443\n",
      "Training_loss 0.30357\n",
      "Training_loss 0.30286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 871/1000 [01:21<00:10, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30153\n",
      "Training_loss 0.29932\n",
      "Training_loss 0.29829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 875/1000 [01:21<00:10, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29752\n",
      "Training_loss 0.29691\n",
      "Training_loss 0.29542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 877/1000 [01:21<00:10, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29428\n",
      "Training_loss 0.29342\n",
      "Training_loss 0.29267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 881/1000 [01:21<00:10, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29206\n",
      "Training_loss 0.29114\n",
      "Training_loss 0.28930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 883/1000 [01:22<00:10, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28818\n",
      "Training_loss 0.28712\n",
      "Training_loss 0.28611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 887/1000 [01:22<00:09, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28569\n",
      "Training_loss 0.28465\n",
      "Training_loss 0.28347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 889/1000 [01:22<00:09, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28211\n",
      "Training_loss 0.28094\n",
      "Training_loss 0.27967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 893/1000 [01:22<00:09, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27862\n",
      "Training_loss 0.27796\n",
      "Training_loss 0.27691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 895/1000 [01:23<00:09, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27587\n",
      "Training_loss 0.27495\n",
      "Training_loss 0.27423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 899/1000 [01:23<00:09, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27347\n",
      "Training_loss 0.27235\n",
      "Training_loss 0.27186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 901/1000 [01:23<00:09, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27047\n",
      "Training_loss 0.26963\n",
      "Training_loss 0.26870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 905/1000 [01:24<00:08, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26751\n",
      "Training_loss 0.26624\n",
      "Training_loss 0.26505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 907/1000 [01:24<00:07, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26432\n",
      "Training_loss 0.26359\n",
      "Training_loss 0.26270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 911/1000 [01:24<00:07, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26210\n",
      "Training_loss 0.26117\n",
      "Training_loss 0.26014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 913/1000 [01:24<00:07, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25912\n",
      "Training_loss 0.25787\n",
      "Training_loss 0.25696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 917/1000 [01:25<00:07, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25556\n",
      "Training_loss 0.25387\n",
      "Training_loss 0.25301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 919/1000 [01:25<00:07, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25236\n",
      "Training_loss 0.25165\n",
      "Training_loss 0.25050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 923/1000 [01:25<00:06, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24979\n",
      "Training_loss 0.24887\n",
      "Training_loss 0.24805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 925/1000 [01:25<00:06, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24646\n",
      "Training_loss 0.24551\n",
      "Training_loss 0.24495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 928/1000 [01:26<00:08,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24430\n",
      "Training_loss 0.24349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 930/1000 [01:26<00:08,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24252\n",
      "Training_loss 0.24164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 933/1000 [01:26<00:07,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24103\n",
      "Training_loss 0.24046\n",
      "Training_loss 0.24013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 934/1000 [01:26<00:07,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 936/1000 [01:27<00:10,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23788\n",
      "Training_loss 0.23652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 938/1000 [01:27<00:08,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23568\n",
      "Training_loss 0.23497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 940/1000 [01:27<00:07,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23400\n",
      "Training_loss 0.23311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 941/1000 [01:27<00:07,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.23220\n",
      "Training_loss 0.23071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 944/1000 [01:28<00:06,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22917\n",
      "Training_loss 0.22873\n",
      "Training_loss 0.22774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 948/1000 [01:28<00:05, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22688\n",
      "Training_loss 0.22585\n",
      "Training_loss 0.22472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 950/1000 [01:28<00:04, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22414\n",
      "Training_loss 0.22320\n",
      "Training_loss 0.22286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 954/1000 [01:29<00:03, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22180\n",
      "Training_loss 0.22109\n",
      "Training_loss 0.22071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 956/1000 [01:29<00:03, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22012\n",
      "Training_loss 0.21969\n",
      "Training_loss 0.21921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 960/1000 [01:29<00:03, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.21835\n",
      "Training_loss 0.21737\n",
      "Training_loss 0.21687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 962/1000 [01:29<00:03, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.21605\n",
      "Training_loss 0.21589\n",
      "Training_loss 0.21530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 966/1000 [01:30<00:02, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.21471\n",
      "Training_loss 0.21409\n",
      "Training_loss 0.21343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 968/1000 [01:30<00:02, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.21270\n",
      "Training_loss 0.21186\n",
      "Training_loss 0.21131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 972/1000 [01:30<00:02, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.21056\n",
      "Training_loss 0.20985\n",
      "Training_loss 0.20922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 974/1000 [01:30<00:02, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.20797\n",
      "Training_loss 0.20686\n",
      "Training_loss 0.20579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 978/1000 [01:31<00:01, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.20505\n",
      "Training_loss 0.20347\n",
      "Training_loss 0.20289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 980/1000 [01:31<00:01, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.20262\n",
      "Training_loss 0.20146\n",
      "Training_loss 0.20064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 984/1000 [01:31<00:01, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.20009\n",
      "Training_loss 0.19968\n",
      "Training_loss 0.19896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 986/1000 [01:31<00:01, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.19808\n",
      "Training_loss 0.19756\n",
      "Training_loss 0.19640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 990/1000 [01:32<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.19522\n",
      "Training_loss 0.19468\n",
      "Training_loss 0.19400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 992/1000 [01:32<00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.19310\n",
      "Training_loss 0.19243\n",
      "Training_loss 0.19166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 996/1000 [01:32<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.19093\n",
      "Training_loss 0.19022\n",
      "Training_loss 0.18882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 998/1000 [01:33<00:00, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.18774\n",
      "Training_loss 0.18706\n",
      "Training_loss 0.18640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:33<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.18583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#global_model = CNN_Net().cuda()\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "dummy_models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "\n",
    "#model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "for curr_round in tqdm(range(1, it+1)):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        dummy_models[i].load_state_dict(models[i].state_dict())\n",
    "        local_update = ClientUpdate(dataset=datapoints[i], batchSize=batch_size, alpha=alpha, lamda=lamda, epochs=1, projection_list=projection_list, projected_weights=projected_weights)\n",
    "        weights, loss = local_update.train(dummy_models[i])\n",
    "        w.append(weights)\n",
    "        local_loss.append(loss)\n",
    "        models[i].load_state_dict(w[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Update prjection matrix\n",
    "    \n",
    "    #print(projection_list[0], projected_weights[0])\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        weights = parameters_to_vector(models[i].parameters())\n",
    "        for j in G.neighbors(i):\n",
    "            weights = parameters_to_vector(model.parameters())\n",
    "            mat_vec_sum = torch.zeros_like(weights)\n",
    "            for k in G.neighbors(i):\n",
    "                 mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(projected_weights[k][i] - projected_weights[i][k],\n",
    "                                                                  torch.transpose(weights, -1, 0)))\n",
    "            projection_list[i][j] = torch.add(projection_list[i][j], -1 * eta * lamda * mat_vec_sum)\n",
    "                                         \n",
    "    projected_weights = []                                          \n",
    "    update_ProjWeight(projection_list, projected_weights, first_run=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "\n",
    "    local_test_acc = []\n",
    "    local_test_loss = []\n",
    "    for k in range(no_users):\n",
    "      \n",
    "      g_loss = testing(models[i], datapoints[i], 50, criterion)\n",
    "      local_test_loss.append(g_loss)\n",
    "    \n",
    "        \n",
    "\n",
    "    g_loss = sum(local_test_loss) / len(local_test_loss)\n",
    "    #g_accuracy = sum(local_test_acc) / len(local_test_acc)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_loss.append(g_loss)\n",
    "    #test_accuracy.append(g_accuracy)\n",
    "    print(\"Training_loss %2.5f\"% (test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff0ff71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-679ff9d7dd9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "plot.plot(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
