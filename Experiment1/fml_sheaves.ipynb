{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d5d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7617ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph implementation\n",
    "def generate_graph(cluster_sizes=[100,100], pin=0.5, pout=0.01, seed=0):\n",
    "    \"\"\"Generate a random connected graph\"\"\"\n",
    "    probs = np.array([[pin, pout],[pout, pin]])\n",
    "    while True:\n",
    "        g = nx.stochastic_block_model(cluster_sizes, probs)\n",
    "        if nx.algorithms.components.is_connected(g):\n",
    "            return g\n",
    "\n",
    "\n",
    "cluster_sizes = [10, 10]\n",
    "pin = 0.5\n",
    "pout = 0.1\n",
    "seed = 0\n",
    "alpha = 1e-2\n",
    "lamda = 1e-3\n",
    "eta = 1e-2\n",
    "d0 = 8\n",
    "no_users = sum(cluster_sizes)\n",
    "batch_size = 20\n",
    "epochs = 1\n",
    "it = 200\n",
    "G = generate_graph(cluster_sizes, pin, pout, seed)\n",
    "\n",
    "#nx.draw(G, with_labels=True, node_size=100, alpha=1, linewidths=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "809e7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.125      0.14285714 0.         0.125\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.         0.125      0.14285714 0.         0.125\n",
      "  0.         0.16666667 0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.         0.         0.         0.125\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.125      0.\n",
      "  0.         0.125     ]\n",
      " [0.14285714 0.14285714 0.         0.         0.         0.125\n",
      "  0.14285714 0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.125      0.125      0.125      0.\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125     ]\n",
      " [0.         0.         0.125      0.14285714 0.         0.\n",
      "  0.         0.         0.14285714 0.         0.         0.16666667\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.16666667]\n",
      " [0.14285714 0.14285714 0.         0.14285714 0.         0.125\n",
      "  0.14285714 0.         0.         0.14285714 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.14285714 0.\n",
      "  0.         0.14285714 0.14285714 0.         0.14285714 0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714 0.         0.14285714 0.         0.14285714\n",
      "  0.14285714 0.         0.14285714 0.         0.14285714 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.         0.         0.         0.14285714 0.\n",
      "  0.         0.16666667 0.         0.16666667 0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.         0.         0.         0.16666667 0.16666667 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.14285714 0.         0.         0.14285714 0.14285714 0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.16666667\n",
      "  0.         0.16666667 0.14285714 0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.         0.16666667 0.14285714 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.14285714 0.         0.\n",
      "  0.         0.14285714 0.         0.         0.         0.14285714\n",
      "  0.         0.         0.14285714 0.14285714 0.         0.14285714\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.125      0.         0.         0.125\n",
      "  0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "[[0.29761905 0.         0.125      0.14285714 0.         0.125\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.29761905 0.125      0.14285714 0.         0.125\n",
      "  0.         0.16666667 0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.125      0.         0.         0.125\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.125      0.         0.125      0.\n",
      "  0.         0.125     ]\n",
      " [0.14285714 0.14285714 0.         0.16071429 0.         0.125\n",
      "  0.14285714 0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.73214286 0.125\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.125      0.125      0.125      0.125\n",
      "  0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125     ]\n",
      " [0.         0.         0.125      0.14285714 0.         0.\n",
      "  0.25595238 0.         0.14285714 0.         0.         0.16666667\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.         0.16666667 0.         0.         0.         0.\n",
      "  0.         0.23809524 0.         0.14285714 0.14285714 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.16666667]\n",
      " [0.14285714 0.14285714 0.         0.14285714 0.         0.125\n",
      "  0.14285714 0.         0.16071429 0.14285714 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.14285714 0.\n",
      "  0.         0.14285714 0.14285714 0.14285714 0.14285714 0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714 0.         0.14285714 0.14285714 0.14285714\n",
      "  0.14285714 0.         0.14285714 0.         0.14285714 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.         0.         0.         0.14285714 0.21428571\n",
      "  0.         0.16666667 0.         0.16666667 0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.71428571 0.         0.14285714 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.         0.5        0.         0.16666667 0.16666667 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.14285714 0.         0.16071429 0.14285714 0.14285714 0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.16666667\n",
      "  0.         0.16666667 0.14285714 0.23809524 0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.14285714 0.\n",
      "  0.         0.16666667 0.14285714 0.         0.2797619  0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.85714286\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.14285714 0.         0.\n",
      "  0.         0.14285714 0.         0.         0.         0.14285714\n",
      "  0.         0.         0.14285714 0.14285714 0.         0.14285714\n",
      "  0.14285714 0.        ]\n",
      " [0.16666667 0.         0.125      0.         0.         0.125\n",
      "  0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "# Metropolis weights \n",
    "number_nodes = G.number_of_nodes()\n",
    "weights = np.zeros([number_nodes, number_nodes])\n",
    "for edge in G.edges():\n",
    "  i, j = edge[0], edge[1]\n",
    "  weights[i - 1][j - 1] = 1 / (1 + np.max([G.degree(i), G.degree(j)]))\n",
    "  weights[j - 1][i - 1] = weights[i - 1][j - 1]\n",
    "\n",
    "print(weights)\n",
    "\n",
    "weights = weights + np.diag(1 - np.sum(weights, axis=0))\n",
    "\n",
    "metropolis_weights = weights\n",
    "print(metropolis_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "654ab72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    transforms_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "    mnist_data_train = datasets.MNIST('./data/mnist', train=True, download=True, transform=transforms_mnist)\n",
    "    mnist_data_test = datasets.MNIST('./data/mnist', train=False, download=True, transform=transforms_mnist)\n",
    "\n",
    "    return mnist_data_train, mnist_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26f67564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees(A):\n",
    "    \"\"\"Return the degrees of each node of a graph from its adjacency matrix\"\"\"\n",
    "    return np.sum(A, axis=0).reshape(A.shape[0], 1)\n",
    "\n",
    "def node_degree(n, G):\n",
    "    cnt = 0\n",
    "    for i in G.neighbors(n):\n",
    "        cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def get_neighbors(n, G):\n",
    "    neighbors_list = []\n",
    "    for i in G.neighbors(n):\n",
    "        neighbors_list.append(int(i))\n",
    "    return neighbors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbc31eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = {}\n",
    "count = 0\n",
    "W1 = np.array([2.0, 2.0, 0.0, 5.0, -2.0, -3.0, 5.0, 2.0])\n",
    "W2 = np.array([2.0, 2.0, 0.0, 5.0, 2.0, 3.0, -5.0, -2.0])\n",
    "W = [W1, W2]\n",
    "m = 200\n",
    "n = 8\n",
    "noise_sd = 0.001\n",
    "for i, cluster_size in enumerate(cluster_sizes):\n",
    "    for j in range(cluster_size):\n",
    "        features = np.random.normal(loc=0.0, scale=1.0, size=(m, n))\n",
    "        label = np.dot(features, W[i]) + np.random.normal(0,noise_sd)\n",
    "        datapoints[count] = {\n",
    "                'features': features,\n",
    "                'degree': node_degree(count, G),\n",
    "                'label': label,\n",
    "                'neighbors': get_neighbors(count, G),\n",
    "                'exact_weights': torch.from_numpy(W[i])\n",
    "            }\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c2530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d84bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self, user_id):\n",
    "        super(MLP_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 1, bias=False)\n",
    "        #self.fc2 = nn.Linear(4, 1, bias=False)\n",
    "        #self.fc3 = nn.Linear(200, 10)\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        output = self.fc1(x)\n",
    "        #output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f93f4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "\n",
    "def grads_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:\n",
    "    r\"\"\"Convert parameters to one vector\n",
    "\n",
    "    Args:\n",
    "        parameters (Iterable[Tensor]): an iterator of Tensors that are the\n",
    "            parameters of a model.\n",
    "\n",
    "    Returns:\n",
    "        The parameters represented by a single vector\n",
    "    \"\"\"\n",
    "    # Flag for the device where the parameter is located\n",
    "    param_device = None\n",
    "\n",
    "    vec = []\n",
    "    for param in parameters:\n",
    "        # Ensure the parameters are located in the same device\n",
    "        param_device = param.grad\n",
    "\n",
    "        vec.append(param_device.view(-1))\n",
    "    return torch.cat(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cd3a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(67.7575) tensor([-0.2762,  0.3150, -0.2469, -0.0316, -0.3489,  0.0675, -0.0357, -0.2872])\n",
      "0 tensor(43.6709) tensor([-0.2384,  0.3568, -0.2781,  0.0811, -0.3566,  0.1175, -0.1236, -0.3307])\n",
      "0 tensor(71.2480) tensor([-0.1696,  0.3602, -0.2363,  0.1274, -0.3335,  0.1468, -0.1930, -0.3289])\n",
      "0 tensor(57.2519) tensor([-0.1687,  0.3975, -0.2431,  0.2185, -0.2818,  0.1925, -0.3287, -0.3383])\n",
      "1 tensor(58.7885) tensor([-0.1393,  0.3980, -0.2538,  0.3296, -0.2605,  0.2443, -0.3907, -0.3797])\n",
      "1 tensor(38.1779) tensor([-0.1040,  0.4376, -0.2827,  0.4343, -0.2664,  0.2908, -0.4718, -0.4207])\n",
      "1 tensor(62.0731) tensor([-0.0395,  0.4411, -0.2432,  0.4768, -0.2436,  0.3189, -0.5362, -0.4192])\n",
      "1 tensor(49.8173) tensor([-0.0384,  0.4765, -0.2490,  0.5614, -0.1940,  0.3614, -0.6626, -0.4279])\n",
      "2 tensor(51.0360) tensor([-0.0110,  0.4774, -0.2582,  0.6645, -0.1732,  0.4102, -0.7196, -0.4672])\n",
      "2 tensor(33.3960) tensor([ 0.0219,  0.5149, -0.2849,  0.7616, -0.1775,  0.4535, -0.7946, -0.5058])\n",
      "2 tensor(54.1043) tensor([ 0.0825,  0.5185, -0.2477,  0.8007, -0.1550,  0.4804, -0.8543, -0.5046])\n",
      "2 tensor(43.3740) tensor([ 0.0838,  0.5522, -0.2526,  0.8793, -0.1076,  0.5198, -0.9719, -0.5126])\n",
      "3 tensor(44.3308) tensor([ 0.1094,  0.5534, -0.2603,  0.9749, -0.0872,  0.5659, -1.0245, -0.5498])\n",
      "3 tensor(29.2304) tensor([ 0.1401,  0.5889, -0.2850,  1.0651, -0.0902,  0.6062, -1.0938, -0.5863])\n",
      "3 tensor(47.1795) tensor([ 0.1970,  0.5925, -0.2499,  1.1010, -0.0680,  0.6319, -1.1492, -0.5853])\n",
      "3 tensor(37.7864) tensor([ 0.1984,  0.6245, -0.2541,  1.1740, -0.0227,  0.6685, -1.2587, -0.5927])\n",
      "4 tensor(38.5282) tensor([ 0.2223,  0.6261, -0.2605,  1.2627, -0.0028,  0.7120, -1.3071, -0.6280])\n",
      "4 tensor(25.5991) tensor([ 0.2511,  0.6597, -0.2834,  1.3465, -0.0046,  0.7495, -1.3712, -0.6624])\n",
      "4 tensor(41.1590) tensor([ 0.3045,  0.6632, -0.2503,  1.3795,  0.0172,  0.7741, -1.4225, -0.6616])\n",
      "4 tensor(32.9376) tensor([ 0.3060,  0.6936, -0.2539,  1.4472,  0.0604,  0.8082, -1.5245, -0.6684])\n",
      "5 tensor(33.5037) tensor([ 0.3283,  0.6955, -0.2592,  1.5296,  0.0798,  0.8491, -1.5691, -0.7019])\n",
      "5 tensor(22.4315) tensor([ 0.3552,  0.7273, -0.2803,  1.6075,  0.0790,  0.8841, -1.6284, -0.7343])\n",
      "5 tensor(35.9222) tensor([ 0.4053,  0.7308, -0.2492,  1.6377,  0.1003,  0.9076, -1.6760, -0.7337])\n",
      "5 tensor(28.7273) tensor([ 0.4070,  0.7597, -0.2521,  1.7006,  0.1415,  0.9392, -1.7710, -0.7400])\n",
      "6 tensor(29.1504) tensor([ 0.4278,  0.7617, -0.2564,  1.7771,  0.1605,  0.9778, -1.8121, -0.7718])\n",
      "6 tensor(19.6665) tensor([ 0.4529,  0.7919, -0.2760,  1.8494,  0.1606,  1.0104, -1.8669, -0.8024])\n",
      "6 tensor(31.3649) tensor([ 0.5000,  0.7954, -0.2467,  1.8772,  0.1813,  1.0329, -1.9110, -0.8020])\n",
      "6 tensor(25.0693) tensor([ 0.5017,  0.8227, -0.2491,  1.9356,  0.2206,  1.0623, -1.9996, -0.8078])\n",
      "7 tensor(25.3765) tensor([ 0.5213,  0.8250, -0.2525,  2.0066,  0.2390,  1.0987, -2.0374, -0.8379])\n",
      "7 tensor(17.2516) tensor([ 0.5447,  0.8535, -0.2706,  2.0738,  0.2399,  1.1290, -2.0881, -0.8667])\n",
      "7 tensor(27.3971) tensor([ 0.5889,  0.8569, -0.2431,  2.0993,  0.2601,  1.1506, -2.1290, -0.8665])\n",
      "7 tensor(21.8890) tensor([ 0.5907,  0.8828, -0.2450,  2.1535,  0.2976,  1.1779, -2.2115, -0.8719])\n",
      "8 tensor(22.1030) tensor([ 0.6090,  0.8853, -0.2477,  2.2195,  0.3154,  1.2122, -2.2464, -0.9005])\n",
      "8 tensor(15.1409) tensor([ 0.6308,  0.9122, -0.2645,  2.2819,  0.3169,  1.2405, -2.2933, -0.9277])\n",
      "8 tensor(23.9410) tensor([ 0.6724,  0.9156, -0.2386,  2.3053,  0.3365,  1.2610, -2.3313, -0.9276])\n",
      "8 tensor(19.1225) tensor([ 0.6743,  0.9402, -0.2401,  2.3557,  0.3723,  1.2865, -2.4082, -0.9326])\n",
      "9 tensor(19.2619) tensor([ 0.6913,  0.9427, -0.2421,  2.4169,  0.3895,  1.3188, -2.4403, -0.9596])\n",
      "9 tensor(13.2952) tensor([ 0.7118,  0.9683, -0.2577,  2.4749,  0.3916,  1.3452, -2.4837, -0.9853])\n",
      "9 tensor(20.9292) tensor([ 0.7509,  0.9716, -0.2333,  2.4964,  0.4106,  1.3648, -2.5189, -0.9854])\n",
      "9 tensor(16.7144) tensor([ 0.7527,  0.9949, -0.2344,  2.5432,  0.4446,  1.3885, -2.5906, -0.9900])\n",
      "10 tensor(16.7947) tensor([ 0.7687,  0.9975, -0.2358,  2.6001,  0.4613,  1.4189, -2.6202, -1.0156])\n",
      "10 tensor(11.6800) tensor([ 0.7878,  1.0216, -0.2503,  2.6540,  0.4639,  1.4435, -2.6603, -1.0398])\n",
      "10 tensor(18.3034) tensor([ 0.8246,  1.0249, -0.2274,  2.6736,  0.4823,  1.4623, -2.6930, -1.0400])\n",
      "10 tensor(14.6170) tensor([ 0.8265,  1.0469, -0.2282,  2.7172,  0.5147,  1.4843, -2.7598, -1.0444])\n",
      "11 tensor(14.6511) tensor([ 0.8414,  1.0497, -0.2291,  2.7700,  0.5307,  1.5130, -2.7872, -1.0686])\n",
      "11 tensor(10.2659) tensor([ 0.8593,  1.0725, -0.2425,  2.8201,  0.5337,  1.5359, -2.8243, -1.0915])\n",
      "11 tensor(16.0131) tensor([ 0.8938,  1.0757, -0.2210,  2.8381,  0.5515,  1.5538, -2.8546, -1.0918])\n",
      "11 tensor(12.7893) tensor([ 0.8957,  1.0965, -0.2216,  2.8786,  0.5823,  1.5743, -2.9169, -1.0958])\n",
      "12 tensor(12.7874) tensor([ 0.9097,  1.0993, -0.2220,  2.9277,  0.5978,  1.6014, -2.9421, -1.1188])\n",
      "12 tensor(9.0271) tensor([ 0.9264,  1.1209, -0.2345,  2.9742,  0.6011,  1.6227, -2.9765, -1.1403])\n",
      "12 tensor(14.0146) tensor([ 0.9589,  1.1240, -0.2142,  2.9907,  0.6183,  1.6398, -3.0046, -1.1407])\n",
      "12 tensor(11.1956) tensor([ 0.9608,  1.1437, -0.2146,  3.0283,  0.6476,  1.6589, -3.0627, -1.1445])\n",
      "13 tensor(11.1664) tensor([ 0.9739,  1.1465, -0.2146,  3.0740,  0.6625,  1.6844, -3.0859, -1.1662])\n",
      "13 tensor(7.9412) tensor([ 0.9896,  1.1669, -0.2262,  3.1173,  0.6661,  1.7043, -3.1177, -1.1866])\n",
      "13 tensor(12.2700) tensor([ 1.0201,  1.1699, -0.2072,  3.1324,  0.6827,  1.7206, -3.1439, -1.1870])\n",
      "13 tensor(9.8052) tensor([ 1.0220,  1.1886, -0.2074,  3.1673,  0.7105,  1.7383, -3.1980, -1.1906])\n",
      "14 tensor(9.7556) tensor([ 1.0342,  1.1914, -0.2071,  3.2097,  0.7248,  1.7624, -3.2194, -1.2111])\n",
      "14 tensor(6.9889) tensor([ 1.0489,  1.2107, -0.2179,  3.2500,  0.7287,  1.7810, -3.2489, -1.2304])\n",
      "14 tensor(10.7465) tensor([ 1.0776,  1.2136, -0.2000,  3.2638,  0.7446,  1.7965, -3.2731, -1.2309])\n",
      "14 tensor(8.5915) tensor([ 1.0795,  1.2313, -0.2000,  3.2963,  0.7711,  1.8130, -3.3237, -1.2342])\n",
      "15 tensor(8.5271) tensor([ 1.0909,  1.2341, -0.1994,  3.3357,  0.7848,  1.8357, -3.3434, -1.2536])\n",
      "15 tensor(6.1533) tensor([ 1.1047,  1.2524, -0.2094,  3.3731,  0.7889,  1.8531, -3.3707, -1.2718])\n",
      "15 tensor(9.4153) tensor([ 1.1316,  1.2552, -0.1926,  3.3858,  0.8042,  1.8679, -3.3932, -1.2724])\n",
      "15 tensor(7.5314) tensor([ 1.1335,  1.2719, -0.1925,  3.4160,  0.8293,  1.8833, -3.4404, -1.2755])\n",
      "16 tensor(7.4569) tensor([ 1.1443,  1.2747, -0.1917,  3.4526,  0.8425,  1.9046, -3.4586, -1.2939])\n",
      "16 tensor(5.4197) tensor([ 1.1571,  1.2919, -0.2010,  3.4875,  0.8467,  1.9209, -3.4838, -1.3110])\n",
      "16 tensor(8.2519) tensor([ 1.1825,  1.2947, -0.1852,  3.4991,  0.8614,  1.9349, -3.5047, -1.3117])\n",
      "16 tensor(6.6051) tensor([ 1.1843,  1.3105, -0.1850,  3.5271,  0.8853,  1.9493, -3.5487, -1.3145])\n",
      "17 tensor(6.5239) tensor([ 1.1944,  1.3133, -0.1840,  3.5612,  0.8979,  1.9694, -3.5655, -1.3320])\n",
      "17 tensor(4.7754) tensor([ 1.2064,  1.3295, -0.1927,  3.5936,  0.9022,  1.9846, -3.5889, -1.3482])\n",
      "17 tensor(7.2347) tensor([ 1.2303,  1.3322, -0.1778,  3.6042,  0.9163,  1.9980, -3.6083, -1.3489])\n",
      "17 tensor(5.7952) tensor([ 1.2321,  1.3472, -0.1775,  3.6303,  0.9390,  2.0113, -3.6493, -1.3515])\n",
      "18 tensor(5.7102) tensor([ 1.2416,  1.3499, -0.1763,  3.6620,  0.9511,  2.0303, -3.6648, -1.3681])\n",
      "18 tensor(4.2092) tensor([ 1.2528,  1.3653, -0.1844,  3.6921,  0.9554,  2.0444, -3.6865, -1.3833])\n",
      "18 tensor(6.3449) tensor([ 1.2752,  1.3678, -0.1705,  3.7018,  0.9690,  2.0572, -3.7045, -1.3841])\n",
      "18 tensor(5.0867) tensor([ 1.2770,  1.3820, -0.1701,  3.7261,  0.9905,  2.0697, -3.7428, -1.3866])\n",
      "19 tensor(5.0003) tensor([ 1.2859,  1.3846, -0.1687,  3.7556,  1.0021,  2.0876, -3.7571, -1.4022])\n",
      "19 tensor(3.7114) tensor([ 1.2965,  1.3992, -0.1763,  3.7836,  1.0064,  2.1008, -3.7772, -1.4166])\n",
      "19 tensor(5.5663) tensor([ 1.3175,  1.4016, -0.1632,  3.7924,  1.0195,  2.1129, -3.7940, -1.4174])\n",
      "19 tensor(4.4667) tensor([ 1.3193,  1.4150, -0.1627,  3.8150,  1.0399,  2.1245, -3.8297, -1.4197])\n",
      "20 tensor(4.3804) tensor([ 1.3276,  1.4176, -0.1613,  3.8424,  1.0510,  2.1414, -3.8429, -1.4345])\n",
      "20 tensor(3.2736) tensor([ 1.3375,  1.4314, -0.1683,  3.8685,  1.0553,  2.1537, -3.8615, -1.4481])\n",
      "20 tensor(4.8848) tensor([ 1.3573,  1.4337, -0.1560,  3.8766,  1.0678,  2.1653, -3.8770, -1.4489])\n",
      "20 tensor(3.9237) tensor([ 1.3591,  1.4464, -0.1555,  3.8976,  1.0871,  2.1761, -3.9104, -1.4511])\n",
      "21 tensor(3.8391) tensor([ 1.3669,  1.4490, -0.1539,  3.9231,  1.0977,  2.1920, -3.9226, -1.4651])\n",
      "21 tensor(2.8884) tensor([ 1.3761,  1.4619, -0.1605,  3.9474,  1.1020,  2.2035, -3.9398, -1.4780])\n",
      "21 tensor(4.2880) tensor([ 1.3948,  1.4642, -0.1490,  3.9548,  1.1140,  2.2145, -3.9543, -1.4788])\n",
      "21 tensor(3.4481) tensor([ 1.3965,  1.4762, -0.1484,  3.9743,  1.1323,  2.2246, -3.9854, -1.4808])\n",
      "22 tensor(3.3660) tensor([ 1.4038,  1.4787, -0.1468,  3.9981,  1.1425,  2.2396, -3.9966, -1.4941])\n",
      "22 tensor(2.5493) tensor([ 1.4125,  1.4909, -0.1530,  4.0207,  1.1468,  2.2503, -4.0126, -1.5062])\n",
      "22 tensor(3.7652) tensor([ 1.4300,  1.4931, -0.1421,  4.0274,  1.1582,  2.2608, -4.0261, -1.5070])\n",
      "22 tensor(3.0313) tensor([ 1.4317,  1.5044, -0.1415,  4.0456,  1.1756,  2.2702, -4.0552, -1.5090])\n",
      "23 tensor(2.9524) tensor([ 1.4385,  1.5068, -0.1399,  4.0677,  1.1853,  2.2844, -4.0655, -1.5215])\n",
      "23 tensor(2.2506) tensor([ 1.4467,  1.5184, -0.1456,  4.0887,  1.1895,  2.2944, -4.0803, -1.5329])\n",
      "23 tensor(3.3071) tensor([ 1.4632,  1.5205, -0.1354,  4.0949,  1.2004,  2.3044, -4.0928, -1.5338])\n",
      "23 tensor(2.6658) tensor([ 1.4648,  1.5312, -0.1348,  4.1118,  1.2169,  2.3131, -4.1200, -1.5356])\n",
      "24 tensor(2.5906) tensor([ 1.4712,  1.5335, -0.1331,  4.1324,  1.2261,  2.3265, -4.1295, -1.5474])\n",
      "24 tensor(1.9875) tensor([ 1.4788,  1.5445, -0.1385,  4.1519,  1.2303,  2.3358, -4.1432, -1.5583])\n",
      "24 tensor(2.9056) tensor([ 1.4944,  1.5465, -0.1289,  4.1576,  1.2407,  2.3453, -4.1549, -1.5591])\n",
      "24 tensor(2.3452) tensor([ 1.4959,  1.5566, -0.1283,  4.1733,  1.2563,  2.3535, -4.1802, -1.5608])\n",
      "25 tensor(2.2741) tensor([ 1.5020,  1.5589, -0.1266,  4.1924,  1.2652,  2.3660, -4.1890, -1.5720])\n",
      "25 tensor(1.7557) tensor([ 1.5091,  1.5692, -0.1316,  4.2107,  1.2693,  2.3748, -4.2018, -1.5822])\n",
      "25 tensor(2.5535) tensor([ 1.5238,  1.5711, -0.1227,  4.2158,  1.2792,  2.3838, -4.2126, -1.5830])\n",
      "25 tensor(2.0638) tensor([ 1.5253,  1.5806, -0.1220,  4.2305,  1.2940,  2.3915, -4.2363, -1.5846])\n",
      "26 tensor(1.9969) tensor([ 1.5309,  1.5829, -0.1203,  4.2483,  1.3024,  2.4033, -4.2444, -1.5952])\n",
      "26 tensor(1.5513) tensor([ 1.5376,  1.5926, -0.1249,  4.2652,  1.3064,  2.4115, -4.2562, -1.6049])\n",
      "26 tensor(2.2446) tensor([ 1.5514,  1.5945, -0.1166,  4.2699,  1.3159,  2.4200, -4.2663, -1.6057])\n",
      "26 tensor(1.8168) tensor([ 1.5529,  1.6034, -0.1159,  4.2836,  1.3299,  2.4272, -4.2884, -1.6072])\n",
      "27 tensor(1.7542) tensor([ 1.5582,  1.6056, -0.1142,  4.3001,  1.3379,  2.4383, -4.2959, -1.6172])\n",
      "27 tensor(1.3710) tensor([ 1.5645,  1.6148, -0.1186,  4.3159,  1.3419,  2.4460, -4.3068, -1.6264])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 tensor(1.9737) tensor([ 1.5774,  1.6166, -0.1107,  4.3202,  1.3509,  2.4541, -4.3162, -1.6272])\n",
      "27 tensor(1.5998) tensor([ 1.5788,  1.6250, -0.1100,  4.3329,  1.3642,  2.4608, -4.3369, -1.6286])\n",
      "28 tensor(1.5415) tensor([ 1.5838,  1.6271, -0.1083,  4.3484,  1.3718,  2.4713, -4.3438, -1.6381])\n",
      "28 tensor(1.2119) tensor([ 1.5897,  1.6358, -0.1124,  4.3631,  1.3757,  2.4784, -4.3539, -1.6467])\n",
      "28 tensor(1.7359) tensor([ 1.6019,  1.6375, -0.1050,  4.3670,  1.3843,  2.4862, -4.3626, -1.6475])\n",
      "28 tensor(1.4092) tensor([ 1.6033,  1.6455, -0.1044,  4.3788,  1.3969,  2.4924, -4.3820, -1.6488])\n",
      "29 tensor(1.3551) tensor([ 1.6080,  1.6475, -0.1027,  4.3932,  1.4041,  2.5023, -4.3883, -1.6578])\n",
      "29 tensor(1.0716) tensor([ 1.6135,  1.6558, -0.1065,  4.4069,  1.4078,  2.5090, -4.3978, -1.6659])\n",
      "29 tensor(1.5271) tensor([ 1.6250,  1.6574, -0.0996,  4.4104,  1.4161,  2.5163, -4.4059, -1.6667])\n",
      "29 tensor(1.2417) tensor([ 1.6263,  1.6649, -0.0990,  4.4214,  1.4280,  2.5221, -4.4239, -1.6680])\n",
      "30 tensor(1.1916) tensor([ 1.6307,  1.6669, -0.0973,  4.4348,  1.4349,  2.5315, -4.4298, -1.6764])\n",
      "30 tensor(0.9477) tensor([ 1.6359,  1.6746, -0.1009,  4.4476,  1.4385,  2.5377, -4.4386, -1.6841])\n",
      "30 tensor(1.3437) tensor([ 1.6467,  1.6762, -0.0944,  4.4508,  1.4463,  2.5447, -4.4461, -1.6849])\n",
      "30 tensor(1.0944) tensor([ 1.6480,  1.6833, -0.0938,  4.4611,  1.4576,  2.5501, -4.4630, -1.6861])\n",
      "31 tensor(1.0482) tensor([ 1.6521,  1.6852, -0.0921,  4.4736,  1.4642,  2.5589, -4.4684, -1.6941])\n",
      "31 tensor(0.8383) tensor([ 1.6570,  1.6925, -0.0955,  4.4855,  1.4677,  2.5648, -4.4765, -1.7013])\n",
      "31 tensor(1.1827) tensor([ 1.6672,  1.6939, -0.0894,  4.4884,  1.4751,  2.5714, -4.4835, -1.7021])\n",
      "31 tensor(0.9648) tensor([ 1.6684,  1.7007, -0.0888,  4.4980,  1.4858,  2.5764, -4.4993, -1.7032])\n",
      "32 tensor(0.9224) tensor([ 1.6723,  1.7025, -0.0871,  4.5096,  1.4921,  2.5847, -4.5043, -1.7108])\n",
      "32 tensor(0.7417) tensor([ 1.6769,  1.7094, -0.0903,  4.5207,  1.4955,  2.5902, -4.5118, -1.7177])\n",
      "32 tensor(1.0411) tensor([ 1.6864,  1.7108, -0.0846,  4.5234,  1.5026,  2.5965, -4.5184, -1.7184])\n",
      "32 tensor(0.8508) tensor([ 1.6876,  1.7171, -0.0840,  4.5323,  1.5126,  2.6012, -4.5331, -1.7195])\n",
      "33 tensor(0.8119) tensor([ 1.6913,  1.7189, -0.0824,  4.5431,  1.5186,  2.6090, -4.5377, -1.7266])\n",
      "33 tensor(0.6563) tensor([ 1.6956,  1.7254, -0.0854,  4.5534,  1.5219,  2.6142, -4.5447, -1.7331])\n",
      "33 tensor(0.9167) tensor([ 1.7046,  1.7267, -0.0800,  4.5559,  1.5286,  2.6201, -4.5508, -1.7338])\n",
      "33 tensor(0.7504) tensor([ 1.7057,  1.7327, -0.0794,  4.5641,  1.5382,  2.6245, -4.5646, -1.7348])\n",
      "34 tensor(0.7148) tensor([ 1.7091,  1.7344, -0.0779,  4.5743,  1.5438,  2.6319, -4.5689, -1.7416])\n",
      "34 tensor(0.5809) tensor([ 1.7132,  1.7405, -0.0807,  4.5839,  1.5470,  2.6367, -4.5754, -1.7477])\n",
      "34 tensor(0.8074) tensor([ 1.7217,  1.7418, -0.0757,  4.5861,  1.5534,  2.6423, -4.5810, -1.7484])\n",
      "34 tensor(0.6621) tensor([ 1.7227,  1.7474, -0.0751,  4.5938,  1.5624,  2.6465, -4.5939, -1.7493])\n",
      "35 tensor(0.6295) tensor([ 1.7260,  1.7490, -0.0736,  4.6032,  1.5678,  2.6534, -4.5978, -1.7557])\n",
      "35 tensor(0.5142) tensor([ 1.7298,  1.7549, -0.0762,  4.6122,  1.5709,  2.6579, -4.6039, -1.7615])\n",
      "35 tensor(0.7112) tensor([ 1.7377,  1.7561, -0.0715,  4.6142,  1.5770,  2.6633, -4.6091, -1.7622])\n",
      "35 tensor(0.5843) tensor([ 1.7388,  1.7614, -0.0709,  4.6214,  1.5855,  2.6671, -4.6212, -1.7631])\n",
      "36 tensor(0.5546) tensor([ 1.7418,  1.7629, -0.0695,  4.6302,  1.5906,  2.6737, -4.6248, -1.7691])\n",
      "36 tensor(0.4553) tensor([ 1.7454,  1.7684, -0.0719,  4.6386,  1.5935,  2.6779, -4.6304, -1.7746])\n",
      "36 tensor(0.6267) tensor([ 1.7529,  1.7696, -0.0675,  4.6404,  1.5993,  2.6830, -4.6353, -1.7753])\n",
      "36 tensor(0.5157) tensor([ 1.7539,  1.7746, -0.0670,  4.6471,  1.6074,  2.6866, -4.6466, -1.7761])\n",
      "37 tensor(0.4887) tensor([ 1.7568,  1.7761, -0.0656,  4.6553,  1.6123,  2.6928, -4.6500, -1.7818])\n",
      "37 tensor(0.4031) tensor([ 1.7601,  1.7812, -0.0679,  4.6631,  1.6151,  2.6967, -4.6552, -1.7869])\n",
      "37 tensor(0.5522) tensor([ 1.7672,  1.7823, -0.0637,  4.6647,  1.6206,  2.7015, -4.6597, -1.7876])\n",
      "37 tensor(0.4553) tensor([ 1.7681,  1.7871, -0.0632,  4.6710,  1.6282,  2.7049, -4.6703, -1.7884])\n",
      "38 tensor(0.4308) tensor([ 1.7708,  1.7885, -0.0618,  4.6786,  1.6328,  2.7107, -4.6734, -1.7938])\n",
      "38 tensor(0.3570) tensor([ 1.7739,  1.7934, -0.0640,  4.6859,  1.6356,  2.7144, -4.6782, -1.7986])\n",
      "38 tensor(0.4868) tensor([ 1.7806,  1.7944, -0.0601,  4.6874,  1.6408,  2.7189, -4.6825, -1.7993])\n",
      "38 tensor(0.4021) tensor([ 1.7815,  1.7989, -0.0597,  4.6932,  1.6480,  2.7221, -4.6923, -1.8000])\n",
      "39 tensor(0.3798) tensor([ 1.7841,  1.8002, -0.0583,  4.7003,  1.6524,  2.7276, -4.6952, -1.8051])\n",
      "39 tensor(0.3162) tensor([ 1.7870,  1.8048, -0.0604,  4.7071,  1.6550,  2.7310, -4.6997, -1.8097])\n",
      "39 tensor(0.4291) tensor([ 1.7933,  1.8058, -0.0567,  4.7085,  1.6600,  2.7354, -4.7036, -1.8103])\n",
      "39 tensor(0.3551) tensor([ 1.7942,  1.8100, -0.0563,  4.7139,  1.6668,  2.7383, -4.7129, -1.8110])\n",
      "40 tensor(0.3349) tensor([ 1.7965,  1.8113, -0.0550,  4.7206,  1.6709,  2.7435, -4.7155, -1.8158])\n",
      "40 tensor(0.2801) tensor([ 1.7993,  1.8157, -0.0569,  4.7269,  1.6734,  2.7467, -4.7197, -1.8202])\n",
      "40 tensor(0.3784) tensor([ 1.8052,  1.8166, -0.0535,  4.7281,  1.6782,  2.7508, -4.7234, -1.8208])\n",
      "40 tensor(0.3137) tensor([ 1.8061,  1.8206, -0.0530,  4.7332,  1.6846,  2.7536, -4.7320, -1.8214])\n",
      "41 tensor(0.2954) tensor([ 1.8083,  1.8218, -0.0518,  4.7394,  1.6885,  2.7585, -4.7344, -1.8260])\n",
      "41 tensor(0.2482) tensor([ 1.8109,  1.8260, -0.0536,  4.7453,  1.6909,  2.7615, -4.7383, -1.8301])\n",
      "41 tensor(0.3337) tensor([ 1.8164,  1.8269, -0.0504,  4.7464,  1.6954,  2.7654, -4.7418, -1.8307])\n",
      "41 tensor(0.2772) tensor([ 1.8173,  1.8306, -0.0500,  4.7511,  1.7015,  2.7680, -4.7498, -1.8313])\n",
      "42 tensor(0.2607) tensor([ 1.8194,  1.8318, -0.0488,  4.7569,  1.7052,  2.7725, -4.7521, -1.8356])\n",
      "42 tensor(0.2199) tensor([ 1.8218,  1.8356, -0.0505,  4.7624,  1.7076,  2.7754, -4.7557, -1.8394])\n",
      "42 tensor(0.2943) tensor([ 1.8270,  1.8365, -0.0475,  4.7634,  1.7118,  2.7791, -4.7589, -1.8400])\n",
      "42 tensor(0.2449) tensor([ 1.8278,  1.8400, -0.0471,  4.7678,  1.7176,  2.7815, -4.7665, -1.8406])\n",
      "43 tensor(0.2300) tensor([ 1.8298,  1.8412, -0.0459,  4.7732,  1.7211,  2.7858, -4.7685, -1.8446])\n",
      "43 tensor(0.1949) tensor([ 1.8321,  1.8448, -0.0475,  4.7784,  1.7233,  2.7885, -4.7719, -1.8483])\n",
      "43 tensor(0.2597) tensor([ 1.8370,  1.8456, -0.0447,  4.7793,  1.7273,  2.7919, -4.7749, -1.8488])\n",
      "43 tensor(0.2165) tensor([ 1.8378,  1.8489, -0.0443,  4.7834,  1.7328,  2.7942, -4.7819, -1.8494])\n",
      "44 tensor(0.2030) tensor([ 1.8396,  1.8500, -0.0432,  4.7884,  1.7361,  2.7983, -4.7839, -1.8532])\n",
      "44 tensor(0.1727) tensor([ 1.8418,  1.8535, -0.0447,  4.7932,  1.7382,  2.8008, -4.7870, -1.8567])\n",
      "44 tensor(0.2291) tensor([ 1.8464,  1.8543, -0.0421,  4.7940,  1.7421,  2.8041, -4.7898, -1.8572])\n",
      "44 tensor(0.1914) tensor([ 1.8471,  1.8574, -0.0417,  4.7979,  1.7472,  2.8062, -4.7964, -1.8577])\n",
      "45 tensor(0.1793) tensor([ 1.8489,  1.8584, -0.0407,  4.8026,  1.7504,  2.8100, -4.7982, -1.8613])\n",
      "45 tensor(0.1531) tensor([ 1.8509,  1.8617, -0.0421,  4.8071,  1.7524,  2.8124, -4.8011, -1.8646])\n",
      "45 tensor(0.2022) tensor([ 1.8553,  1.8624, -0.0396,  4.8078,  1.7560,  2.8155, -4.8037, -1.8651])\n",
      "45 tensor(0.1692) tensor([ 1.8559,  1.8653, -0.0393,  4.8114,  1.7609,  2.8175, -4.8099, -1.8656])\n",
      "46 tensor(0.1583) tensor([ 1.8576,  1.8663, -0.0383,  4.8157,  1.7639,  2.8211, -4.8115, -1.8690])\n",
      "46 tensor(0.1357) tensor([ 1.8595,  1.8694, -0.0396,  4.8199,  1.7658,  2.8233, -4.8142, -1.8721])\n",
      "46 tensor(0.1784) tensor([ 1.8636,  1.8701, -0.0373,  4.8206,  1.7693,  2.8263, -4.8166, -1.8726])\n",
      "46 tensor(0.1496) tensor([ 1.8643,  1.8729, -0.0370,  4.8239,  1.7738,  2.8281, -4.8224, -1.8730])\n",
      "47 tensor(0.1398) tensor([ 1.8658,  1.8738, -0.0360,  4.8280,  1.7767,  2.8315, -4.8239, -1.8763])\n",
      "47 tensor(0.1203) tensor([ 1.8676,  1.8767, -0.0372,  4.8319,  1.7785,  2.8336, -4.8264, -1.8792])\n",
      "47 tensor(0.1575) tensor([ 1.8715,  1.8774, -0.0351,  4.8325,  1.7818,  2.8364, -4.8287, -1.8796])\n",
      "47 tensor(0.1323) tensor([ 1.8721,  1.8800, -0.0348,  4.8356,  1.7861,  2.8381, -4.8341, -1.8801])\n",
      "48 tensor(0.1235) tensor([ 1.8736,  1.8809, -0.0338,  4.8395,  1.7888,  2.8413, -4.8355, -1.8831])\n",
      "48 tensor(0.1067) tensor([ 1.8752,  1.8836, -0.0350,  4.8431,  1.7906,  2.8433, -4.8379, -1.8859])\n",
      "48 tensor(0.1391) tensor([ 1.8789,  1.8843, -0.0330,  4.8436,  1.7937,  2.8459, -4.8399, -1.8863])\n",
      "48 tensor(0.1170) tensor([ 1.8795,  1.8867, -0.0327,  4.8466,  1.7978,  2.8475, -4.8450, -1.8867])\n",
      "49 tensor(0.1091) tensor([ 1.8808,  1.8876, -0.0318,  4.8501,  1.8003,  2.8506, -4.8463, -1.8896])\n",
      "49 tensor(0.0946) tensor([ 1.8824,  1.8902, -0.0329,  4.8535,  1.8020,  2.8524, -4.8485, -1.8922])\n",
      "49 tensor(0.1228) tensor([ 1.8859,  1.8907, -0.0310,  4.8540,  1.8049,  2.8549, -4.8505, -1.8926])\n",
      "49 tensor(0.1035) tensor([ 1.8864,  1.8931, -0.0307,  4.8567,  1.8088,  2.8564, -4.8552, -1.8930])\n",
      "50 tensor(0.0964) tensor([ 1.8877,  1.8939, -0.0299,  4.8601,  1.8112,  2.8593, -4.8564, -1.8957])\n",
      "50 tensor(0.0839) tensor([ 1.8892,  1.8963, -0.0309,  4.8633,  1.8128,  2.8610, -4.8584, -1.8982])\n",
      "50 tensor(0.1084) tensor([ 1.8924,  1.8969, -0.0292,  4.8637,  1.8156,  2.8633, -4.8603, -1.8986])\n",
      "50 tensor(0.0916) tensor([ 1.8930,  1.8991, -0.0289,  4.8662,  1.8193,  2.8648, -4.8647, -1.8990])\n",
      "51 tensor(0.0852) tensor([ 1.8942,  1.8998, -0.0281,  4.8693,  1.8215,  2.8675, -4.8658, -1.9015])\n",
      "51 tensor(0.0744) tensor([ 1.8956,  1.9021, -0.0291,  4.8723,  1.8231,  2.8690, -4.8677, -1.9038])\n",
      "51 tensor(0.0958) tensor([ 1.8986,  1.9027, -0.0274,  4.8727,  1.8257,  2.8713, -4.8694, -1.9042])\n",
      "51 tensor(0.0811) tensor([ 1.8991,  1.9047, -0.0271,  4.8750,  1.8291,  2.8726, -4.8736, -1.9046])\n",
      "52 tensor(0.0753) tensor([ 1.9003,  1.9055, -0.0264,  4.8780,  1.8313,  2.8752, -4.8746, -1.9070])\n",
      "52 tensor(0.0660) tensor([ 1.9016,  1.9076, -0.0273,  4.8807,  1.8328,  2.8767, -4.8764, -1.9092])\n",
      "52 tensor(0.0846) tensor([ 1.9045,  1.9081, -0.0257,  4.8811,  1.8353,  2.8788, -4.8779, -1.9096])\n",
      "52 tensor(0.0717) tensor([ 1.9050,  1.9101, -0.0255,  4.8833,  1.8385,  2.8800, -4.8819, -1.9099])\n",
      "53 tensor(0.0666) tensor([ 1.9060,  1.9108, -0.0247,  4.8860,  1.8406,  2.8824, -4.8828, -1.9122])\n",
      "53 tensor(0.0585) tensor([ 1.9073,  1.9128, -0.0256,  4.8886,  1.8420,  2.8838, -4.8844, -1.9142])\n",
      "53 tensor(0.0747) tensor([ 1.9100,  1.9133, -0.0242,  4.8889,  1.8443,  2.8858, -4.8859, -1.9146])\n",
      "53 tensor(0.0635) tensor([ 1.9104,  1.9151, -0.0239,  4.8910,  1.8474,  2.8870, -4.8896, -1.9149])\n",
      "54 tensor(0.0589) tensor([ 1.9115,  1.9158, -0.0232,  4.8935,  1.8493,  2.8893, -4.8905, -1.9171])\n",
      "54 tensor(0.0519) tensor([ 1.9126,  1.9177, -0.0241,  4.8959,  1.8506,  2.8906, -4.8920, -1.9190])\n",
      "54 tensor(0.0660) tensor([ 1.9152,  1.9182, -0.0227,  4.8962,  1.8529,  2.8925, -4.8933, -1.9194])\n",
      "54 tensor(0.0562) tensor([ 1.9156,  1.9199, -0.0225,  4.8981,  1.8558,  2.8936, -4.8968, -1.9197])\n",
      "55 tensor(0.0521) tensor([ 1.9166,  1.9206, -0.0218,  4.9005,  1.8576,  2.8957, -4.8976, -1.9217])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 tensor(0.0460) tensor([ 1.9177,  1.9224, -0.0226,  4.9028,  1.8589,  2.8969, -4.8990, -1.9235])\n",
      "55 tensor(0.0584) tensor([ 1.9201,  1.9228, -0.0213,  4.9030,  1.8610,  2.8987, -4.9003, -1.9239])\n",
      "55 tensor(0.0497) tensor([ 1.9205,  1.9244, -0.0211,  4.9048,  1.8637,  2.8998, -4.9035, -1.9242])\n",
      "56 tensor(0.0461) tensor([ 1.9214,  1.9250, -0.0205,  4.9070,  1.8654,  2.9018, -4.9043, -1.9261])\n",
      "56 tensor(0.0408) tensor([ 1.9224,  1.9267, -0.0212,  4.9092,  1.8667,  2.9029, -4.9056, -1.9278])\n",
      "56 tensor(0.0516) tensor([ 1.9247,  1.9272, -0.0200,  4.9094,  1.8687,  2.9046, -4.9068, -1.9281])\n",
      "56 tensor(0.0440) tensor([ 1.9251,  1.9287, -0.0198,  4.9110,  1.8712,  2.9056, -4.9098, -1.9284])\n",
      "57 tensor(0.0408) tensor([ 1.9259,  1.9293, -0.0192,  4.9131,  1.8729,  2.9075, -4.9105, -1.9302])\n",
      "57 tensor(0.0362) tensor([ 1.9269,  1.9309, -0.0199,  4.9151,  1.8740,  2.9085, -4.9117, -1.9318])\n",
      "57 tensor(0.0456) tensor([ 1.9290,  1.9313, -0.0188,  4.9153,  1.8759,  2.9102, -4.9128, -1.9321])\n",
      "57 tensor(0.0390) tensor([ 1.9294,  1.9327, -0.0186,  4.9169,  1.8783,  2.9111, -4.9156, -1.9324])\n",
      "58 tensor(0.0361) tensor([ 1.9302,  1.9333, -0.0180,  4.9188,  1.8799,  2.9128, -4.9163, -1.9341])\n",
      "58 tensor(0.0321) tensor([ 1.9311,  1.9348, -0.0187,  4.9207,  1.8810,  2.9139, -4.9174, -1.9356])\n",
      "58 tensor(0.0403) tensor([ 1.9331,  1.9351, -0.0176,  4.9208,  1.8828,  2.9154, -4.9185, -1.9359])\n",
      "58 tensor(0.0345) tensor([ 1.9335,  1.9365, -0.0174,  4.9223,  1.8851,  2.9162, -4.9211, -1.9362])\n",
      "59 tensor(0.0319) tensor([ 1.9342,  1.9370, -0.0169,  4.9241,  1.8865,  2.9179, -4.9217, -1.9378])\n",
      "59 tensor(0.0285) tensor([ 1.9351,  1.9385, -0.0175,  4.9258,  1.8876,  2.9189, -4.9228, -1.9392])\n",
      "59 tensor(0.0356) tensor([ 1.9369,  1.9388, -0.0165,  4.9260,  1.8893,  2.9203, -4.9237, -1.9395])\n",
      "59 tensor(0.0306) tensor([ 1.9373,  1.9401, -0.0163,  4.9274,  1.8914,  2.9211, -4.9262, -1.9397])\n",
      "60 tensor(0.0282) tensor([ 1.9380,  1.9406, -0.0158,  4.9291,  1.8928,  2.9227, -4.9268, -1.9413])\n",
      "60 tensor(0.0253) tensor([ 1.9388,  1.9419, -0.0164,  4.9307,  1.8938,  2.9236, -4.9278, -1.9426])\n",
      "60 tensor(0.0315) tensor([ 1.9406,  1.9423, -0.0155,  4.9308,  1.8954,  2.9249, -4.9287, -1.9429])\n",
      "60 tensor(0.0271) tensor([ 1.9409,  1.9435, -0.0153,  4.9321,  1.8975,  2.9257, -4.9310, -1.9431])\n",
      "61 tensor(0.0250) tensor([ 1.9416,  1.9439, -0.0148,  4.9337,  1.8988,  2.9272, -4.9315, -1.9446])\n",
      "61 tensor(0.0224) tensor([ 1.9423,  1.9452, -0.0154,  4.9352,  1.8997,  2.9280, -4.9324, -1.9458])\n",
      "61 tensor(0.0278) tensor([ 1.9440,  1.9455, -0.0145,  4.9353,  1.9012,  2.9293, -4.9333, -1.9461])\n",
      "61 tensor(0.0240) tensor([ 1.9443,  1.9467, -0.0144,  4.9365,  1.9032,  2.9300, -4.9355, -1.9463])\n",
      "62 tensor(0.0221) tensor([ 1.9449,  1.9471, -0.0139,  4.9380,  1.9044,  2.9314, -4.9359, -1.9477])\n",
      "62 tensor(0.0199) tensor([ 1.9457,  1.9483, -0.0144,  4.9394,  1.9053,  2.9322, -4.9368, -1.9489])\n",
      "62 tensor(0.0246) tensor([ 1.9472,  1.9486, -0.0136,  4.9395,  1.9067,  2.9334, -4.9376, -1.9491])\n",
      "62 tensor(0.0212) tensor([ 1.9475,  1.9497, -0.0135,  4.9406,  1.9085,  2.9341, -4.9396, -1.9493])\n",
      "63 tensor(0.0196) tensor([ 1.9481,  1.9501, -0.0130,  4.9420,  1.9097,  2.9354, -4.9401, -1.9506])\n",
      "63 tensor(0.0177) tensor([ 1.9488,  1.9512, -0.0135,  4.9433,  1.9106,  2.9361, -4.9409, -1.9518])\n",
      "63 tensor(0.0218) tensor([ 1.9503,  1.9515, -0.0128,  4.9434,  1.9119,  2.9373, -4.9416, -1.9520])\n",
      "63 tensor(0.0188) tensor([ 1.9506,  1.9525, -0.0126,  4.9444,  1.9136,  2.9379, -4.9435, -1.9522])\n",
      "64 tensor(0.0173) tensor([ 1.9511,  1.9529, -0.0122,  4.9458,  1.9147,  2.9391, -4.9439, -1.9534])\n",
      "64 tensor(0.0157) tensor([ 1.9517,  1.9540, -0.0127,  4.9470,  1.9155,  2.9398, -4.9447, -1.9545])\n",
      "64 tensor(0.0193) tensor([ 1.9531,  1.9543, -0.0120,  4.9471,  1.9168,  2.9409, -4.9453, -1.9547])\n",
      "64 tensor(0.0167) tensor([ 1.9534,  1.9552, -0.0118,  4.9480,  1.9184,  2.9415, -4.9471, -1.9549])\n",
      "65 tensor(0.0154) tensor([ 1.9539,  1.9556, -0.0114,  4.9493,  1.9195,  2.9427, -4.9475, -1.9560])\n",
      "65 tensor(0.0139) tensor([ 1.9545,  1.9566, -0.0119,  4.9504,  1.9203,  2.9433, -4.9482, -1.9570])\n",
      "65 tensor(0.0170) tensor([ 1.9558,  1.9569, -0.0112,  4.9505,  1.9215,  2.9443, -4.9489, -1.9572])\n",
      "65 tensor(0.0148) tensor([ 1.9561,  1.9577, -0.0111,  4.9514,  1.9230,  2.9449, -4.9505, -1.9574])\n",
      "66 tensor(0.0136) tensor([ 1.9566,  1.9581, -0.0107,  4.9525,  1.9240,  2.9460, -4.9509, -1.9585])\n",
      "66 tensor(0.0123) tensor([ 1.9571,  1.9591, -0.0111,  4.9536,  1.9247,  2.9466, -4.9515, -1.9594])\n",
      "66 tensor(0.0151) tensor([ 1.9584,  1.9593, -0.0105,  4.9537,  1.9258,  2.9476, -4.9521, -1.9596])\n",
      "66 tensor(0.0131) tensor([ 1.9586,  1.9601, -0.0104,  4.9545,  1.9273,  2.9481, -4.9537, -1.9598])\n",
      "67 tensor(0.0120) tensor([ 1.9591,  1.9605, -0.0100,  4.9556,  1.9282,  2.9491, -4.9540, -1.9608])\n",
      "67 tensor(0.0110) tensor([ 1.9596,  1.9614, -0.0104,  4.9566,  1.9289,  2.9497, -4.9546, -1.9617])\n",
      "67 tensor(0.0133) tensor([ 1.9608,  1.9616, -0.0098,  4.9566,  1.9300,  2.9506, -4.9552, -1.9619])\n",
      "67 tensor(0.0116) tensor([ 1.9610,  1.9624, -0.0097,  4.9574,  1.9314,  2.9511, -4.9567, -1.9621])\n",
      "68 tensor(0.0107) tensor([ 1.9614,  1.9627, -0.0094,  4.9585,  1.9322,  2.9521, -4.9570, -1.9630])\n",
      "68 tensor(0.0097) tensor([ 1.9619,  1.9636, -0.0098,  4.9594,  1.9329,  2.9526, -4.9575, -1.9639])\n",
      "68 tensor(0.0118) tensor([ 1.9630,  1.9638, -0.0092,  4.9594,  1.9339,  2.9535, -4.9581, -1.9641])\n",
      "68 tensor(0.0103) tensor([ 1.9633,  1.9645, -0.0091,  4.9602,  1.9352,  2.9539, -4.9595, -1.9642])\n",
      "69 tensor(0.0094) tensor([ 1.9637,  1.9648, -0.0088,  4.9611,  1.9360,  2.9549, -4.9597, -1.9651])\n",
      "69 tensor(0.0086) tensor([ 1.9641,  1.9656, -0.0091,  4.9620,  1.9366,  2.9554, -4.9603, -1.9659])\n",
      "69 tensor(0.0104) tensor([ 1.9652,  1.9658, -0.0086,  4.9620,  1.9376,  2.9562, -4.9607, -1.9661])\n",
      "69 tensor(0.0091) tensor([ 1.9654,  1.9665, -0.0085,  4.9627,  1.9388,  2.9566, -4.9620, -1.9662])\n",
      "70 tensor(0.0084) tensor([ 1.9658,  1.9668, -0.0082,  4.9636,  1.9396,  2.9575, -4.9623, -1.9671])\n",
      "70 tensor(0.0077) tensor([ 1.9662,  1.9676, -0.0086,  4.9644,  1.9402,  2.9579, -4.9628, -1.9678])\n",
      "70 tensor(0.0092) tensor([ 1.9672,  1.9678, -0.0081,  4.9645,  1.9411,  2.9587, -4.9632, -1.9680])\n",
      "70 tensor(0.0081) tensor([ 1.9674,  1.9684, -0.0080,  4.9651,  1.9423,  2.9591, -4.9645, -1.9681])\n",
      "71 tensor(0.0074) tensor([ 1.9677,  1.9687, -0.0077,  4.9659,  1.9430,  2.9599, -4.9647, -1.9689])\n",
      "71 tensor(0.0068) tensor([ 1.9682,  1.9694, -0.0080,  4.9667,  1.9436,  2.9604, -4.9652, -1.9696])\n",
      "71 tensor(0.0082) tensor([ 1.9691,  1.9696, -0.0076,  4.9667,  1.9444,  2.9611, -4.9656, -1.9698])\n",
      "71 tensor(0.0072) tensor([ 1.9693,  1.9702, -0.0075,  4.9673,  1.9455,  2.9615, -4.9667, -1.9699])\n",
      "72 tensor(0.0066) tensor([ 1.9696,  1.9705, -0.0072,  4.9681,  1.9462,  2.9623, -4.9670, -1.9707])\n",
      "72 tensor(0.0060) tensor([ 1.9700,  1.9712, -0.0075,  4.9689,  1.9467,  2.9627, -4.9674, -1.9714])\n",
      "72 tensor(0.0072) tensor([ 1.9709,  1.9713, -0.0071,  4.9689,  1.9475,  2.9634, -4.9678, -1.9715])\n",
      "72 tensor(0.0063) tensor([ 1.9710,  1.9719, -0.0070,  4.9694,  1.9486,  2.9637, -4.9689, -1.9716])\n",
      "73 tensor(0.0058) tensor([ 1.9714,  1.9722, -0.0067,  4.9702,  1.9492,  2.9645, -4.9691, -1.9723])\n",
      "73 tensor(0.0054) tensor([ 1.9717,  1.9728, -0.0070,  4.9708,  1.9497,  2.9648, -4.9695, -1.9730])\n",
      "73 tensor(0.0064) tensor([ 1.9725,  1.9730, -0.0066,  4.9708,  1.9505,  2.9655, -4.9698, -1.9731])\n",
      "73 tensor(0.0056) tensor([ 1.9727,  1.9735, -0.0066,  4.9714,  1.9514,  2.9658, -4.9708, -1.9732])\n",
      "74 tensor(0.0052) tensor([ 1.9730,  1.9737, -0.0063,  4.9721,  1.9521,  2.9665, -4.9710, -1.9739])\n",
      "74 tensor(0.0047) tensor([ 1.9734,  1.9743, -0.0066,  4.9727,  1.9525,  2.9669, -4.9714, -1.9745])\n",
      "74 tensor(0.0057) tensor([ 1.9741,  1.9745, -0.0062,  4.9727,  1.9533,  2.9675, -4.9717, -1.9746])\n",
      "74 tensor(0.0050) tensor([ 1.9743,  1.9750, -0.0061,  4.9732,  1.9542,  2.9678, -4.9727, -1.9747])\n",
      "75 tensor(0.0046) tensor([ 1.9746,  1.9752, -0.0059,  4.9738,  1.9548,  2.9685, -4.9729, -1.9754])\n",
      "75 tensor(0.0042) tensor([ 1.9749,  1.9758, -0.0062,  4.9744,  1.9552,  2.9688, -4.9732, -1.9759])\n",
      "75 tensor(0.0050) tensor([ 1.9756,  1.9759, -0.0058,  4.9744,  1.9559,  2.9694, -4.9735, -1.9761])\n",
      "75 tensor(0.0044) tensor([ 1.9758,  1.9764, -0.0057,  4.9749,  1.9568,  2.9697, -4.9744, -1.9762])\n",
      "76 tensor(0.0041) tensor([ 1.9760,  1.9766, -0.0055,  4.9755,  1.9573,  2.9703, -4.9746, -1.9768])\n",
      "76 tensor(0.0037) tensor([ 1.9763,  1.9772, -0.0058,  4.9761,  1.9577,  2.9706, -4.9749, -1.9773])\n",
      "76 tensor(0.0044) tensor([ 1.9770,  1.9773, -0.0054,  4.9761,  1.9584,  2.9712, -4.9752, -1.9774])\n",
      "76 tensor(0.0039) tensor([ 1.9772,  1.9778, -0.0054,  4.9765,  1.9592,  2.9714, -4.9760, -1.9775])\n",
      "77 tensor(0.0036) tensor([ 1.9774,  1.9780, -0.0052,  4.9771,  1.9597,  2.9720, -4.9762, -1.9781])\n",
      "77 tensor(0.0033) tensor([ 1.9777,  1.9785, -0.0054,  4.9776,  1.9601,  2.9723, -4.9765, -1.9786])\n",
      "77 tensor(0.0039) tensor([ 1.9783,  1.9786, -0.0051,  4.9776,  1.9607,  2.9728, -4.9768, -1.9787])\n",
      "77 tensor(0.0035) tensor([ 1.9785,  1.9790, -0.0050,  4.9780,  1.9615,  2.9731, -4.9776, -1.9788])\n",
      "78 tensor(0.0032) tensor([ 1.9787e+00,  1.9792e+00, -4.8327e-03,  4.9785e+00,  1.9620e+00,\n",
      "         2.9736e+00, -4.9777e+00, -1.9793e+00])\n",
      "78 tensor(0.0029) tensor([ 1.9790,  1.9797, -0.0050,  4.9790,  1.9624,  2.9739, -4.9780, -1.9798])\n",
      "78 tensor(0.0035) tensor([ 1.9796e+00,  1.9798e+00, -4.7572e-03,  4.9790e+00,  1.9629e+00,\n",
      "         2.9744e+00, -4.9782e+00, -1.9799e+00])\n",
      "78 tensor(0.0031) tensor([ 1.9797e+00,  1.9802e+00, -4.7049e-03,  4.9794e+00,  1.9637e+00,\n",
      "         2.9746e+00, -4.9790e+00, -1.9800e+00])\n",
      "79 tensor(0.0028) tensor([ 1.9799e+00,  1.9804e+00, -4.5192e-03,  4.9799e+00,  1.9641e+00,\n",
      "         2.9752e+00, -4.9791e+00, -1.9805e+00])\n",
      "79 tensor(0.0026) tensor([ 1.9802e+00,  1.9809e+00, -4.7163e-03,  4.9803e+00,  1.9645e+00,\n",
      "         2.9754e+00, -4.9794e+00, -1.9809e+00])\n",
      "79 tensor(0.0031) tensor([ 1.9808e+00,  1.9810e+00, -4.4502e-03,  4.9803e+00,  1.9650e+00,\n",
      "         2.9759e+00, -4.9796e+00, -1.9810e+00])\n",
      "79 tensor(0.0027) tensor([ 1.9809e+00,  1.9814e+00, -4.4012e-03,  4.9807e+00,  1.9657e+00,\n",
      "         2.9761e+00, -4.9803e+00, -1.9811e+00])\n",
      "80 tensor(0.0025) tensor([ 1.9811e+00,  1.9815e+00, -4.2257e-03,  4.9811e+00,  1.9662e+00,\n",
      "         2.9766e+00, -4.9804e+00, -1.9816e+00])\n",
      "80 tensor(0.0023) tensor([ 1.9813e+00,  1.9819e+00, -4.4119e-03,  4.9816e+00,  1.9665e+00,\n",
      "         2.9768e+00, -4.9807e+00, -1.9820e+00])\n",
      "80 tensor(0.0027) tensor([ 1.9819e+00,  1.9821e+00, -4.1625e-03,  4.9816e+00,  1.9670e+00,\n",
      "         2.9773e+00, -4.9809e+00, -1.9821e+00])\n",
      "80 tensor(0.0024) tensor([ 1.9820e+00,  1.9824e+00, -4.1166e-03,  4.9819e+00,  1.9677e+00,\n",
      "         2.9775e+00, -4.9816e+00, -1.9822e+00])\n",
      "81 tensor(0.0022) tensor([ 1.9822e+00,  1.9826e+00, -3.9508e-03,  4.9823e+00,  1.9681e+00,\n",
      "         2.9779e+00, -4.9817e+00, -1.9826e+00])\n",
      "81 tensor(0.0021) tensor([ 1.9824e+00,  1.9830e+00, -4.1268e-03,  4.9827e+00,  1.9684e+00,\n",
      "         2.9782e+00, -4.9819e+00, -1.9830e+00])\n",
      "81 tensor(0.0024) tensor([ 1.9829e+00,  1.9831e+00, -3.8931e-03,  4.9827e+00,  1.9689e+00,\n",
      "         2.9786e+00, -4.9821e+00, -1.9831e+00])\n",
      "81 tensor(0.0021) tensor([ 1.9830e+00,  1.9834e+00, -3.8501e-03,  4.9830e+00,  1.9695e+00,\n",
      "         2.9788e+00, -4.9827e+00, -1.9832e+00])\n",
      "82 tensor(0.0020) tensor([ 1.9832e+00,  1.9836e+00, -3.6934e-03,  4.9834e+00,  1.9699e+00,\n",
      "         2.9792e+00, -4.9828e+00, -1.9836e+00])\n",
      "82 tensor(0.0018) tensor([ 1.9834e+00,  1.9839e+00, -3.8598e-03,  4.9838e+00,  1.9702e+00,\n",
      "         2.9795e+00, -4.9830e+00, -1.9840e+00])\n",
      "82 tensor(0.0021) tensor([ 1.9839e+00,  1.9840e+00, -3.6408e-03,  4.9838e+00,  1.9706e+00,\n",
      "         2.9798e+00, -4.9832e+00, -1.9841e+00])\n",
      "82 tensor(0.0019) tensor([ 1.9840e+00,  1.9844e+00, -3.6005e-03,  4.9841e+00,  1.9712e+00,\n",
      "         2.9800e+00, -4.9838e+00, -1.9842e+00])\n",
      "83 tensor(0.0017) tensor([ 1.9842e+00,  1.9845e+00, -3.4525e-03,  4.9845e+00,  1.9716e+00,\n",
      "         2.9804e+00, -4.9839e+00, -1.9846e+00])\n",
      "83 tensor(0.0016) tensor([ 1.9844e+00,  1.9849e+00, -3.6097e-03,  4.9848e+00,  1.9719e+00,\n",
      "         2.9806e+00, -4.9841e+00, -1.9849e+00])\n",
      "83 tensor(0.0019) tensor([ 1.9848e+00,  1.9849e+00, -3.4046e-03,  4.9848e+00,  1.9723e+00,\n",
      "         2.9810e+00, -4.9843e+00, -1.9850e+00])\n",
      "83 tensor(0.0017) tensor([ 1.9849e+00,  1.9852e+00, -3.3668e-03,  4.9851e+00,  1.9728e+00,\n",
      "         2.9812e+00, -4.9848e+00, -1.9851e+00])\n",
      "84 tensor(0.0015) tensor([ 1.9851e+00,  1.9854e+00, -3.2270e-03,  4.9855e+00,  1.9732e+00,\n",
      "         2.9816e+00, -4.9849e+00, -1.9854e+00])\n",
      "84 tensor(0.0014) tensor([ 1.9853e+00,  1.9857e+00, -3.3756e-03,  4.9858e+00,  1.9735e+00,\n",
      "         2.9818e+00, -4.9851e+00, -1.9858e+00])\n",
      "84 tensor(0.0017) tensor([ 1.9857e+00,  1.9858e+00, -3.1834e-03,  4.9858e+00,  1.9739e+00,\n",
      "         2.9821e+00, -4.9853e+00, -1.9859e+00])\n",
      "84 tensor(0.0015) tensor([ 1.9858e+00,  1.9861e+00, -3.1479e-03,  4.9860e+00,  1.9744e+00,\n",
      "         2.9823e+00, -4.9858e+00, -1.9859e+00])\n",
      "85 tensor(0.0014) tensor([ 1.9860e+00,  1.9862e+00, -3.0160e-03,  4.9864e+00,  1.9747e+00,\n",
      "         2.9826e+00, -4.9859e+00, -1.9863e+00])\n",
      "85 tensor(0.0013) tensor([ 1.9861e+00,  1.9865e+00, -3.1564e-03,  4.9867e+00,  1.9750e+00,\n",
      "         2.9828e+00, -4.9860e+00, -1.9866e+00])\n",
      "85 tensor(0.0015) tensor([ 1.9865e+00,  1.9866e+00, -2.9763e-03,  4.9867e+00,  1.9754e+00,\n",
      "         2.9831e+00, -4.9862e+00, -1.9867e+00])\n",
      "85 tensor(0.0013) tensor([ 1.9866e+00,  1.9869e+00, -2.9431e-03,  4.9869e+00,  1.9758e+00,\n",
      "         2.9833e+00, -4.9867e+00, -1.9867e+00])\n",
      "86 tensor(0.0012) tensor([ 1.9868e+00,  1.9870e+00, -2.8185e-03,  4.9872e+00,  1.9761e+00,\n",
      "         2.9836e+00, -4.9867e+00, -1.9870e+00])\n",
      "86 tensor(0.0011) tensor([ 1.9869e+00,  1.9873e+00, -2.9512e-03,  4.9875e+00,  1.9764e+00,\n",
      "         2.9838e+00, -4.9869e+00, -1.9873e+00])\n",
      "86 tensor(0.0013) tensor([ 1.9873e+00,  1.9874e+00, -2.7824e-03,  4.9875e+00,  1.9767e+00,\n",
      "         2.9841e+00, -4.9871e+00, -1.9874e+00])\n",
      "86 tensor(0.0012) tensor([ 1.9874e+00,  1.9876e+00, -2.7513e-03,  4.9877e+00,  1.9772e+00,\n",
      "         2.9843e+00, -4.9875e+00, -1.9875e+00])\n",
      "87 tensor(0.0011) tensor([ 1.9875e+00,  1.9877e+00, -2.6338e-03,  4.9880e+00,  1.9775e+00,\n",
      "         2.9846e+00, -4.9876e+00, -1.9878e+00])\n",
      "87 tensor(0.0010) tensor([ 1.9877e+00,  1.9880e+00, -2.7591e-03,  4.9883e+00,  1.9777e+00,\n",
      "         2.9847e+00, -4.9877e+00, -1.9881e+00])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 tensor(0.0012) tensor([ 1.9881e+00,  1.9881e+00, -2.6010e-03,  4.9883e+00,  1.9781e+00,\n",
      "         2.9850e+00, -4.9879e+00, -1.9881e+00])\n",
      "87 tensor(0.0010) tensor([ 1.9881e+00,  1.9883e+00, -2.5719e-03,  4.9885e+00,  1.9785e+00,\n",
      "         2.9852e+00, -4.9883e+00, -1.9882e+00])\n",
      "88 tensor(0.0010) tensor([ 1.9883e+00,  1.9884e+00, -2.4609e-03,  4.9888e+00,  1.9788e+00,\n",
      "         2.9855e+00, -4.9883e+00, -1.9885e+00])\n",
      "88 tensor(0.0009) tensor([ 1.9884e+00,  1.9887e+00, -2.5794e-03,  4.9890e+00,  1.9790e+00,\n",
      "         2.9856e+00, -4.9885e+00, -1.9887e+00])\n",
      "88 tensor(0.0010) tensor([ 1.9887e+00,  1.9888e+00, -2.4311e-03,  4.9890e+00,  1.9793e+00,\n",
      "         2.9859e+00, -4.9886e+00, -1.9888e+00])\n",
      "88 tensor(0.0009) tensor([ 1.9888e+00,  1.9890e+00, -2.4039e-03,  4.9892e+00,  1.9797e+00,\n",
      "         2.9860e+00, -4.9890e+00, -1.9888e+00])\n",
      "89 tensor(0.0008) tensor([ 1.9889e+00,  1.9891e+00, -2.2992e-03,  4.9895e+00,  1.9800e+00,\n",
      "         2.9863e+00, -4.9891e+00, -1.9891e+00])\n",
      "89 tensor(0.0008) tensor([ 1.9891e+00,  1.9893e+00, -2.4112e-03,  4.9897e+00,  1.9802e+00,\n",
      "         2.9865e+00, -4.9892e+00, -1.9894e+00])\n",
      "89 tensor(0.0009) tensor([ 1.9894e+00,  1.9894e+00, -2.2722e-03,  4.9897e+00,  1.9805e+00,\n",
      "         2.9867e+00, -4.9893e+00, -1.9894e+00])\n",
      "89 tensor(0.0008) tensor([ 1.9895e+00,  1.9896e+00, -2.2467e-03,  4.9899e+00,  1.9809e+00,\n",
      "         2.9868e+00, -4.9897e+00, -1.9895e+00])\n",
      "90 tensor(0.0008) tensor([ 1.9896e+00,  1.9897e+00, -2.1479e-03,  4.9901e+00,  1.9811e+00,\n",
      "         2.9871e+00, -4.9898e+00, -1.9897e+00])\n",
      "90 tensor(0.0007) tensor([ 1.9897e+00,  1.9900e+00, -2.2538e-03,  4.9904e+00,  1.9813e+00,\n",
      "         2.9872e+00, -4.9899e+00, -1.9900e+00])\n",
      "90 tensor(0.0008) tensor([ 1.9900e+00,  1.9900e+00, -2.1236e-03,  4.9903e+00,  1.9816e+00,\n",
      "         2.9875e+00, -4.9900e+00, -1.9900e+00])\n",
      "90 tensor(0.0007) tensor([ 1.9901e+00,  1.9902e+00, -2.0997e-03,  4.9905e+00,  1.9819e+00,\n",
      "         2.9876e+00, -4.9903e+00, -1.9901e+00])\n",
      "91 tensor(0.0007) tensor([ 1.9902e+00,  1.9903e+00, -2.0065e-03,  4.9907e+00,  1.9822e+00,\n",
      "         2.9879e+00, -4.9904e+00, -1.9903e+00])\n",
      "91 tensor(0.0006) tensor([ 1.9903e+00,  1.9905e+00, -2.1065e-03,  4.9910e+00,  1.9824e+00,\n",
      "         2.9880e+00, -4.9905e+00, -1.9906e+00])\n",
      "91 tensor(0.0007) tensor([ 1.9906e+00,  1.9906e+00, -1.9845e-03,  4.9909e+00,  1.9826e+00,\n",
      "         2.9882e+00, -4.9906e+00, -1.9906e+00])\n",
      "91 tensor(0.0006) tensor([ 1.9906e+00,  1.9908e+00, -1.9621e-03,  4.9911e+00,  1.9830e+00,\n",
      "         2.9883e+00, -4.9909e+00, -1.9906e+00])\n",
      "92 tensor(0.0006) tensor([ 1.9908e+00,  1.9909e+00, -1.8742e-03,  4.9913e+00,  1.9832e+00,\n",
      "         2.9886e+00, -4.9910e+00, -1.9909e+00])\n",
      "92 tensor(0.0006) tensor([ 1.9909e+00,  1.9911e+00, -1.9687e-03,  4.9915e+00,  1.9834e+00,\n",
      "         2.9887e+00, -4.9911e+00, -1.9911e+00])\n",
      "92 tensor(0.0006) tensor([ 1.9911e+00,  1.9911e+00, -1.8543e-03,  4.9915e+00,  1.9836e+00,\n",
      "         2.9889e+00, -4.9912e+00, -1.9911e+00])\n",
      "92 tensor(0.0006) tensor([ 1.9912e+00,  1.9913e+00, -1.8334e-03,  4.9917e+00,  1.9839e+00,\n",
      "         2.9890e+00, -4.9915e+00, -1.9912e+00])\n",
      "93 tensor(0.0005) tensor([ 1.9913e+00,  1.9914e+00, -1.7505e-03,  4.9919e+00,  1.9842e+00,\n",
      "         2.9892e+00, -4.9916e+00, -1.9914e+00])\n",
      "93 tensor(0.0005) tensor([ 1.9914e+00,  1.9916e+00, -1.8399e-03,  4.9920e+00,  1.9843e+00,\n",
      "         2.9893e+00, -4.9917e+00, -1.9916e+00])\n",
      "93 tensor(0.0006) tensor([ 1.9916e+00,  1.9916e+00, -1.7326e-03,  4.9920e+00,  1.9846e+00,\n",
      "         2.9895e+00, -4.9918e+00, -1.9917e+00])\n",
      "93 tensor(0.0005) tensor([ 1.9917e+00,  1.9918e+00, -1.7130e-03,  4.9922e+00,  1.9849e+00,\n",
      "         2.9896e+00, -4.9920e+00, -1.9917e+00])\n",
      "94 tensor(0.0005) tensor([ 1.9918e+00,  1.9919e+00, -1.6349e-03,  4.9924e+00,  1.9851e+00,\n",
      "         2.9898e+00, -4.9921e+00, -1.9919e+00])\n",
      "94 tensor(0.0004) tensor([ 1.9919e+00,  1.9921e+00, -1.7193e-03,  4.9925e+00,  1.9852e+00,\n",
      "         2.9899e+00, -4.9922e+00, -1.9921e+00])\n",
      "94 tensor(0.0005) tensor([ 1.9921e+00,  1.9921e+00, -1.6188e-03,  4.9925e+00,  1.9854e+00,\n",
      "         2.9901e+00, -4.9923e+00, -1.9921e+00])\n",
      "94 tensor(0.0004) tensor([ 1.9922e+00,  1.9923e+00, -1.6005e-03,  4.9927e+00,  1.9857e+00,\n",
      "         2.9902e+00, -4.9925e+00, -1.9922e+00])\n",
      "95 tensor(0.0004) tensor([ 1.9923e+00,  1.9923e+00, -1.5268e-03,  4.9928e+00,  1.9859e+00,\n",
      "         2.9904e+00, -4.9926e+00, -1.9924e+00])\n",
      "95 tensor(0.0004) tensor([ 1.9924e+00,  1.9925e+00, -1.6066e-03,  4.9930e+00,  1.9861e+00,\n",
      "         2.9905e+00, -4.9927e+00, -1.9925e+00])\n",
      "95 tensor(0.0004) tensor([ 1.9926e+00,  1.9926e+00, -1.5123e-03,  4.9930e+00,  1.9863e+00,\n",
      "         2.9907e+00, -4.9927e+00, -1.9926e+00])\n",
      "95 tensor(0.0004) tensor([ 1.9926e+00,  1.9927e+00, -1.4952e-03,  4.9931e+00,  1.9865e+00,\n",
      "         2.9908e+00, -4.9930e+00, -1.9926e+00])\n",
      "96 tensor(0.0004) tensor([ 1.9927e+00,  1.9928e+00, -1.4257e-03,  4.9933e+00,  1.9867e+00,\n",
      "         2.9910e+00, -4.9930e+00, -1.9928e+00])\n",
      "96 tensor(0.0003) tensor([ 1.9928e+00,  1.9929e+00, -1.5012e-03,  4.9934e+00,  1.9868e+00,\n",
      "         2.9911e+00, -4.9931e+00, -1.9930e+00])\n",
      "96 tensor(0.0004) tensor([ 1.9930e+00,  1.9930e+00, -1.4128e-03,  4.9934e+00,  1.9871e+00,\n",
      "         2.9912e+00, -4.9932e+00, -1.9930e+00])\n",
      "96 tensor(0.0004) tensor([ 1.9931e+00,  1.9931e+00, -1.3967e-03,  4.9935e+00,  1.9873e+00,\n",
      "         2.9913e+00, -4.9934e+00, -1.9930e+00])\n",
      "97 tensor(0.0003) tensor([ 1.9931e+00,  1.9932e+00, -1.3313e-03,  4.9937e+00,  1.9875e+00,\n",
      "         2.9915e+00, -4.9935e+00, -1.9932e+00])\n",
      "97 tensor(0.0003) tensor([ 1.9932e+00,  1.9933e+00, -1.4026e-03,  4.9938e+00,  1.9876e+00,\n",
      "         2.9916e+00, -4.9935e+00, -1.9934e+00])\n",
      "97 tensor(0.0003) tensor([ 1.9934e+00,  1.9934e+00, -1.3197e-03,  4.9938e+00,  1.9878e+00,\n",
      "         2.9918e+00, -4.9936e+00, -1.9934e+00])\n",
      "97 tensor(0.0003) tensor([ 1.9935e+00,  1.9935e+00, -1.3047e-03,  4.9939e+00,  1.9880e+00,\n",
      "         2.9918e+00, -4.9938e+00, -1.9934e+00])\n",
      "98 tensor(0.0003) tensor([ 1.9935e+00,  1.9936e+00, -1.2430e-03,  4.9941e+00,  1.9882e+00,\n",
      "         2.9920e+00, -4.9939e+00, -1.9936e+00])\n",
      "98 tensor(0.0003) tensor([ 1.9936e+00,  1.9937e+00, -1.3104e-03,  4.9942e+00,  1.9883e+00,\n",
      "         2.9921e+00, -4.9939e+00, -1.9937e+00])\n",
      "98 tensor(0.0003) tensor([ 1.9938e+00,  1.9938e+00, -1.2326e-03,  4.9942e+00,  1.9885e+00,\n",
      "         2.9922e+00, -4.9940e+00, -1.9938e+00])\n",
      "98 tensor(0.0003) tensor([ 1.9938e+00,  1.9939e+00, -1.2186e-03,  4.9943e+00,  1.9887e+00,\n",
      "         2.9923e+00, -4.9942e+00, -1.9938e+00])\n",
      "99 tensor(0.0003) tensor([ 1.9939e+00,  1.9939e+00, -1.1605e-03,  4.9944e+00,  1.9889e+00,\n",
      "         2.9925e+00, -4.9942e+00, -1.9940e+00])\n",
      "99 tensor(0.0002) tensor([ 1.9940e+00,  1.9941e+00, -1.2242e-03,  4.9946e+00,  1.9890e+00,\n",
      "         2.9925e+00, -4.9943e+00, -1.9941e+00])\n",
      "99 tensor(0.0003) tensor([ 1.9942e+00,  1.9941e+00, -1.1513e-03,  4.9946e+00,  1.9891e+00,\n",
      "         2.9927e+00, -4.9944e+00, -1.9941e+00])\n",
      "99 tensor(0.0002) tensor([ 1.9942e+00,  1.9942e+00, -1.1382e-03,  4.9947e+00,  1.9894e+00,\n",
      "         2.9927e+00, -4.9946e+00, -1.9942e+00])\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "dataloader = DataLoader(MyDataset(datapoints[19][\"features\"], datapoints[19][\"label\"]), batch_size=50, shuffle=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    for (x, y) in dataloader:\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "\n",
    "        loss = criterion(yhat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        print(i, loss.detach(), parameters_to_vector(model.parameters()).detach())\n",
    "        #optimizer.step()\n",
    "        new_model = parameters_to_vector(model.parameters()) - lr * grads_to_vector(model.parameters())\n",
    "        vector_to_parameters(parameters=model.parameters(), vec=new_model)\n",
    "        #if i % 50 ==0:\n",
    "            #lr *= 0.9\n",
    "            \n",
    "\n",
    "#parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb22da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9943e+00,  1.9943e+00, -1.0834e-03,  4.9948e+00,  1.9895e+00,\n",
       "         2.9929e+00, -4.9946e+00, -1.9943e+00], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52396ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb5fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, alpha, lamda, epochs, projection_list, projected_weights):\n",
    "        self.train_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=batchSize, shuffle=True)\n",
    "        #self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def train(self, model):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5)\n",
    "\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for i, (data, labels) in zip(range(1), self.train_loader):\n",
    "                data, labels = data, labels\n",
    "                optimizer.zero_grad() \n",
    "                output = model(data)  \n",
    "                loss = criterion(output, labels)\n",
    "                #loss += mu/2 * torch.norm(client_param.data - server_param.data)**2\n",
    "                loss.backward()\n",
    "                grads = grads_to_vector(model.parameters())\n",
    "                #optimizer.step()\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                weights = parameters_to_vector(model.parameters())\n",
    "                mat_vec_sum = torch.zeros_like(weights)\n",
    "                for j in G.neighbors(model.user_id):\n",
    "                    mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(torch.transpose(projection_list[model.user_id][j], 0, 1), \n",
    "                                                         projected_weights[j][model.user_id] - projected_weights[model.user_id][j]))\n",
    "                \n",
    "                model_update = parameters_to_vector(model.parameters()) - alpha * (grads + lamda * mat_vec_sum)\n",
    "                \n",
    "            vector_to_parameters(parameters=model.parameters(), vec=model_update)\n",
    "                \n",
    "\n",
    "            train_loss = train_loss/self.batchSize#len(self.train_loader.dataset) \n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "        total_loss = e_loss#sum(e_loss)/len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2eeef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing projection matrices\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "#temp = MLP_Net()\n",
    "projection_list = []\n",
    "projected_weights = []\n",
    "\n",
    "def update_ProjWeight(projection_list, projected_weights, models, first_run=True):\n",
    "    for i in range(no_users):\n",
    "        neighbors_mat = []\n",
    "        neighbors_weights = []\n",
    "        for j in range(no_users):\n",
    "            if j in G.neighbors(i):\n",
    "                with torch.no_grad():\n",
    "                    if first_run == True:\n",
    "                        row, column = d0, parameters_to_vector(models[i].parameters()).size()[0]\n",
    "                        mat = torch.zeros((row, column))\n",
    "                        \n",
    "                        # Generate random values from a normal distribution for the diagonal\n",
    "                        diag_values = 1.0 + 1.0 * torch.randn(row)\n",
    "\n",
    "                        # Create a diagonal matrix with random values\n",
    "                        mat = torch.diag(diag_values)\n",
    "                        \n",
    "                        neighbors_mat.append(mat)\n",
    "                        neighbors_weights.append(torch.matmul(mat, parameters_to_vector(models[i].parameters())))\n",
    "                    else:\n",
    "                        neighbors_weights.append(torch.matmul(projection_list[i][j], parameters_to_vector(models[i].parameters())))\n",
    "            else:\n",
    "                neighbors_mat.append(0)\n",
    "                neighbors_weights.append(0)\n",
    "        if first_run == True:\n",
    "            projection_list.append(neighbors_mat)\n",
    "        projected_weights.append(neighbors_weights)\n",
    "\n",
    "update_ProjWeight(projection_list, projected_weights, models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "722653ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, tensor([[ 2.9217,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.7406,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.3727,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0376,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9716,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0785,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.8234,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0488]]), 0, tensor([[ 2.4993,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.5665,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.3929,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.5409,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  3.0847,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.5212,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.8441]]), 0, 0, tensor([[-0.0570,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.2701,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.9254,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  2.5247,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  2.2072,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.3762,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.7722,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9763]]), tensor([[ 0.3590,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.3208,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.5643,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.5196,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.6319,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3197,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.0343,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4592]]), tensor([[ 0.2606,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.7650,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.6124,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.9877,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.3778,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2576,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8508,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5573]]), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(projection_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f6059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion): \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data, labels\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        #_, pred = torch.max(output, 1)\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f172f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(model):\n",
    "    return (torch.norm(parameters_to_vector(model.parameters()) - datapoints[model.user_id]['exact_weights']) / torch.norm(datapoints[model.user_id]['exact_weights'])).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e38148f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6603, dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(datapoints[model.user_id]['exact_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d1a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0952, -0.3215, -0.2745, -0.0331,  0.1014,  0.0049,  0.3437, -0.3522])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1904, -0.6431, -0.5490, -0.0662,  0.2029,  0.0098,  0.6874, -0.7043],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "with torch.no_grad():    \n",
    "    params = parameters_to_vector(model.parameters())\n",
    "\n",
    "    print(params)\n",
    "\n",
    "params *= 2.\n",
    "\n",
    "vector_to_parameters(parameters=model.parameters(), vec=params)\n",
    "\n",
    "parameters_to_vector(model.parameters())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71472693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:00<00:21,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 57.55137,   Relative Error 0.95083\n",
      "Training_loss 56.42604,   Relative Error 0.94203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:22,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 53.99686,   Relative Error 0.92218\n",
      "Training_loss 52.94161,   Relative Error 0.91279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:00<00:21,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 51.54682,   Relative Error 0.90185\n",
      "Training_loss 49.29687,   Relative Error 0.88260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:00<00:22,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 48.00951,   Relative Error 0.87076\n",
      "Training_loss 46.68472,   Relative Error 0.85941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:01<00:22,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 43.88747,   Relative Error 0.83429\n",
      "Training_loss 42.22898,   Relative Error 0.81770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:01<00:22,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 40.93532,   Relative Error 0.80510\n",
      "Training_loss 39.96024,   Relative Error 0.79585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:01<00:22,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 38.79027,   Relative Error 0.78397\n",
      "Training_loss 37.86939,   Relative Error 0.77522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:01<00:21,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 36.05740,   Relative Error 0.75703\n",
      "Training_loss 34.93983,   Relative Error 0.74618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:02<00:21,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 33.42794,   Relative Error 0.73073\n",
      "Training_loss 32.12336,   Relative Error 0.71699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:02<00:21,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 31.00620,   Relative Error 0.70465\n",
      "Training_loss 29.51133,   Relative Error 0.68857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:02<00:21,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 28.69645,   Relative Error 0.67900\n",
      "Training_loss 27.85218,   Relative Error 0.66883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:02<00:22,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 27.32808,   Relative Error 0.66298\n",
      "Training_loss 25.90296,   Relative Error 0.64638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:03<00:21,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 25.04710,   Relative Error 0.63537\n",
      "Training_loss 24.37683,   Relative Error 0.62714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [00:03<00:21,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 23.52145,   Relative Error 0.61624\n",
      "Training_loss 23.25799,   Relative Error 0.61249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [00:03<00:23,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 22.11505,   Relative Error 0.59856\n",
      "Training_loss 21.26139,   Relative Error 0.58751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 31/200 [00:03<00:25,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 20.48802,   Relative Error 0.57720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 32/200 [00:04<00:28,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 19.81833,   Relative Error 0.56777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 33/200 [00:04<00:32,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 19.23632,   Relative Error 0.55908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 34/200 [00:04<00:36,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 18.47148,   Relative Error 0.54875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/200 [00:04<00:39,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 17.94512,   Relative Error 0.54071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 36/200 [00:05<00:45,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 17.59059,   Relative Error 0.53492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 37/200 [00:05<00:47,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 16.99384,   Relative Error 0.52624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [00:06<00:40,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 16.35308,   Relative Error 0.51639\n",
      "Training_loss 15.82757,   Relative Error 0.50754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:06<00:33,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 15.54946,   Relative Error 0.50295\n",
      "Training_loss 15.22170,   Relative Error 0.49778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [00:06<00:32,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 14.75654,   Relative Error 0.49037\n",
      "Training_loss 14.34031,   Relative Error 0.48369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [00:07<00:29,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 13.77390,   Relative Error 0.47432\n",
      "Training_loss 13.23176,   Relative Error 0.46548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:07<00:24,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 12.94117,   Relative Error 0.46015\n",
      "Training_loss 12.45887,   Relative Error 0.45203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [00:07<00:25,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 12.06679,   Relative Error 0.44496\n",
      "Training_loss 11.73654,   Relative Error 0.43914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 50/200 [00:07<00:26,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 11.33924,   Relative Error 0.43199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 51/200 [00:08<00:28,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 11.05507,   Relative Error 0.42603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 52/200 [00:08<00:29,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 10.80338,   Relative Error 0.42118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 53/200 [00:08<00:30,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 10.45766,   Relative Error 0.41458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 54/200 [00:08<00:31,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 10.16816,   Relative Error 0.40889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/200 [00:09<00:34,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 9.85639,   Relative Error 0.40281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [00:09<00:31,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 9.41173,   Relative Error 0.39387\n",
      "Training_loss 9.14333,   Relative Error 0.38858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [00:09<00:25,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.81589,   Relative Error 0.38184\n",
      "Training_loss 8.59345,   Relative Error 0.37681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [00:10<00:21,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.31480,   Relative Error 0.37076\n",
      "Training_loss 7.92500,   Relative Error 0.36248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [00:10<00:19,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.69268,   Relative Error 0.35738\n",
      "Training_loss 7.34698,   Relative Error 0.34936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [00:10<00:19,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.07583,   Relative Error 0.34286\n",
      "Training_loss 6.81865,   Relative Error 0.33682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [00:10<00:19,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.68092,   Relative Error 0.33349\n",
      "Training_loss 6.48059,   Relative Error 0.32861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [00:11<00:18,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.30775,   Relative Error 0.32415\n",
      "Training_loss 6.14800,   Relative Error 0.32034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [00:11<00:16,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.98823,   Relative Error 0.31633\n",
      "Training_loss 5.66655,   Relative Error 0.30802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [00:11<00:15,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.43725,   Relative Error 0.30195\n",
      "Training_loss 5.21467,   Relative Error 0.29596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [00:11<00:15,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.06314,   Relative Error 0.29173\n",
      "Training_loss 4.89488,   Relative Error 0.28700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [00:12<00:14,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.72920,   Relative Error 0.28241\n",
      "Training_loss 4.56849,   Relative Error 0.27776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [00:12<00:14,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.36153,   Relative Error 0.27148\n",
      "Training_loss 4.20338,   Relative Error 0.26678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [00:12<00:14,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.99527,   Relative Error 0.26035\n",
      "Training_loss 3.78666,   Relative Error 0.25359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [00:12<00:14,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.65124,   Relative Error 0.24921\n",
      "Training_loss 3.54974,   Relative Error 0.24578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [00:13<00:14,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.42324,   Relative Error 0.24138\n",
      "Training_loss 3.28114,   Relative Error 0.23651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [00:13<00:13,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.17014,   Relative Error 0.23232\n",
      "Training_loss 3.09527,   Relative Error 0.22961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [00:13<00:14,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.01794,   Relative Error 0.22671\n",
      "Training_loss 2.96129,   Relative Error 0.22437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [00:13<00:15,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.87347,   Relative Error 0.22119\n",
      "Training_loss 2.78711,   Relative Error 0.21791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [00:14<00:16,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.70106,   Relative Error 0.21463\n",
      "Training_loss 2.66782,   Relative Error 0.21332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [00:14<00:18,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.60408,   Relative Error 0.21086\n",
      "Training_loss 2.51983,   Relative Error 0.20757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 96/200 [00:14<00:19,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.45910,   Relative Error 0.20498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 97/200 [00:15<00:20,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.38566,   Relative Error 0.20202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [00:15<00:20,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.29144,   Relative Error 0.19820\n",
      "Training_loss 2.23844,   Relative Error 0.19587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [00:15<00:17,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.15914,   Relative Error 0.19230\n",
      "Training_loss 2.06926,   Relative Error 0.18831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [00:16<00:16,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.03196,   Relative Error 0.18676\n",
      "Training_loss 1.96474,   Relative Error 0.18371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [00:16<00:14,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.90073,   Relative Error 0.18067\n",
      "Training_loss 1.83411,   Relative Error 0.17761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [00:16<00:13,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.75884,   Relative Error 0.17384\n",
      "Training_loss 1.68413,   Relative Error 0.17017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [00:17<00:14,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.63410,   Relative Error 0.16756\n",
      "Training_loss 1.58003,   Relative Error 0.16471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [00:17<00:13,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.53832,   Relative Error 0.16251\n",
      "Training_loss 1.50270,   Relative Error 0.16061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 113/200 [00:17<00:13,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.45345,   Relative Error 0.15789\n",
      "Training_loss 1.39923,   Relative Error 0.15505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 115/200 [00:17<00:12,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.33222,   Relative Error 0.15130\n",
      "Training_loss 1.28343,   Relative Error 0.14860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 117/200 [00:18<00:12,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.23090,   Relative Error 0.14550\n",
      "Training_loss 1.19650,   Relative Error 0.14344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119/200 [00:18<00:11,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.15732,   Relative Error 0.14115\n",
      "Training_loss 1.12275,   Relative Error 0.13901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [00:18<00:10,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.07439,   Relative Error 0.13605\n",
      "Training_loss 1.03383,   Relative Error 0.13352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 123/200 [00:19<00:10,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.01520,   Relative Error 0.13236\n",
      "Training_loss 0.98124,   Relative Error 0.13019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 125/200 [00:19<00:10,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.95288,   Relative Error 0.12834\n",
      "Training_loss 0.90978,   Relative Error 0.12550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [00:19<00:09,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.88541,   Relative Error 0.12382\n",
      "Training_loss 0.84413,   Relative Error 0.12093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 129/200 [00:19<00:09,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.80639,   Relative Error 0.11822\n",
      "Training_loss 0.77116,   Relative Error 0.11567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [00:20<00:08,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.75275,   Relative Error 0.11434\n",
      "Training_loss 0.72722,   Relative Error 0.11239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 133/200 [00:20<00:08,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.70837,   Relative Error 0.11097\n",
      "Training_loss 0.68616,   Relative Error 0.10931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 135/200 [00:20<00:08,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65773,   Relative Error 0.10702\n",
      "Training_loss 0.64433,   Relative Error 0.10590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 137/200 [00:20<00:07,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.62784,   Relative Error 0.10454\n",
      "Training_loss 0.59977,   Relative Error 0.10225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 139/200 [00:21<00:07,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.58283,   Relative Error 0.10085\n",
      "Training_loss 0.56538,   Relative Error 0.09929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [00:21<00:07,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54539,   Relative Error 0.09752\n",
      "Training_loss 0.53408,   Relative Error 0.09652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 143/200 [00:21<00:07,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52248,   Relative Error 0.09552\n",
      "Training_loss 0.50383,   Relative Error 0.09373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 145/200 [00:21<00:07,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48705,   Relative Error 0.09220\n",
      "Training_loss 0.47204,   Relative Error 0.09074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 147/200 [00:22<00:07,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45111,   Relative Error 0.08871\n",
      "Training_loss 0.43368,   Relative Error 0.08702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 149/200 [00:22<00:07,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41685,   Relative Error 0.08534\n",
      "Training_loss 0.40705,   Relative Error 0.08435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151/200 [00:22<00:06,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39313,   Relative Error 0.08289\n",
      "Training_loss 0.37950,   Relative Error 0.08143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 153/200 [00:22<00:06,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36522,   Relative Error 0.07985\n",
      "Training_loss 0.35359,   Relative Error 0.07858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [00:23<00:06,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34035,   Relative Error 0.07715\n",
      "Training_loss 0.33095,   Relative Error 0.07611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [00:23<00:05,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32321,   Relative Error 0.07526\n",
      "Training_loss 0.31199,   Relative Error 0.07395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159/200 [00:23<00:05,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29807,   Relative Error 0.07226\n",
      "Training_loss 0.29123,   Relative Error 0.07141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [00:24<00:05,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28064,   Relative Error 0.07011\n",
      "Training_loss 0.26906,   Relative Error 0.06869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163/200 [00:24<00:05,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26177,   Relative Error 0.06778\n",
      "Training_loss 0.25544,   Relative Error 0.06697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 165/200 [00:24<00:04,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24583,   Relative Error 0.06572\n",
      "Training_loss 0.23919,   Relative Error 0.06485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 167/200 [00:24<00:04,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.22800,   Relative Error 0.06333\n",
      "Training_loss 0.22043,   Relative Error 0.06231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 169/200 [00:25<00:04,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.20682,   Relative Error 0.06034\n",
      "Training_loss 0.20213,   Relative Error 0.05966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [00:25<00:04,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.19700,   Relative Error 0.05889\n",
      "Training_loss 0.19291,   Relative Error 0.05827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 173/200 [00:25<00:03,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.18334,   Relative Error 0.05680\n",
      "Training_loss 0.17593,   Relative Error 0.05563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 175/200 [00:26<00:03,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.17254,   Relative Error 0.05510\n",
      "Training_loss 0.16562,   Relative Error 0.05397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/200 [00:26<00:03,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.15994,   Relative Error 0.05304\n",
      "Training_loss 0.15647,   Relative Error 0.05244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 179/200 [00:26<00:02,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.15213,   Relative Error 0.05173\n",
      "Training_loss 0.14591,   Relative Error 0.05068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [00:26<00:02,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.13981,   Relative Error 0.04961\n",
      "Training_loss 0.13692,   Relative Error 0.04908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183/200 [00:27<00:02,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.13390,   Relative Error 0.04853\n",
      "Training_loss 0.12991,   Relative Error 0.04780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 185/200 [00:27<00:02,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.12677,   Relative Error 0.04724\n",
      "Training_loss 0.12318,   Relative Error 0.04655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 187/200 [00:27<00:01,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.11999,   Relative Error 0.04595\n",
      "Training_loss 0.11665,   Relative Error 0.04530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 189/200 [00:28<00:01,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.11143,   Relative Error 0.04425\n",
      "Training_loss 0.10570,   Relative Error 0.04309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 191/200 [00:28<00:01,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.10295,   Relative Error 0.04252\n",
      "Training_loss 0.09946,   Relative Error 0.04180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 193/200 [00:28<00:01,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.09436,   Relative Error 0.04071\n",
      "Training_loss 0.09075,   Relative Error 0.03993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 195/200 [00:28<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.08853,   Relative Error 0.03945\n",
      "Training_loss 0.08621,   Relative Error 0.03893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 197/200 [00:29<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.08284,   Relative Error 0.03816\n",
      "Training_loss 0.08022,   Relative Error 0.03759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199/200 [00:29<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.07695,   Relative Error 0.03682\n",
      "Training_loss 0.07425,   Relative Error 0.03620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:29<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.07176,   Relative Error 0.03557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#global_model = CNN_Net().cuda()\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "dummy_models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "\n",
    "#model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "total_rel_error = []\n",
    "\n",
    "for curr_round in tqdm(range(1, it+1)):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        dummy_models[i].load_state_dict(models[i].state_dict())\n",
    "        local_update = ClientUpdate(dataset=datapoints[i], batchSize=batch_size, alpha=alpha, lamda=lamda, epochs=1, projection_list=projection_list, projected_weights=projected_weights)\n",
    "        weights, loss = local_update.train(dummy_models[i])\n",
    "        w.append(weights)\n",
    "        local_loss.append(loss)\n",
    "        models[i].load_state_dict(w[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Update prjection matrix\n",
    "    projected_weights = []\n",
    "    update_ProjWeight(projection_list, projected_weights, models, first_run=False)\n",
    "    \n",
    "    #print(projection_list[0], projected_weights[0])\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        weights = parameters_to_vector(models[i].parameters())\n",
    "        for j in G.neighbors(i):\n",
    "            temp_mat = torch.outer(projected_weights[i][j] - projected_weights[j][i], weights).clone()\n",
    "            projection_list[i][j] = torch.add(projection_list[i][j], -1 * eta * lamda * temp_mat)\n",
    "                                         \n",
    "                                              \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "\n",
    "    local_test_acc = []\n",
    "    local_test_loss = []\n",
    "    user_rel_error = 0\n",
    "    for k in range(no_users):\n",
    "      \n",
    "        g_loss = testing(models[i], datapoints[i], 50, criterion)\n",
    "        local_test_loss.append(g_loss)\n",
    "        user_rel_error += rel_error(models[i])\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    g_loss = sum(local_test_loss) / len(local_test_loss)\n",
    "    total_rel_error.append(user_rel_error / no_users)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_loss.append(g_loss)\n",
    "    #test_accuracy.append(g_accuracy)\n",
    "    print(\"Training_loss %2.5f,   Relative Error %2.5f\"% (test_loss[-1], total_rel_error[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ff0ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9324e+00,  1.9037e+00,  3.5253e-03,  4.8826e+00,  1.8235e+00,\n",
      "         2.8820e+00, -4.8826e+00, -1.9083e+00], grad_fn=<CatBackward0>) [ 2.  2.  0.  5.  2.  3. -5. -2.]\n"
     ]
    }
   ],
   "source": [
    "#plot.plot(test_loss)\n",
    "print(parameters_to_vector(models[19].parameters()), W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea69c3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "7\n",
      "15\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in G.neighbors(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf702d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3668, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(projection_list[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "449050cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0908, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(projection_list[3][17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a73e6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " tensor([ 5.2790e+00, -2.5029e-01,  9.1683e-03,  7.0979e+00,  3.6382e-01,\n",
       "         -1.9726e+00,  1.0874e+01,  2.9370e-01]),\n",
       " tensor([ 2.9348e+00, -2.2912e-01, -7.7133e-03,  1.8830e+00, -5.2439e+00,\n",
       "          1.0127e-01,  8.6279e+00, -6.4575e-01]),\n",
       " tensor([ 1.9854, -1.1935,  0.0217, -4.1667,  0.0568, -1.3243,  7.5671,  0.6386]),\n",
       " 0,\n",
       " tensor([ 4.3646e+00,  1.7972e-01,  6.4962e-03,  7.7013e+00,  6.3390e-01,\n",
       "         -2.0343e+00,  8.8277e+00,  4.0564e+00]),\n",
       " 0,\n",
       " tensor([ 3.2554e+00,  6.8024e-01,  3.4622e-03,  3.0119e+00, -4.5969e+00,\n",
       "         -5.8841e+00, -3.4314e+00,  6.2406e-01]),\n",
       " tensor([ 5.9126,  3.1070,  0.0465,  9.8781, -1.5906, -0.4128,  3.7419,  2.8448]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2561d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = np.array(test_loss)\n",
    "total_rel_error = np.array(total_rel_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c36b1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67.33135414 64.57100201 61.27441311 60.00060463 58.65205193 56.40827847\n",
      " 53.31119537 51.32714367 49.33261395 47.54439068 46.269557   43.40295792\n",
      " 42.05415058 40.75786495 39.83782101 38.06907368 36.55533314 34.83418465\n",
      " 33.51958656 32.18213272 31.13984156 30.17588854 29.04995108 27.89095736\n",
      " 27.00554848 25.85731554 24.95472002 24.09577179 23.28443193 22.41710711\n",
      " 21.63378    20.82412243 20.16054583 19.53862286 18.38286591 17.94714689\n",
      " 17.05394793 16.16547894 15.6152935  14.67442036 14.24921751 13.59483433\n",
      " 13.15179515 12.6843164  12.3842926  12.03766274 11.53843713 11.1109519\n",
      " 10.86659288 10.61069608 10.31712437  9.93964243  9.71444321  9.48615575\n",
      "  9.14067149  8.76560855  8.37353909  8.08962882  7.95410132  7.76755345\n",
      "  7.35702753  7.075629    6.91544116  6.78558016  6.64930212  6.43153965\n",
      "  6.20015156  6.00742829  5.8313092   5.66502392  5.51256323  5.36497355\n",
      "  5.09306157  4.95911086  4.79514909  4.61898971  4.48799241  4.38134193\n",
      "  4.33169758  4.13522625  4.03800017  3.90009385  3.71679085  3.62814301\n",
      "  3.50254595  3.37715495  3.26365477  3.18006653  2.96473992  2.87210149\n",
      "  2.78167719  2.66159225  2.59506547  2.48472077  2.40099221  2.35489786\n",
      "  2.29352999  2.23693532  2.16163298  2.09615481  2.01321498  1.94178364\n",
      "  1.87379032  1.82737234  1.74913755  1.70827839  1.61247429  1.55624858\n",
      "  1.51291847  1.46958357  1.39279535  1.32633126  1.29207775  1.26052085\n",
      "  1.19915137  1.14739996  1.09538251  1.04258551  1.01830448  0.97049031\n",
      "  0.94588749  0.92192377  0.89604551  0.85790712  0.84131759  0.80829422\n",
      "  0.78114092  0.77471764  0.75720391  0.73424916  0.70420429  0.68803722\n",
      "  0.66277532  0.63554272  0.62349799  0.61077735  0.59649846  0.5804825\n",
      "  0.55926335  0.53322332  0.51972251  0.50682335  0.48708559  0.46786907\n",
      "  0.45202819  0.44091333  0.43199112  0.41983104  0.40602174  0.39409886\n",
      "  0.38608777  0.3735177   0.35440455  0.34676284  0.33427883  0.32141238\n",
      "  0.30678311  0.29959041  0.28510357  0.2713863   0.2620869   0.25364434\n",
      "  0.24024817  0.23345745  0.22416445  0.21836842  0.21155664  0.20574333\n",
      "  0.20274268  0.1948497   0.18971901  0.184142    0.18000911  0.17331052\n",
      "  0.16812012  0.16289279  0.15858858  0.15414759  0.15004585  0.14462164\n",
      "  0.1390709   0.13542338  0.13215146  0.12694813  0.12294674  0.11948541\n",
      "  0.11428118  0.11250701  0.10945136  0.10656345  0.10410821  0.09981283\n",
      "  0.09613014  0.09291428  0.09052764  0.08681127  0.08454229  0.08159017\n",
      "  0.0775217   0.07559406]\n"
     ]
    }
   ],
   "source": [
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d61db64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( 'training_loss_sheave_fml' + str(eta).replace('.', '_')+ '_pout' + str(pout).replace('.', '_'), test_loss)\n",
    "np.save('relative_error_sheave_fml' + str(eta).replace('.', '_')+ '_pout' + str(pout).replace('.', '_'), total_rel_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725be3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_loss_sheave_fml0_01_pout0_01'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'training_loss_sheave_fml' + str(eta).replace('.', '_')+ '_pout' + str(pout).replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1bb8533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relative_error_sheave_fml0_01_pout0_01'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'relative_error_sheave_fml' + str(eta).replace('.', '_')+ '_pout' + str(pout).replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6635c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
