{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d5d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7617ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph implementation\n",
    "def generate_graph(cluster_sizes=[100,100], pin=0.5, pout=0.01, seed=0):\n",
    "    \"\"\"Generate a random connected graph\"\"\"\n",
    "    probs = np.array([[pin, pout],[pout, pin]])\n",
    "    while True:\n",
    "        g = nx.stochastic_block_model(cluster_sizes, probs)\n",
    "        if nx.algorithms.components.is_connected(g):\n",
    "            return g\n",
    "\n",
    "\n",
    "cluster_sizes = [10, 10]\n",
    "pin = 0.5\n",
    "pout = 0.01\n",
    "seed = 0\n",
    "alpha = 1e-3\n",
    "lamda = 1e-3\n",
    "eta = 1e-3\n",
    "no_users = sum(cluster_sizes)\n",
    "batch_size = 20\n",
    "epochs = 1\n",
    "it = 1000\n",
    "G = generate_graph(cluster_sizes, pin, pout, seed)\n",
    "\n",
    "#nx.draw(G, with_labels=True, node_size=100, alpha=1, linewidths=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809e7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.125      0.         0.14285714 0.         0.\n",
      "  0.         0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.         0.         0.125      0.125      0.125\n",
      "  0.125      0.125      0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.14285714 0.         0.16666667\n",
      "  0.16666667 0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.14285714 0.125      0.14285714 0.         0.         0.\n",
      "  0.14285714 0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714]\n",
      " [0.         0.125      0.         0.         0.         0.\n",
      "  0.16666667 0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.16666667 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.16666667 0.         0.         0.\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.16666667 0.14285714 0.16666667 0.\n",
      "  0.         0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.14285714 0.14285714 0.         0.14285714\n",
      "  0.         0.         0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714]\n",
      " [0.16666667 0.125      0.         0.         0.16666667 0.\n",
      "  0.16666667 0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.125      0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714 0.         0.16666667 0.125      0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.         0.16666667 0.16666667 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.         0.14285714 0.16666667 0.         0.125      0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.14285714 0.         0.14285714 0.         0.125      0.14285714\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.16666667 0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.16666667 0.14285714 0.         0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.         0.         0.         0.         0.125      0.16666667\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.125      0.\n",
      "  0.125      0.125      0.         0.125      0.         0.125\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714 0.         0.16666667 0.125      0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.14285714 0.14285714 0.14285714 0.14285714 0.125      0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.16666667 0.14285714 0.         0.\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "[[0.56547619 0.125      0.         0.14285714 0.         0.\n",
      "  0.         0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.125      0.125      0.         0.125      0.125      0.125\n",
      "  0.125      0.125      0.125      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.21428571 0.14285714 0.         0.16666667\n",
      "  0.16666667 0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16666667]\n",
      " [0.14285714 0.125      0.14285714 0.16071429 0.         0.\n",
      "  0.14285714 0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714]\n",
      " [0.         0.125      0.         0.         0.375      0.\n",
      "  0.16666667 0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.16666667 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.16666667 0.         0.         0.56547619\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.16666667 0.14285714 0.16666667 0.\n",
      "  0.23214286 0.         0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.125      0.14285714 0.14285714 0.         0.14285714\n",
      "  0.         0.16071429 0.14285714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714]\n",
      " [0.16666667 0.125      0.         0.         0.16666667 0.\n",
      "  0.16666667 0.14285714 0.23214286 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.73214286 0.         0.\n",
      "  0.         0.         0.         0.         0.125      0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.56547619 0.\n",
      "  0.         0.14285714 0.         0.16666667 0.125      0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.5\n",
      "  0.16666667 0.         0.16666667 0.16666667 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.25595238 0.14285714 0.16666667 0.         0.125      0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14285714 0.\n",
      "  0.14285714 0.16071429 0.14285714 0.         0.125      0.14285714\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.16666667 0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.16666667 0.14285714 0.21428571 0.         0.         0.\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.         0.         0.         0.23214286 0.125      0.16666667\n",
      "  0.14285714 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.125      0.\n",
      "  0.125      0.125      0.         0.125      0.125      0.125\n",
      "  0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14285714 0.         0.16666667 0.125      0.56547619\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14285714 0.         0.\n",
      "  0.14285714 0.14285714 0.14285714 0.14285714 0.125      0.\n",
      "  0.16071429 0.        ]\n",
      " [0.         0.         0.16666667 0.14285714 0.         0.\n",
      "  0.         0.14285714 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.54761905]]\n"
     ]
    }
   ],
   "source": [
    "# Metropolis weights \n",
    "number_nodes = G.number_of_nodes()\n",
    "weights = np.zeros([number_nodes, number_nodes])\n",
    "for edge in G.edges():\n",
    "  i, j = edge[0], edge[1]\n",
    "  weights[i - 1][j - 1] = 1 / (1 + np.max([G.degree(i), G.degree(j)]))\n",
    "  weights[j - 1][i - 1] = weights[i - 1][j - 1]\n",
    "\n",
    "print(weights)\n",
    "\n",
    "weights = weights + np.diag(1 - np.sum(weights, axis=0))\n",
    "\n",
    "metropolis_weights = weights\n",
    "print(metropolis_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654ab72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    transforms_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "    mnist_data_train = datasets.MNIST('./data/mnist', train=True, download=True, transform=transforms_mnist)\n",
    "    mnist_data_test = datasets.MNIST('./data/mnist', train=False, download=True, transform=transforms_mnist)\n",
    "\n",
    "    return mnist_data_train, mnist_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f67564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees(A):\n",
    "    \"\"\"Return the degrees of each node of a graph from its adjacency matrix\"\"\"\n",
    "    return np.sum(A, axis=0).reshape(A.shape[0], 1)\n",
    "\n",
    "def node_degree(n, G):\n",
    "    cnt = 0\n",
    "    for i in G.neighbors(n):\n",
    "        cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def get_neighbors(n, G):\n",
    "    neighbors_list = []\n",
    "    for i in G.neighbors(n):\n",
    "        neighbors_list.append(int(i))\n",
    "    return neighbors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc31eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = {}\n",
    "count = 0\n",
    "W1 = np.array([2, 2])\n",
    "W2 = np.array([-2, 2])\n",
    "W = [W1, W2]\n",
    "m = 200\n",
    "n = 2\n",
    "noise_sd = 0.001\n",
    "for i, cluster_size in enumerate(cluster_sizes):\n",
    "    for j in range(cluster_size):\n",
    "        features = np.random.normal(loc=0.0, scale=1.0, size=(m, n))\n",
    "        label = np.dot(features, W[i]) + np.random.normal(0,noise_sd)\n",
    "        datapoints[count] = {\n",
    "                'features': features,\n",
    "                'degree': node_degree(count, G),\n",
    "                'label': label,\n",
    "                'neighbors': get_neighbors(count, G)\n",
    "            }\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self, user_id):\n",
    "        super(MLP_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 1, bias=False)\n",
    "        #self.fc2 = nn.Linear(4, 1, bias=False)\n",
    "        #self.fc3 = nn.Linear(200, 10)\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        output = self.fc1(x)\n",
    "        #output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd672ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "\n",
    "def grads_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:\n",
    "    r\"\"\"Convert parameters to one vector\n",
    "\n",
    "    Args:\n",
    "        parameters (Iterable[Tensor]): an iterator of Tensors that are the\n",
    "            parameters of a model.\n",
    "\n",
    "    Returns:\n",
    "        The parameters represented by a single vector\n",
    "    \"\"\"\n",
    "    # Flag for the device where the parameter is located\n",
    "    param_device = None\n",
    "\n",
    "    vec = []\n",
    "    for param in parameters:\n",
    "        # Ensure the parameters are located in the same device\n",
    "        param_device = param.grad\n",
    "\n",
    "        vec.append(param_device.view(-1))\n",
    "    return torch.cat(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd3a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(6.5186, grad_fn=<MseLossBackward0>) tensor([ 5.1784, -2.6586]) tensor([-0.2075,  0.5876], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(3.9923, grad_fn=<MseLossBackward0>) tensor([ 3.2408, -1.6909]) tensor([-0.2593,  0.6142], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(4.6513, grad_fn=<MseLossBackward0>) tensor([ 3.5628, -2.3494]) tensor([-0.2917,  0.6311], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "0 tensor(3.1075, grad_fn=<MseLossBackward0>) tensor([ 2.2779, -1.7873]) tensor([-0.3273,  0.6546], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(5.5905, grad_fn=<MseLossBackward0>) tensor([ 4.7732, -2.4902]) tensor([-0.3501,  0.6725], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(3.4250, grad_fn=<MseLossBackward0>) tensor([ 2.9686, -1.6073]) tensor([-0.3978,  0.6974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(3.9989, grad_fn=<MseLossBackward0>) tensor([ 3.2832, -2.2034]) tensor([-0.4275,  0.7135], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "1 tensor(2.6764, grad_fn=<MseLossBackward0>) tensor([ 2.0900, -1.6882]) tensor([-0.4603,  0.7355], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(4.7964, grad_fn=<MseLossBackward0>) tensor([ 4.4002, -2.3324]) tensor([-0.4812,  0.7524], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(2.9399, grad_fn=<MseLossBackward0>) tensor([ 2.7192, -1.5270]) tensor([-0.5252,  0.7757], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(3.4393, grad_fn=<MseLossBackward0>) tensor([ 3.0258, -2.0665]) tensor([-0.5524,  0.7910], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "2 tensor(2.3063, grad_fn=<MseLossBackward0>) tensor([ 1.9177, -1.5941]) tensor([-0.5827,  0.8116], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(4.1164, grad_fn=<MseLossBackward0>) tensor([ 4.0566, -2.1846]) tensor([-0.6019,  0.8276], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(2.5248, grad_fn=<MseLossBackward0>) tensor([ 2.4907, -1.4500]) tensor([-0.6424,  0.8494], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(2.9592, grad_fn=<MseLossBackward0>) tensor([ 2.7889, -1.9379]) tensor([-0.6673,  0.8639], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "3 tensor(1.9883, grad_fn=<MseLossBackward0>) tensor([ 1.7596, -1.5049]) tensor([-0.6952,  0.8833], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(3.5342, grad_fn=<MseLossBackward0>) tensor([ 3.7402, -2.0462]) tensor([-0.7128,  0.8984], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(2.1696, grad_fn=<MseLossBackward0>) tensor([ 2.2814, -1.3762]) tensor([-0.7502,  0.9188], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(2.5470, grad_fn=<MseLossBackward0>) tensor([ 2.5707, -1.8173]) tensor([-0.7730,  0.9326], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "4 tensor(1.7150, grad_fn=<MseLossBackward0>) tensor([ 1.6146, -1.4203]) tensor([-0.7987,  0.9508], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(3.0353, grad_fn=<MseLossBackward0>) tensor([ 3.4487, -1.9165]) tensor([-0.8149,  0.9650], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(1.8653, grad_fn=<MseLossBackward0>) tensor([ 2.0896, -1.3055]) tensor([-0.8494,  0.9841], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(2.1931, grad_fn=<MseLossBackward0>) tensor([ 2.3698, -1.7041]) tensor([-0.8703,  0.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "5 tensor(1.4800, grad_fn=<MseLossBackward0>) tensor([ 1.4816, -1.3402]) tensor([-0.8940,  1.0142], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(2.6078, grad_fn=<MseLossBackward0>) tensor([ 3.1803, -1.7949]) tensor([-0.9088,  1.0276], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(1.6046, grad_fn=<MseLossBackward0>) tensor([ 1.9139, -1.2379]) tensor([-0.9406,  1.0456], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(1.8891, grad_fn=<MseLossBackward0>) tensor([ 2.1847, -1.5979]) tensor([-0.9597,  1.0579], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "6 tensor(1.2778, grad_fn=<MseLossBackward0>) tensor([ 1.3595, -1.2643]) tensor([-0.9816,  1.0739], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(2.2413, grad_fn=<MseLossBackward0>) tensor([ 2.9330, -1.6811]) tensor([-0.9952,  1.0866], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.3810, grad_fn=<MseLossBackward0>) tensor([ 1.7530, -1.1733]) tensor([-1.0245,  1.1034], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.6278, grad_fn=<MseLossBackward0>) tensor([ 2.0143, -1.4983]) tensor([-1.0420,  1.1151], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "7 tensor(1.1037, grad_fn=<MseLossBackward0>) tensor([ 1.2475, -1.1925]) tensor([-1.0622,  1.1301], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.9270, grad_fn=<MseLossBackward0>) tensor([ 2.7052, -1.5745]) tensor([-1.0746,  1.1420], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.1893, grad_fn=<MseLossBackward0>) tensor([ 1.6056, -1.1116]) tensor([-1.1017,  1.1578], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(1.4031, grad_fn=<MseLossBackward0>) tensor([ 1.8573, -1.4048]) tensor([-1.1178,  1.1689], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "8 tensor(0.9538, grad_fn=<MseLossBackward0>) tensor([ 1.1448, -1.1244]) tensor([-1.1363,  1.1829], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.6573, grad_fn=<MseLossBackward0>) tensor([ 2.4953, -1.4746]) tensor([-1.1478,  1.1942], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.0246, grad_fn=<MseLossBackward0>) tensor([ 1.4705, -1.0528]) tensor([-1.1727,  1.2089], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(1.2099, grad_fn=<MseLossBackward0>) tensor([ 1.7128, -1.3171]) tensor([-1.1874,  1.2194], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "9 tensor(0.8246, grad_fn=<MseLossBackward0>) tensor([ 1.0506, -1.0601]) tensor([-1.2046,  1.2326], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.4259, grad_fn=<MseLossBackward0>) tensor([ 2.3019, -1.3810]) tensor([-1.2151,  1.2432], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(0.8833, grad_fn=<MseLossBackward0>) tensor([ 1.3467, -0.9967]) tensor([-1.2381,  1.2570], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(1.0437, grad_fn=<MseLossBackward0>) tensor([ 1.5796, -1.2348]) tensor([-1.2516,  1.2670], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "10 tensor(0.7133, grad_fn=<MseLossBackward0>) tensor([ 0.9641, -0.9992]) tensor([-1.2673,  1.2793], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(1.2272, grad_fn=<MseLossBackward0>) tensor([ 2.1236, -1.2933]) tensor([-1.2770,  1.2893], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.7618, grad_fn=<MseLossBackward0>) tensor([ 1.2334, -0.9432]) tensor([-1.2982,  1.3023], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.9006, grad_fn=<MseLossBackward0>) tensor([ 1.4569, -1.1576]) tensor([-1.3106,  1.3117], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "11 tensor(0.6172, grad_fn=<MseLossBackward0>) tensor([ 0.8848, -0.9417]) tensor([-1.3251,  1.3233], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(1.0566, grad_fn=<MseLossBackward0>) tensor([ 1.9594, -1.2112]) tensor([-1.3340,  1.3327], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.6574, grad_fn=<MseLossBackward0>) tensor([ 1.1296, -0.8923]) tensor([-1.3536,  1.3448], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.7775, grad_fn=<MseLossBackward0>) tensor([ 1.3438, -1.0852]) tensor([-1.3649,  1.3537], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "12 tensor(0.5343, grad_fn=<MseLossBackward0>) tensor([ 0.8120, -0.8873]) tensor([-1.3783,  1.3646], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.9100, grad_fn=<MseLossBackward0>) tensor([ 1.8080, -1.1343]) tensor([-1.3864,  1.3735], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.5676, grad_fn=<MseLossBackward0>) tensor([ 1.0344, -0.8439]) tensor([-1.4045,  1.3848], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.6714, grad_fn=<MseLossBackward0>) tensor([ 1.2397, -1.0173]) tensor([-1.4148,  1.3932], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "13 tensor(0.4628, grad_fn=<MseLossBackward0>) tensor([ 0.7452, -0.8359]) tensor([-1.4272,  1.4034], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.7840, grad_fn=<MseLossBackward0>) tensor([ 1.6685, -1.0623]) tensor([-1.4347,  1.4118], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.4903, grad_fn=<MseLossBackward0>) tensor([ 0.9473, -0.7978]) tensor([-1.4514,  1.4224], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.5799, grad_fn=<MseLossBackward0>) tensor([ 1.1437, -0.9536]) tensor([-1.4609,  1.4304], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "14 tensor(0.4010, grad_fn=<MseLossBackward0>) tensor([ 0.6839, -0.7873]) tensor([-1.4723,  1.4399], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.6757, grad_fn=<MseLossBackward0>) tensor([ 1.5399, -0.9948]) tensor([-1.4791,  1.4478], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.4237, grad_fn=<MseLossBackward0>) tensor([ 0.8675, -0.7540]) tensor([-1.4945,  1.4577], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.5011, grad_fn=<MseLossBackward0>) tensor([ 1.0552, -0.8939]) tensor([-1.5032,  1.4653], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "15 tensor(0.3476, grad_fn=<MseLossBackward0>) tensor([ 0.6277, -0.7414]) tensor([-1.5138,  1.4742], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.5825, grad_fn=<MseLossBackward0>) tensor([ 1.4213, -0.9316]) tensor([-1.5200,  1.4816], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 tensor(0.3663, grad_fn=<MseLossBackward0>) tensor([ 0.7944, -0.7125]) tensor([-1.5342,  1.4909], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.4332, grad_fn=<MseLossBackward0>) tensor([ 0.9737, -0.8379]) tensor([-1.5422,  1.4981], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "16 tensor(0.3014, grad_fn=<MseLossBackward0>) tensor([ 0.5761, -0.6981]) tensor([-1.5519,  1.5064], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.5024, grad_fn=<MseLossBackward0>) tensor([ 1.3120, -0.8724]) tensor([-1.5577,  1.5134], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.3169, grad_fn=<MseLossBackward0>) tensor([ 0.7274, -0.6730]) tensor([-1.5708,  1.5221], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.3746, grad_fn=<MseLossBackward0>) tensor([ 0.8986, -0.7854]) tensor([-1.5781,  1.5289], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "17 tensor(0.2614, grad_fn=<MseLossBackward0>) tensor([ 0.5288, -0.6572]) tensor([-1.5871,  1.5367], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.4334, grad_fn=<MseLossBackward0>) tensor([ 1.2112, -0.8170]) tensor([-1.5924,  1.5433], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.2743, grad_fn=<MseLossBackward0>) tensor([ 0.6661, -0.6355]) tensor([-1.6045,  1.5515], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.3240, grad_fn=<MseLossBackward0>) tensor([ 0.8293, -0.7361]) tensor([-1.6111,  1.5578], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "18 tensor(0.2269, grad_fn=<MseLossBackward0>) tensor([ 0.4853, -0.6187]) tensor([-1.6194,  1.5652], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.3740, grad_fn=<MseLossBackward0>) tensor([ 1.1183, -0.7651]) tensor([-1.6243,  1.5714], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.2375, grad_fn=<MseLossBackward0>) tensor([ 0.6099, -0.6000]) tensor([-1.6355,  1.5790], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.2804, grad_fn=<MseLossBackward0>) tensor([ 0.7655, -0.6899]) tensor([-1.6416,  1.5850], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "19 tensor(0.1970, grad_fn=<MseLossBackward0>) tensor([ 0.4455, -0.5823]) tensor([-1.6492,  1.5919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.3229, grad_fn=<MseLossBackward0>) tensor([ 1.0325, -0.7164]) tensor([-1.6537,  1.5977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.2057, grad_fn=<MseLossBackward0>) tensor([ 0.5585, -0.5663]) tensor([-1.6640,  1.6049], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.2427, grad_fn=<MseLossBackward0>) tensor([ 0.7066, -0.6466]) tensor([-1.6696,  1.6106], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "20 tensor(0.1710, grad_fn=<MseLossBackward0>) tensor([ 0.4089, -0.5479]) tensor([-1.6766,  1.6170], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.2788, grad_fn=<MseLossBackward0>) tensor([ 0.9535, -0.6709]) tensor([-1.6807,  1.6225], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.1783, grad_fn=<MseLossBackward0>) tensor([ 0.5113, -0.5344]) tensor([-1.6903,  1.6292], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.2101, grad_fn=<MseLossBackward0>) tensor([ 0.6523, -0.6060]) tensor([-1.6954,  1.6346], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "21 tensor(0.1486, grad_fn=<MseLossBackward0>) tensor([ 0.3753, -0.5155]) tensor([-1.7019,  1.6406], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.2408, grad_fn=<MseLossBackward0>) tensor([ 0.8806, -0.6282]) tensor([-1.7057,  1.6458], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1545, grad_fn=<MseLossBackward0>) tensor([ 0.4682, -0.5042]) tensor([-1.7145,  1.6521], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1820, grad_fn=<MseLossBackward0>) tensor([ 0.6023, -0.5679]) tensor([-1.7191,  1.6571], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "22 tensor(0.1291, grad_fn=<MseLossBackward0>) tensor([ 0.3445, -0.4850]) tensor([-1.7252,  1.6628], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.2081, grad_fn=<MseLossBackward0>) tensor([ 0.8133, -0.5883]) tensor([-1.7286,  1.6676], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1340, grad_fn=<MseLossBackward0>) tensor([ 0.4287, -0.4755]) tensor([-1.7367,  1.6735], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1576, grad_fn=<MseLossBackward0>) tensor([ 0.5561, -0.5322]) tensor([-1.7410,  1.6783], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "23 tensor(0.1123, grad_fn=<MseLossBackward0>) tensor([ 0.3163, -0.4562]) tensor([-1.7466,  1.6836], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1799, grad_fn=<MseLossBackward0>) tensor([ 0.7513, -0.5509]) tensor([-1.7498,  1.6882], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1163, grad_fn=<MseLossBackward0>) tensor([ 0.3925, -0.4484]) tensor([-1.7573,  1.6937], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.1366, grad_fn=<MseLossBackward0>) tensor([ 0.5136, -0.4988]) tensor([-1.7612,  1.6982], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "24 tensor(0.0976, grad_fn=<MseLossBackward0>) tensor([ 0.2903, -0.4291]) tensor([-1.7663,  1.7031], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1555, grad_fn=<MseLossBackward0>) tensor([ 0.6941, -0.5158]) tensor([-1.7692,  1.7074], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1010, grad_fn=<MseLossBackward0>) tensor([ 0.3593, -0.4228]) tensor([-1.7762,  1.7126], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.1184, grad_fn=<MseLossBackward0>) tensor([ 0.4743, -0.4674]) tensor([-1.7798,  1.7168], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "25 tensor(0.0849, grad_fn=<MseLossBackward0>) tensor([ 0.2665, -0.4035]) tensor([-1.7845,  1.7215], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1345, grad_fn=<MseLossBackward0>) tensor([ 0.6412, -0.4830]) tensor([-1.7872,  1.7255], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.0877, grad_fn=<MseLossBackward0>) tensor([ 0.3289, -0.3985]) tensor([-1.7936,  1.7304], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.1027, grad_fn=<MseLossBackward0>) tensor([ 0.4381, -0.4380]) tensor([-1.7969,  1.7343], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "26 tensor(0.0739, grad_fn=<MseLossBackward0>) tensor([ 0.2447, -0.3794]) tensor([-1.8013,  1.7387], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.1164, grad_fn=<MseLossBackward0>) tensor([ 0.5925, -0.4523]) tensor([-1.8037,  1.7425], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0762, grad_fn=<MseLossBackward0>) tensor([ 0.3011, -0.3756]) tensor([-1.8096,  1.7470], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0891, grad_fn=<MseLossBackward0>) tensor([ 0.4047, -0.4104]) tensor([-1.8126,  1.7508], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "27 tensor(0.0643, grad_fn=<MseLossBackward0>) tensor([ 0.2246, -0.3568]) tensor([-1.8167,  1.7549], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.1007, grad_fn=<MseLossBackward0>) tensor([ 0.5475, -0.4235]) tensor([-1.8189,  1.7585], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0662, grad_fn=<MseLossBackward0>) tensor([ 0.2757, -0.3539]) tensor([-1.8244,  1.7627], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0773, grad_fn=<MseLossBackward0>) tensor([ 0.3738, -0.3846]) tensor([-1.8272,  1.7662], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "28 tensor(0.0560, grad_fn=<MseLossBackward0>) tensor([ 0.2062, -0.3354]) tensor([-1.8309,  1.7701], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0872, grad_fn=<MseLossBackward0>) tensor([ 0.5060, -0.3966]) tensor([-1.8330,  1.7734], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0575, grad_fn=<MseLossBackward0>) tensor([ 0.2523, -0.3334]) tensor([-1.8380,  1.7774], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0670, grad_fn=<MseLossBackward0>) tensor([ 0.3454, -0.3603]) tensor([-1.8405,  1.7807], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "29 tensor(0.0488, grad_fn=<MseLossBackward0>) tensor([ 0.1894, -0.3153]) tensor([-1.8440,  1.7844], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0755, grad_fn=<MseLossBackward0>) tensor([ 0.4677, -0.3713]) tensor([-1.8459,  1.7875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0500, grad_fn=<MseLossBackward0>) tensor([ 0.2310, -0.3140]) tensor([-1.8506,  1.7912], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0582, grad_fn=<MseLossBackward0>) tensor([ 0.3192, -0.3376]) tensor([-1.8529,  1.7944], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "30 tensor(0.0425, grad_fn=<MseLossBackward0>) tensor([ 0.1739, -0.2963]) tensor([-1.8561,  1.7977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0654, grad_fn=<MseLossBackward0>) tensor([ 0.4323, -0.3477]) tensor([-1.8578,  1.8007], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0435, grad_fn=<MseLossBackward0>) tensor([ 0.2114, -0.2957]) tensor([-1.8621,  1.8042], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "31 tensor(0.0505, grad_fn=<MseLossBackward0>) tensor([ 0.2949, -0.3163]) tensor([-1.8643,  1.8071], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 tensor(0.0370, grad_fn=<MseLossBackward0>) tensor([ 0.1596, -0.2785]) tensor([-1.8672,  1.8103], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0566, grad_fn=<MseLossBackward0>) tensor([ 0.3997, -0.3255]) tensor([-1.8688,  1.8131], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0379, grad_fn=<MseLossBackward0>) tensor([ 0.1935, -0.2785]) tensor([-1.8728,  1.8163], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0439, grad_fn=<MseLossBackward0>) tensor([ 0.2726, -0.2964]) tensor([-1.8747,  1.8191], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "32 tensor(0.0323, grad_fn=<MseLossBackward0>) tensor([ 0.1466, -0.2617]) tensor([-1.8775,  1.8221], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0491, grad_fn=<MseLossBackward0>) tensor([ 0.3695, -0.3048]) tensor([-1.8789,  1.8247], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0330, grad_fn=<MseLossBackward0>) tensor([ 0.1771, -0.2622]) tensor([-1.8826,  1.8277], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0381, grad_fn=<MseLossBackward0>) tensor([ 0.2520, -0.2777]) tensor([-1.8844,  1.8304], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "33 tensor(0.0281, grad_fn=<MseLossBackward0>) tensor([ 0.1346, -0.2459]) tensor([-1.8869,  1.8331], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0425, grad_fn=<MseLossBackward0>) tensor([ 0.3417, -0.2854]) tensor([-1.8883,  1.8356], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0287, grad_fn=<MseLossBackward0>) tensor([ 0.1621, -0.2468]) tensor([-1.8917,  1.8385], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0331, grad_fn=<MseLossBackward0>) tensor([ 0.2329, -0.2602]) tensor([-1.8933,  1.8409], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "34 tensor(0.0245, grad_fn=<MseLossBackward0>) tensor([ 0.1236, -0.2310]) tensor([-1.8956,  1.8435], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0369, grad_fn=<MseLossBackward0>) tensor([ 0.3160, -0.2672]) tensor([-1.8969,  1.8458], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0250, grad_fn=<MseLossBackward0>) tensor([ 0.1484, -0.2323]) tensor([-1.9000,  1.8485], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0288, grad_fn=<MseLossBackward0>) tensor([ 0.2153, -0.2438]) tensor([-1.9015,  1.8508], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "35 tensor(0.0214, grad_fn=<MseLossBackward0>) tensor([ 0.1135, -0.2170]) tensor([-1.9037,  1.8533], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0320, grad_fn=<MseLossBackward0>) tensor([ 0.2922, -0.2502]) tensor([-1.9048,  1.8554], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0218, grad_fn=<MseLossBackward0>) tensor([ 0.1358, -0.2186]) tensor([-1.9077,  1.8579], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0250, grad_fn=<MseLossBackward0>) tensor([ 0.1991, -0.2284]) tensor([-1.9091,  1.8601], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "36 tensor(0.0187, grad_fn=<MseLossBackward0>) tensor([ 0.1042, -0.2039]) tensor([-1.9111,  1.8624], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0278, grad_fn=<MseLossBackward0>) tensor([ 0.2703, -0.2343]) tensor([-1.9121,  1.8645], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0190, grad_fn=<MseLossBackward0>) tensor([ 0.1243, -0.2057]) tensor([-1.9148,  1.8668], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0218, grad_fn=<MseLossBackward0>) tensor([ 0.1841, -0.2139]) tensor([-1.9160,  1.8689], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "37 tensor(0.0163, grad_fn=<MseLossBackward0>) tensor([ 0.0957, -0.1915]) tensor([-1.9179,  1.8710], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0241, grad_fn=<MseLossBackward0>) tensor([ 0.2500, -0.2193]) tensor([-1.9188,  1.8729], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0166, grad_fn=<MseLossBackward0>) tensor([ 0.1137, -0.1935]) tensor([-1.9213,  1.8751], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0189, grad_fn=<MseLossBackward0>) tensor([ 0.1703, -0.2004]) tensor([-1.9225,  1.8770], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "38 tensor(0.0142, grad_fn=<MseLossBackward0>) tensor([ 0.0879, -0.1799]) tensor([-1.9242,  1.8790], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0209, grad_fn=<MseLossBackward0>) tensor([ 0.2313, -0.2054]) tensor([-1.9251,  1.8808], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0144, grad_fn=<MseLossBackward0>) tensor([ 0.1041, -0.1820]) tensor([-1.9274,  1.8829], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0165, grad_fn=<MseLossBackward0>) tensor([ 0.1575, -0.1878]) tensor([-1.9284,  1.8847], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "39 tensor(0.0124, grad_fn=<MseLossBackward0>) tensor([ 0.0807, -0.1689]) tensor([-1.9300,  1.8866], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0181, grad_fn=<MseLossBackward0>) tensor([ 0.2140, -0.1923]) tensor([-1.9308,  1.8883], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0126, grad_fn=<MseLossBackward0>) tensor([ 0.0952, -0.1712]) tensor([-1.9329,  1.8902], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0143, grad_fn=<MseLossBackward0>) tensor([ 0.1457, -0.1759]) tensor([-1.9339,  1.8919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "40 tensor(0.0108, grad_fn=<MseLossBackward0>) tensor([ 0.0741, -0.1586]) tensor([-1.9353,  1.8937], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0158, grad_fn=<MseLossBackward0>) tensor([ 0.1980, -0.1800]) tensor([-1.9361,  1.8953], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0110, grad_fn=<MseLossBackward0>) tensor([ 0.0871, -0.1610]) tensor([-1.9381,  1.8971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0125, grad_fn=<MseLossBackward0>) tensor([ 0.1347, -0.1648]) tensor([-1.9389,  1.8987], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "41 tensor(0.0095, grad_fn=<MseLossBackward0>) tensor([ 0.0681, -0.1490]) tensor([-1.9403,  1.9003], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0137, grad_fn=<MseLossBackward0>) tensor([ 0.1833, -0.1686]) tensor([-1.9410,  1.9018], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0096, grad_fn=<MseLossBackward0>) tensor([ 0.0797, -0.1514]) tensor([-1.9428,  1.9035], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0108, grad_fn=<MseLossBackward0>) tensor([ 0.1247, -0.1544]) tensor([-1.9436,  1.9050], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "42 tensor(0.0083, grad_fn=<MseLossBackward0>) tensor([ 0.0626, -0.1399]) tensor([-1.9448,  1.9065], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0119, grad_fn=<MseLossBackward0>) tensor([ 0.1696, -0.1578]) tensor([-1.9455,  1.9079], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0084, grad_fn=<MseLossBackward0>) tensor([ 0.0729, -0.1423]) tensor([-1.9472,  1.9095], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0094, grad_fn=<MseLossBackward0>) tensor([ 0.1154, -0.1446]) tensor([-1.9479,  1.9109], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "43 tensor(0.0072, grad_fn=<MseLossBackward0>) tensor([ 0.0575, -0.1313]) tensor([-1.9491,  1.9124], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0103, grad_fn=<MseLossBackward0>) tensor([ 0.1570, -0.1478]) tensor([-1.9496,  1.9137], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0073, grad_fn=<MseLossBackward0>) tensor([ 0.0667, -0.1338]) tensor([-1.9512,  1.9152], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0082, grad_fn=<MseLossBackward0>) tensor([ 0.1068, -0.1354]) tensor([-1.9519,  1.9165], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "44 tensor(0.0063, grad_fn=<MseLossBackward0>) tensor([ 0.0528, -0.1233]) tensor([-1.9529,  1.9179], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0090, grad_fn=<MseLossBackward0>) tensor([ 0.1453, -0.1383]) tensor([-1.9535,  1.9191], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0064, grad_fn=<MseLossBackward0>) tensor([ 0.0611, -0.1257]) tensor([-1.9549,  1.9205], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0072, grad_fn=<MseLossBackward0>) tensor([ 0.0988, -0.1269]) tensor([-1.9555,  1.9218], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "45 tensor(0.0055, grad_fn=<MseLossBackward0>) tensor([ 0.0485, -0.1157]) tensor([-1.9565,  1.9230], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0078, grad_fn=<MseLossBackward0>) tensor([ 0.1346, -0.1295]) tensor([-1.9570,  1.9242], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0056, grad_fn=<MseLossBackward0>) tensor([ 0.0559, -0.1182]) tensor([-1.9583,  1.9255], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0062, grad_fn=<MseLossBackward0>) tensor([ 0.0914, -0.1188]) tensor([-1.9589,  1.9267], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "46 tensor(0.0048, grad_fn=<MseLossBackward0>) tensor([ 0.0445, -0.1086]) tensor([-1.9598,  1.9278], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0068, grad_fn=<MseLossBackward0>) tensor([ 0.1246, -0.1213]) tensor([-1.9603,  1.9289], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0049, grad_fn=<MseLossBackward0>) tensor([ 0.0511, -0.1111]) tensor([-1.9615,  1.9301], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0054, grad_fn=<MseLossBackward0>) tensor([ 0.0847, -0.1113]) tensor([-1.9620,  1.9313], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "47 tensor(0.0042, grad_fn=<MseLossBackward0>) tensor([ 0.0409, -0.1020]) tensor([-1.9629,  1.9324], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0059, grad_fn=<MseLossBackward0>) tensor([ 0.1154, -0.1135]) tensor([-1.9633,  1.9334], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0042, grad_fn=<MseLossBackward0>) tensor([ 0.0467, -0.1044]) tensor([-1.9644,  1.9345], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0047, grad_fn=<MseLossBackward0>) tensor([ 0.0784, -0.1043]) tensor([-1.9649,  1.9356], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "48 tensor(0.0037, grad_fn=<MseLossBackward0>) tensor([ 0.0376, -0.0957]) tensor([-1.9657,  1.9366], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0051, grad_fn=<MseLossBackward0>) tensor([ 0.1068, -0.1063]) tensor([-1.9661,  1.9376], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0037, grad_fn=<MseLossBackward0>) tensor([ 0.0428, -0.0981]) tensor([-1.9671,  1.9386], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0041, grad_fn=<MseLossBackward0>) tensor([ 0.0726, -0.0977]) tensor([-1.9675,  1.9396], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "49 tensor(0.0032, grad_fn=<MseLossBackward0>) tensor([ 0.0345, -0.0898]) tensor([-1.9683,  1.9406], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(0.0045, grad_fn=<MseLossBackward0>) tensor([ 0.0989, -0.0995]) tensor([-1.9686,  1.9415], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0032, grad_fn=<MseLossBackward0>) tensor([ 0.0391, -0.0921]) tensor([-1.9696,  1.9425], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0036, grad_fn=<MseLossBackward0>) tensor([ 0.0672, -0.0915]) tensor([-1.9700,  1.9434], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "50 tensor(0.0028, grad_fn=<MseLossBackward0>) tensor([ 0.0317, -0.0843]) tensor([-1.9707,  1.9443], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0039, grad_fn=<MseLossBackward0>) tensor([ 0.0917, -0.0932]) tensor([-1.9710,  1.9452], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0028, grad_fn=<MseLossBackward0>) tensor([ 0.0358, -0.0865]) tensor([-1.9719,  1.9461], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0031, grad_fn=<MseLossBackward0>) tensor([ 0.0622, -0.0857]) tensor([-1.9723,  1.9470], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "51 tensor(0.0025, grad_fn=<MseLossBackward0>) tensor([ 0.0292, -0.0791]) tensor([-1.9729,  1.9478], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0034, grad_fn=<MseLossBackward0>) tensor([ 0.0849, -0.0872]) tensor([-1.9732,  1.9486], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0025, grad_fn=<MseLossBackward0>) tensor([ 0.0327, -0.0813]) tensor([-1.9740,  1.9495], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0027, grad_fn=<MseLossBackward0>) tensor([ 0.0576, -0.0802]) tensor([-1.9744,  1.9503], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "52 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0268, -0.0742]) tensor([-1.9749,  1.9511], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0029, grad_fn=<MseLossBackward0>) tensor([ 0.0787, -0.0817]) tensor([-1.9752,  1.9518], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0299, -0.0764]) tensor([-1.9760,  1.9526], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0024, grad_fn=<MseLossBackward0>) tensor([ 0.0534, -0.0751]) tensor([-1.9763,  1.9534], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "53 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0246, -0.0696]) tensor([-1.9768,  1.9542], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0026, grad_fn=<MseLossBackward0>) tensor([ 0.0729, -0.0764]) tensor([-1.9771,  1.9549], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0274, -0.0717]) tensor([-1.9778,  1.9556], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0021, grad_fn=<MseLossBackward0>) tensor([ 0.0495, -0.0704]) tensor([-1.9781,  1.9563], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "54 tensor(0.0016, grad_fn=<MseLossBackward0>) tensor([ 0.0226, -0.0653]) tensor([-1.9786,  1.9570], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0022, grad_fn=<MseLossBackward0>) tensor([ 0.0675, -0.0716]) tensor([-1.9788,  1.9577], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0017, grad_fn=<MseLossBackward0>) tensor([ 0.0250, -0.0673]) tensor([-1.9795,  1.9584], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0018, grad_fn=<MseLossBackward0>) tensor([ 0.0458, -0.0659]) tensor([-1.9797,  1.9591], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "55 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0208, -0.0613]) tensor([-1.9802,  1.9597], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0019, grad_fn=<MseLossBackward0>) tensor([ 0.0626, -0.0670]) tensor([-1.9804,  1.9604], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0229, -0.0632]) tensor([-1.9810,  1.9610], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0016, grad_fn=<MseLossBackward0>) tensor([ 0.0425, -0.0617]) tensor([-1.9812,  1.9617], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "56 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0191, -0.0575]) tensor([-1.9817,  1.9623], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0017, grad_fn=<MseLossBackward0>) tensor([ 0.0580, -0.0627]) tensor([-1.9818,  1.9629], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0209, -0.0594]) tensor([-1.9824,  1.9635], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0014, grad_fn=<MseLossBackward0>) tensor([ 0.0394, -0.0578]) tensor([-1.9826,  1.9641], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "57 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0176, -0.0540]) tensor([-1.9830,  1.9647], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0015, grad_fn=<MseLossBackward0>) tensor([ 0.0538, -0.0587]) tensor([-1.9832,  1.9652], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0191, -0.0557]) tensor([-1.9837,  1.9658], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0012, grad_fn=<MseLossBackward0>) tensor([ 0.0365, -0.0541]) tensor([-1.9839,  1.9663], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "58 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0161, -0.0506]) tensor([-1.9843,  1.9669], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0013, grad_fn=<MseLossBackward0>) tensor([ 0.0498, -0.0550]) tensor([-1.9845,  1.9674], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0175, -0.0523]) tensor([-1.9850,  1.9679], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0338, -0.0507]) tensor([-1.9851,  1.9685], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "59 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0148, -0.0475]) tensor([-1.9855,  1.9690], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0011, grad_fn=<MseLossBackward0>) tensor([ 0.0462, -0.0515]) tensor([-1.9856,  1.9694], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0160, -0.0491]) tensor([-1.9861,  1.9700], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0009, grad_fn=<MseLossBackward0>) tensor([ 0.0314, -0.0475]) tensor([-1.9862,  1.9704], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "60 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0136, -0.0445]) tensor([-1.9866,  1.9709], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0010, grad_fn=<MseLossBackward0>) tensor([ 0.0428, -0.0482]) tensor([-1.9867,  1.9714], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0146, -0.0461]) tensor([-1.9871,  1.9718], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0291, -0.0445]) tensor([-1.9873,  1.9723], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "61 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0125, -0.0418]) tensor([-1.9876,  1.9728], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0008, grad_fn=<MseLossBackward0>) tensor([ 0.0397, -0.0451]) tensor([-1.9877,  1.9732], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0134, -0.0433]) tensor([-1.9881,  1.9736], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0270, -0.0417]) tensor([-1.9882,  1.9741], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "62 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0115, -0.0392]) tensor([-1.9885,  1.9745], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0007, grad_fn=<MseLossBackward0>) tensor([ 0.0368, -0.0422]) tensor([-1.9886,  1.9749], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0122, -0.0406]) tensor([-1.9890,  1.9753], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0250, -0.0390]) tensor([-1.9891,  1.9757], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "63 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0106, -0.0368]) tensor([-1.9893,  1.9761], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0342, -0.0395]) tensor([-1.9894,  1.9764], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0112, -0.0381]) tensor([-1.9898,  1.9768], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0232, -0.0365]) tensor([-1.9899,  1.9772], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "64 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0097, -0.0345]) tensor([-1.9901,  1.9776], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0006, grad_fn=<MseLossBackward0>) tensor([ 0.0317, -0.0370]) tensor([-1.9902,  1.9779], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0102, -0.0357]) tensor([-1.9905,  1.9783], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0215, -0.0342]) tensor([-1.9906,  1.9787], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "65 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0090, -0.0323]) tensor([-1.9909,  1.9790], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0005, grad_fn=<MseLossBackward0>) tensor([ 0.0294, -0.0346]) tensor([-1.9910,  1.9793], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0093, -0.0335]) tensor([-1.9912,  1.9797], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0200, -0.0320]) tensor([-1.9913,  1.9800], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "66 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0082, -0.0303]) tensor([-1.9915,  1.9803], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0273, -0.0324]) tensor([-1.9916,  1.9806], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0085, -0.0315]) tensor([-1.9919,  1.9810], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0185, -0.0300]) tensor([-1.9920,  1.9813], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "67 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0076, -0.0284]) tensor([-1.9922,  1.9816], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0004, grad_fn=<MseLossBackward0>) tensor([ 0.0253, -0.0304]) tensor([-1.9922,  1.9819], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0078, -0.0295]) tensor([-1.9925,  1.9822], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0172, -0.0281]) tensor([-1.9926,  1.9825], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "68 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0070, -0.0267]) tensor([-1.9927,  1.9827], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0235, -0.0284]) tensor([-1.9928,  1.9830], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0071, -0.0277]) tensor([-1.9930,  1.9833], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0160, -0.0263]) tensor([-1.9931,  1.9836], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "69 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0064, -0.0250]) tensor([-1.9933,  1.9838], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0003, grad_fn=<MseLossBackward0>) tensor([ 0.0218, -0.0266]) tensor([-1.9933,  1.9841], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0065, -0.0260]) tensor([-1.9936,  1.9843], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0148, -0.0246]) tensor([-1.9936,  1.9846], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "70 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0059, -0.0235]) tensor([-1.9938,  1.9848], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0202, -0.0249]) tensor([-1.9938,  1.9851], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0059, -0.0244]) tensor([-1.9940,  1.9853], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0138, -0.0231]) tensor([-1.9941,  1.9856], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "71 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0054, -0.0220]) tensor([-1.9942,  1.9858], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0188, -0.0233]) tensor([-1.9943,  1.9860], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0054, -0.0229]) tensor([-1.9945,  1.9863], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0128, -0.0216]) tensor([-1.9945,  1.9865], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "72 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0050, -0.0206]) tensor([-1.9947,  1.9867], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0174, -0.0218]) tensor([-1.9947,  1.9869], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0050, -0.0214]) tensor([-1.9949,  1.9871], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0119, -0.0202]) tensor([-1.9949,  1.9873], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "73 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0046, -0.0193]) tensor([-1.9950,  1.9875], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0002, grad_fn=<MseLossBackward0>) tensor([ 0.0162, -0.0204]) tensor([-1.9951,  1.9877], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0045, -0.0201]) tensor([-1.9953,  1.9879], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0110, -0.0189]) tensor([-1.9953,  1.9881], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "74 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0181]) tensor([-1.9954,  1.9883], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0150, -0.0191]) tensor([-1.9955,  1.9885], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0041, -0.0188]) tensor([-1.9956,  1.9887], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0102, -0.0177]) tensor([-1.9956,  1.9889], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "75 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0170]) tensor([-1.9957,  1.9891], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0139, -0.0179]) tensor([-1.9958,  1.9892], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0038, -0.0177]) tensor([-1.9959,  1.9894], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0095, -0.0166]) tensor([-1.9960,  1.9896], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "76 tensor(8.9227e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0036, -0.0159]) tensor([-1.9961,  1.9898], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(0.0001, grad_fn=<MseLossBackward0>) tensor([ 0.0129, -0.0168]) tensor([-1.9961,  1.9899], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(8.8326e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0035, -0.0166]) tensor([-1.9962,  1.9901], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(9.2461e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0088, -0.0155]) tensor([-1.9963,  1.9903], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "77 tensor(7.8226e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0033, -0.0150]) tensor([-1.9963,  1.9904], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(9.5626e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0120, -0.0157]) tensor([-1.9964,  1.9906], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(7.7344e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0032, -0.0155]) tensor([-1.9965,  1.9907], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(8.0849e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0082, -0.0146]) tensor([-1.9965,  1.9909], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "78 tensor(6.8589e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0030, -0.0140]) tensor([-1.9966,  1.9910], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(8.3493e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0111, -0.0147]) tensor([-1.9966,  1.9912], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(6.7728e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0146]) tensor([-1.9968,  1.9913], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(7.0703e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0076, -0.0136]) tensor([-1.9968,  1.9915], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "79 tensor(6.0146e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0131]) tensor([-1.9969,  1.9916], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(7.2904e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0103, -0.0137]) tensor([-1.9969,  1.9917], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(5.9309e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0136]) tensor([-1.9970,  1.9919], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(6.1835e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0071, -0.0128]) tensor([-1.9970,  1.9920], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "80 tensor(5.2747e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0123]) tensor([-1.9971,  1.9921], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(6.3663e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0096, -0.0129]) tensor([-1.9971,  1.9922], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(5.1935e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0128]) tensor([-1.9972,  1.9924], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(5.4083e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0066, -0.0119]) tensor([-1.9972,  1.9925], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "81 tensor(4.6263e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0116]) tensor([-1.9973,  1.9926], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(5.5597e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0089, -0.0120]) tensor([-1.9973,  1.9927], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(4.5479e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0120]) tensor([-1.9974,  1.9929], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(4.7307e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0061, -0.0112]) tensor([-1.9974,  1.9930], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "82 tensor(4.0581e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0022, -0.0108]) tensor([-1.9975,  1.9931], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(4.8557e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0083, -0.0113]) tensor([-1.9975,  1.9932], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(3.9825e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0112]) tensor([-1.9976,  1.9933], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(4.1385e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0057, -0.0105]) tensor([-1.9976,  1.9934], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "83 tensor(3.5602e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0102]) tensor([-1.9977,  1.9935], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(4.2410e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0077, -0.0106]) tensor([-1.9977,  1.9936], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(3.4874e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0105]) tensor([-1.9978,  1.9937], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(3.6207e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0053, -0.0098]) tensor([-1.9978,  1.9938], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "84 tensor(3.1236e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0095]) tensor([-1.9978,  1.9939], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(3.7044e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0071, -0.0099]) tensor([-1.9979,  1.9940], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(3.0537e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0017, -0.0099]) tensor([-1.9979,  1.9941], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(3.1678e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0049, -0.0092]) tensor([-1.9980,  1.9942], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "85 tensor(2.7409e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0017, -0.0089]) tensor([-1.9980,  1.9943], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(3.2359e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0066, -0.0092]) tensor([-1.9980,  1.9944], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(2.6738e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0015, -0.0092]) tensor([-1.9981,  1.9945], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(2.7719e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0046, -0.0086]) tensor([-1.9981,  1.9946], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "86 tensor(2.4055e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0016, -0.0084]) tensor([-1.9981,  1.9947], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(2.8269e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0062, -0.0087]) tensor([-1.9982,  1.9948], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(2.3414e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0014, -0.0087]) tensor([-1.9982,  1.9949], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(2.4259e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0043, -0.0080]) tensor([-1.9982,  1.9949], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "87 tensor(2.1116e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0014, -0.0079]) tensor([-1.9983,  1.9950], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(2.4699e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0057, -0.0081]) tensor([-1.9983,  1.9951], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(2.0502e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0081]) tensor([-1.9984,  1.9952], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(2.1232e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0040, -0.0075]) tensor([-1.9984,  1.9953], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "88 tensor(1.8538e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0013, -0.0074]) tensor([-1.9984,  1.9953], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(2.1580e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0053, -0.0076]) tensor([-1.9984,  1.9954], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.7952e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0012, -0.0076]) tensor([-1.9985,  1.9955], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.8585e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0037, -0.0071]) tensor([-1.9985,  1.9956], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "89 tensor(1.6277e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0012, -0.0069]) tensor([-1.9985,  1.9956], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.8857e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0049, -0.0071]) tensor([-1.9985,  1.9957], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.5718e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0011, -0.0071]) tensor([-1.9986,  1.9958], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 tensor(1.6269e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0066]) tensor([-1.9986,  1.9958], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "90 tensor(1.4295e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0011, -0.0065]) tensor([-1.9986,  1.9959], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.6478e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0046, -0.0066]) tensor([-1.9986,  1.9960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.3763e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0067]) tensor([-1.9987,  1.9960], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.4245e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0032, -0.0062]) tensor([-1.9987,  1.9961], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "91 tensor(1.2557e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0010, -0.0061]) tensor([-1.9987,  1.9962], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(1.4401e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0042, -0.0062]) tensor([-1.9987,  1.9962], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(1.2050e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0009, -0.0062]) tensor([-1.9988,  1.9963], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(1.2473e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0030, -0.0058]) tensor([-1.9988,  1.9964], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "92 tensor(1.1032e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0009, -0.0057]) tensor([-1.9988,  1.9964], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(1.2587e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0039, -0.0058]) tensor([-1.9988,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(1.0551e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0008, -0.0058]) tensor([-1.9989,  1.9965], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(1.0924e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0028, -0.0054]) tensor([-1.9989,  1.9966], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "93 tensor(9.6953e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0009, -0.0054]) tensor([-1.9989,  1.9966], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(1.1002e-05, grad_fn=<MseLossBackward0>) tensor([ 0.0037, -0.0054]) tensor([-1.9989,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(9.2382e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0008, -0.0055]) tensor([-1.9989,  1.9967], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(9.5682e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0026, -0.0051]) tensor([-1.9990,  1.9968], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "94 tensor(8.5222e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0008, -0.0050]) tensor([-1.9990,  1.9969], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(9.6172e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0034, -0.0051]) tensor([-1.9990,  1.9969], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(8.0883e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0007, -0.0051]) tensor([-1.9990,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(8.3818e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0024, -0.0048]) tensor([-1.9990,  1.9970], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "95 tensor(7.4927e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0007, -0.0047]) tensor([-1.9991,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(8.4074e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0032, -0.0048]) tensor([-1.9991,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(7.0818e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0006, -0.0048]) tensor([-1.9991,  1.9971], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(7.3442e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0023, -0.0044]) tensor([-1.9991,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "96 tensor(6.5903e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0007, -0.0044]) tensor([-1.9991,  1.9972], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(7.3514e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0029, -0.0045]) tensor([-1.9991,  1.9973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(6.2003e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0006, -0.0045]) tensor([-1.9992,  1.9973], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(6.4362e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0021, -0.0042]) tensor([-1.9992,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "97 tensor(5.7980e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0006, -0.0041]) tensor([-1.9992,  1.9974], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(6.4277e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0027, -0.0042]) tensor([-1.9992,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(5.4285e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0005, -0.0042]) tensor([-1.9992,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(5.6410e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0020, -0.0039]) tensor([-1.9992,  1.9975], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "98 tensor(5.1025e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0006, -0.0039]) tensor([-1.9992,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(5.6211e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0025, -0.0039]) tensor([-1.9992,  1.9976], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(4.7532e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0005, -0.0039]) tensor([-1.9993,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(4.9458e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0018, -0.0036]) tensor([-1.9993,  1.9977], grad_fn=<CatBackward0>)\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50, 1])\n",
      "99 tensor(4.4925e-06, grad_fn=<MseLossBackward0>) tensor([ 0.0005, -0.0036]) tensor([-1.9993,  1.9977], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "dataloader = DataLoader(MyDataset(datapoints[19][\"features\"], datapoints[19][\"label\"]), batch_size=50, shuffle=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    for (x, y) in dataloader:\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        print(y.size())\n",
    "        print(yhat.size())\n",
    "        loss = criterion(yhat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        print(i, loss, grads_to_vector(model.parameters()), parameters_to_vector(model.parameters()))\n",
    "        #optimizer.step()\n",
    "        new_model = parameters_to_vector(model.parameters()) - lr * grads_to_vector(model.parameters())\n",
    "        vector_to_parameters(parameters=model.parameters(), vec=new_model)\n",
    "        #if i % 50 ==0:\n",
    "            #lr *= 0.9\n",
    "            \n",
    "\n",
    "#parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfe3e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9993,  1.9978], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52396ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5fe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, alpha, lamda, epochs, projection_list, projected_weights):\n",
    "        self.train_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=batchSize, shuffle=True)\n",
    "        #self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def train(self, model):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5)\n",
    "\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for i, (data, labels) in zip(range(1), self.train_loader):\n",
    "                data, labels = data, labels\n",
    "                optimizer.zero_grad() \n",
    "                output = model(data)  \n",
    "                loss = criterion(output, labels)\n",
    "                #loss += mu/2 * torch.norm(client_param.data - server_param.data)**2\n",
    "                loss.backward()\n",
    "                grads = grads_to_vector(model.parameters())\n",
    "                #optimizer.step()\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                weights = parameters_to_vector(model.parameters())\n",
    "                mat_vec_sum = torch.zeros_like(weights)\n",
    "                for j in G.neighbors(model.user_id):\n",
    "                    mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(torch.transpose(projection_list[model.user_id][j], 0, 1), \n",
    "                                                         projected_weights[j][model.user_id] - projected_weights[model.user_id][j]))\n",
    "                \n",
    "                model_update = parameters_to_vector(model.parameters()) - alpha * (grads + lamda * mat_vec_sum)\n",
    "                \n",
    "            vector_to_parameters(parameters=model.parameters(), vec=model_update)\n",
    "                \n",
    "\n",
    "            train_loss = train_loss/self.batchSize#len(self.train_loader.dataset) \n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "        total_loss = e_loss#sum(e_loss)/len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eeef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing projection matrices\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "#temp = MLP_Net()\n",
    "projection_list = []\n",
    "projected_weights = []\n",
    "\n",
    "def update_ProjWeight(projection_list, projected_weights, first_run=True):\n",
    "    #projected_weights = []\n",
    "    for i in range(no_users):\n",
    "        neighbors_mat = []\n",
    "        neighbors_weights = []\n",
    "        for j in range(no_users):\n",
    "            if j in G.neighbors(i):\n",
    "                with torch.no_grad():\n",
    "                    if first_run == True:\n",
    "                        row, column = parameters_to_vector(models[j].parameters()).size()[0], parameters_to_vector(models[i].parameters()).size()[0]\n",
    "                        mat = torch.zeros((row, column))\n",
    "                        mat.fill_diagonal_(1.0)\n",
    "                        neighbors_mat.append(mat)\n",
    "                        neighbors_weights.append(torch.matmul(mat, parameters_to_vector(models[j].parameters())))\n",
    "                    else:\n",
    "                        neighbors_weights.append(torch.matmul(projection_list[j][i], parameters_to_vector(models[j].parameters())))\n",
    "            else:\n",
    "                neighbors_mat.append(0)\n",
    "                neighbors_weights.append(0)\n",
    "        if first_run == True:\n",
    "            projection_list.append(neighbors_mat)\n",
    "        projected_weights.append(neighbors_weights)\n",
    "\n",
    "update_ProjWeight(projection_list, projected_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion): \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = DataLoader(MyDataset(dataset[\"features\"], dataset[\"label\"]), batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data, labels\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        #_, pred = torch.max(output, 1)\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d1a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0944, -0.2440])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1888, -0.4880], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_Net(user_id=0)\n",
    "\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "with torch.no_grad():    \n",
    "    params = parameters_to_vector(model.parameters())\n",
    "\n",
    "    print(params)\n",
    "\n",
    "params *= 2.\n",
    "\n",
    "vector_to_parameters(parameters=model.parameters(), vec=params)\n",
    "\n",
    "parameters_to_vector(model.parameters())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71472693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:00<01:21, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.53738\n",
      "Training_loss 8.50670\n",
      "Training_loss 8.48036\n",
      "Training_loss 8.45132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:00<01:14, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.42911\n",
      "Training_loss 8.39393\n",
      "Training_loss 8.37661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:00<01:16, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.35580\n",
      "Training_loss 8.30744\n",
      "Training_loss 8.29708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [00:01<01:18, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.25255\n",
      "Training_loss 8.21282\n",
      "Training_loss 8.17620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 15/1000 [00:01<01:18, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.14515\n",
      "Training_loss 8.10755\n",
      "Training_loss 8.06990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 17/1000 [00:01<01:23, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 8.03941\n",
      "Training_loss 8.00898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:01<01:32, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.98718\n",
      "Training_loss 7.96049\n",
      "Training_loss 7.92490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23/1000 [00:01<01:27, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.89574\n",
      "Training_loss 7.88056\n",
      "Training_loss 7.84332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [00:02<01:24, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.81505\n",
      "Training_loss 7.78383\n",
      "Training_loss 7.75723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 29/1000 [00:02<01:37, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.73038\n",
      "Training_loss 7.68149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 31/1000 [00:02<01:41,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.65437\n",
      "Training_loss 7.62496\n",
      "Training_loss 7.60399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1000 [00:03<01:43,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.58463\n",
      "Training_loss 7.55685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 36/1000 [00:03<01:46,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.52570\n",
      "Training_loss 7.47987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [00:03<01:37,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.45608\n",
      "Training_loss 7.42661\n",
      "Training_loss 7.40617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:03<02:04,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.37081\n",
      "Training_loss 7.35382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 42/1000 [00:04<02:30,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.32298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1000 [00:04<02:58,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.30077\n",
      "Training_loss 7.26723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 46/1000 [00:05<03:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.24859\n",
      "Training_loss 7.22545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [00:05<02:38,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.19230\n",
      "Training_loss 7.16160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [00:05<02:14,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.13350\n",
      "Training_loss 7.11602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:05<02:05,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.09933\n",
      "Training_loss 7.07748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [00:06<01:57,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 7.04929\n",
      "Training_loss 7.01933\n",
      "Training_loss 6.98927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1000 [00:06<01:49,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.97184\n",
      "Training_loss 6.93256\n",
      "Training_loss 6.91486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 59/1000 [00:06<01:52,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.88166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 60/1000 [00:06<02:16,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.85551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [00:07<02:37,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.83943\n",
      "Training_loss 6.82066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [00:07<02:17,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.79650\n",
      "Training_loss 6.76668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 66/1000 [00:07<02:02,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.74649\n",
      "Training_loss 6.73180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [00:07<01:55,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.69778\n",
      "Training_loss 6.67856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 69/1000 [00:08<01:53,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.65470\n",
      "Training_loss 6.62453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [00:08<01:51,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.60185\n",
      "Training_loss 6.58558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75/1000 [00:08<01:45,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.56278\n",
      "Training_loss 6.54685\n",
      "Training_loss 6.52453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 78/1000 [00:09<01:37,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.50587\n",
      "Training_loss 6.48437\n",
      "Training_loss 6.45506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 80/1000 [00:09<01:32,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.43105\n",
      "Training_loss 6.40580\n",
      "Training_loss 6.38230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 84/1000 [00:09<01:26, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.36540\n",
      "Training_loss 6.34804\n",
      "Training_loss 6.31646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 86/1000 [00:09<01:25, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.29378\n",
      "Training_loss 6.26283\n",
      "Training_loss 6.22947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 90/1000 [00:10<01:21, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.20831\n",
      "Training_loss 6.17776\n",
      "Training_loss 6.15770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 92/1000 [00:10<01:24, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.14571\n",
      "Training_loss 6.12926\n",
      "Training_loss 6.11803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 96/1000 [00:10<01:21, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.09636\n",
      "Training_loss 6.07209\n",
      "Training_loss 6.05767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 98/1000 [00:10<01:17, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 6.02303\n",
      "Training_loss 6.00800\n",
      "Training_loss 5.97793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:11<01:14, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.94989\n",
      "Training_loss 5.91714\n",
      "Training_loss 5.90185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 104/1000 [00:11<01:12, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.87531\n",
      "Training_loss 5.85292\n",
      "Training_loss 5.82131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 108/1000 [00:11<01:16, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.80285\n",
      "Training_loss 5.78610\n",
      "Training_loss 5.77175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 110/1000 [00:11<01:31,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.75488\n",
      "Training_loss 5.73552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 112/1000 [00:12<01:40,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.72025\n",
      "Training_loss 5.70524\n",
      "Training_loss 5.68869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 114/1000 [00:12<01:31,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.67350\n",
      "Training_loss 5.64397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 118/1000 [00:12<01:33,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.62777\n",
      "Training_loss 5.61619\n",
      "Training_loss 5.59078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/1000 [00:13<01:33,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.57487\n",
      "Training_loss 5.53317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1000 [00:13<01:36,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.51588\n",
      "Training_loss 5.49856\n",
      "Training_loss 5.48474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 125/1000 [00:13<01:29,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.45241\n",
      "Training_loss 5.43245\n",
      "Training_loss 5.41014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [00:13<01:28,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.38779\n",
      "Training_loss 5.37018\n",
      "Training_loss 5.35466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 132/1000 [00:14<01:29,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.32651\n",
      "Training_loss 5.31332\n",
      "Training_loss 5.29267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 134/1000 [00:14<01:23, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.27457\n",
      "Training_loss 5.25281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 136/1000 [00:14<01:30,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.23342\n",
      "Training_loss 5.22374\n",
      "Training_loss 5.19104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/1000 [00:15<01:20, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.17592\n",
      "Training_loss 5.14964\n",
      "Training_loss 5.12748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 142/1000 [00:15<01:26,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.10126\n",
      "Training_loss 5.07664\n",
      "Training_loss 5.06335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 146/1000 [00:15<01:22, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 5.05023\n",
      "Training_loss 5.02985\n",
      "Training_loss 5.01196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 148/1000 [00:15<01:16, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.99693\n",
      "Training_loss 4.97539\n",
      "Training_loss 4.95703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:16<01:16, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.93811\n",
      "Training_loss 4.91832\n",
      "Training_loss 4.89343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 154/1000 [00:16<01:18, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.87409\n",
      "Training_loss 4.84669\n",
      "Training_loss 4.83016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 156/1000 [00:16<01:20, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.81200\n",
      "Training_loss 4.80391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 159/1000 [00:16<01:26,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.78093\n",
      "Training_loss 4.76756\n",
      "Training_loss 4.75093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 163/1000 [00:17<01:22, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.72602\n",
      "Training_loss 4.71591\n",
      "Training_loss 4.69837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 165/1000 [00:17<01:15, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.68528\n",
      "Training_loss 4.66466\n",
      "Training_loss 4.65845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 169/1000 [00:17<01:09, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.64493\n",
      "Training_loss 4.62260\n",
      "Training_loss 4.60740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 173/1000 [00:18<01:03, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.59683\n",
      "Training_loss 4.57591\n",
      "Training_loss 4.55917\n",
      "Training_loss 4.54084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 175/1000 [00:18<01:02, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.52407\n",
      "Training_loss 4.50657\n",
      "Training_loss 4.49480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 179/1000 [00:18<01:01, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.48026\n",
      "Training_loss 4.47107\n",
      "Training_loss 4.44775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 181/1000 [00:18<01:00, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.43362\n",
      "Training_loss 4.40160\n",
      "Training_loss 4.38572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 183/1000 [00:18<01:02, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.37224\n",
      "Training_loss 4.35066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 185/1000 [00:19<01:12, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.33194\n",
      "Training_loss 4.31602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 187/1000 [00:19<01:16, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.29941\n",
      "Training_loss 4.28842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 191/1000 [00:19<01:21,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.27590\n",
      "Training_loss 4.26703\n",
      "Training_loss 4.25187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 193/1000 [00:19<01:21,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.22727\n",
      "Training_loss 4.21498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 195/1000 [00:20<01:24,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.20184\n",
      "Training_loss 4.18392\n",
      "Training_loss 4.17126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 197/1000 [00:20<01:20,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.15698\n",
      "Training_loss 4.14004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [00:20<01:25,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.12496\n",
      "Training_loss 4.11209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 203/1000 [00:20<01:18, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.09865\n",
      "Training_loss 4.08815\n",
      "Training_loss 4.07337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 205/1000 [00:21<01:26,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.05157\n",
      "Training_loss 4.03139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 208/1000 [00:21<01:16, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 4.01634\n",
      "Training_loss 4.00108\n",
      "Training_loss 3.97852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 210/1000 [00:21<01:16, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.96371\n",
      "Training_loss 3.95074\n",
      "Training_loss 3.94439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 214/1000 [00:21<01:12, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.92429\n",
      "Training_loss 3.91591\n",
      "Training_loss 3.89893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 216/1000 [00:22<01:16, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.88359\n",
      "Training_loss 3.87548\n",
      "Training_loss 3.86478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/1000 [00:22<01:08, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.84946\n",
      "Training_loss 3.83389\n",
      "Training_loss 3.82314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 222/1000 [00:22<01:13, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.81547\n",
      "Training_loss 3.80113\n",
      "Training_loss 3.78195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 224/1000 [00:22<01:14, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.77149\n",
      "Training_loss 3.75875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 228/1000 [00:23<01:17,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.73809\n",
      "Training_loss 3.72811\n",
      "Training_loss 3.71451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 231/1000 [00:23<01:19,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.70356\n",
      "Training_loss 3.69303\n",
      "Training_loss 3.67716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 233/1000 [00:23<01:14, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.66496\n",
      "Training_loss 3.65084\n",
      "Training_loss 3.63491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 237/1000 [00:24<01:04, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.61525\n",
      "Training_loss 3.59232\n",
      "Training_loss 3.57916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 239/1000 [00:24<01:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.56000\n",
      "Training_loss 3.55027\n",
      "Training_loss 3.53725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 243/1000 [00:24<00:58, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.52885\n",
      "Training_loss 3.51683\n",
      "Training_loss 3.50119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 247/1000 [00:24<00:56, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.48762\n",
      "Training_loss 3.47440\n",
      "Training_loss 3.46145\n",
      "Training_loss 3.45099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 249/1000 [00:24<00:55, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.43520\n",
      "Training_loss 3.42224\n",
      "Training_loss 3.40742\n",
      "Training_loss 3.39923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 253/1000 [00:25<00:57, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.38869\n",
      "Training_loss 3.37902\n",
      "Training_loss 3.37442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 257/1000 [00:25<01:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.35817\n",
      "Training_loss 3.34366\n",
      "Training_loss 3.33440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 259/1000 [00:25<00:59, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.32041\n",
      "Training_loss 3.30846\n",
      "Training_loss 3.29646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 263/1000 [00:26<00:57, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.28532\n",
      "Training_loss 3.28052\n",
      "Training_loss 3.27223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 267/1000 [00:26<00:55, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.25606\n",
      "Training_loss 3.24297\n",
      "Training_loss 3.23079\n",
      "Training_loss 3.21901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 269/1000 [00:26<00:55, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.21066\n",
      "Training_loss 3.19433\n",
      "Training_loss 3.17700\n",
      "Training_loss 3.16442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 273/1000 [00:26<00:55, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.15980\n",
      "Training_loss 3.14695\n",
      "Training_loss 3.13620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 277/1000 [00:27<01:00, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.12415\n",
      "Training_loss 3.11107\n",
      "Training_loss 3.10170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 279/1000 [00:27<01:03, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.08508\n",
      "Training_loss 3.07533\n",
      "Training_loss 3.06494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 283/1000 [00:27<01:06, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.05244\n",
      "Training_loss 3.04196\n",
      "Training_loss 3.02971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 285/1000 [00:28<01:06, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 3.01363\n",
      "Training_loss 3.00518\n",
      "Training_loss 2.99092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 289/1000 [00:28<01:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.98305\n",
      "Training_loss 2.97049\n",
      "Training_loss 2.95995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 291/1000 [00:28<00:58, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.94992\n",
      "Training_loss 2.93332\n",
      "Training_loss 2.92484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 295/1000 [00:28<00:55, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.91490\n",
      "Training_loss 2.91015\n",
      "Training_loss 2.90139\n",
      "Training_loss 2.88920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 299/1000 [00:29<00:53, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.88069\n",
      "Training_loss 2.87264\n",
      "Training_loss 2.86040\n",
      "Training_loss 2.85321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 303/1000 [00:29<00:52, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.84076\n",
      "Training_loss 2.82790\n",
      "Training_loss 2.81867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 307/1000 [00:29<00:52, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.80593\n",
      "Training_loss 2.79979\n",
      "Training_loss 2.79129\n",
      "Training_loss 2.78519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 311/1000 [00:29<00:50, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.77238\n",
      "Training_loss 2.76145\n",
      "Training_loss 2.74983\n",
      "Training_loss 2.74224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 315/1000 [00:30<00:49, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.73671\n",
      "Training_loss 2.72842\n",
      "Training_loss 2.71505\n",
      "Training_loss 2.69833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 317/1000 [00:30<00:48, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.69144\n",
      "Training_loss 2.68159\n",
      "Training_loss 2.67354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [00:30<00:50, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.66481\n",
      "Training_loss 2.65382\n",
      "Training_loss 2.64451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 325/1000 [00:30<00:48, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.62613\n",
      "Training_loss 2.62115\n",
      "Training_loss 2.61151\n",
      "Training_loss 2.60235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 327/1000 [00:31<00:49, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.59435\n",
      "Training_loss 2.58276\n",
      "Training_loss 2.57081\n",
      "Training_loss 2.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 331/1000 [00:31<00:48, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.55197\n",
      "Training_loss 2.54165\n",
      "Training_loss 2.53038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 335/1000 [00:31<00:51, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.52328\n",
      "Training_loss 2.51473\n",
      "Training_loss 2.49951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 337/1000 [00:31<00:49, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.49037\n",
      "Training_loss 2.47732\n",
      "Training_loss 2.46973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 341/1000 [00:32<00:47, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.46038\n",
      "Training_loss 2.44918\n",
      "Training_loss 2.44332\n",
      "Training_loss 2.43288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 345/1000 [00:32<00:46, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.42495\n",
      "Training_loss 2.41745\n",
      "Training_loss 2.40990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 347/1000 [00:32<00:48, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.40234\n",
      "Training_loss 2.39602\n",
      "Training_loss 2.38469\n",
      "Training_loss 2.37806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [00:32<00:47, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.36950\n",
      "Training_loss 2.36116\n",
      "Training_loss 2.35454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 355/1000 [00:33<00:52, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.34741\n",
      "Training_loss 2.33848\n",
      "Training_loss 2.32763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 357/1000 [00:33<00:56, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.32123\n",
      "Training_loss 2.31332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 359/1000 [00:33<01:03, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.30283\n",
      "Training_loss 2.29539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 361/1000 [00:33<01:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.28319\n",
      "Training_loss 2.27377\n",
      "Training_loss 2.27114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 365/1000 [00:34<00:53, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.26570\n",
      "Training_loss 2.25068\n",
      "Training_loss 2.24230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 367/1000 [00:34<00:51, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.23052\n",
      "Training_loss 2.22366\n",
      "Training_loss 2.21585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 371/1000 [00:34<00:51, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.20768\n",
      "Training_loss 2.19786\n",
      "Training_loss 2.18743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 373/1000 [00:34<00:58, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.18122\n",
      "Training_loss 2.17115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 375/1000 [00:35<01:00, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.16405\n",
      "Training_loss 2.15390\n",
      "Training_loss 2.14855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 379/1000 [00:35<00:56, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.14028\n",
      "Training_loss 2.13480\n",
      "Training_loss 2.13005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 381/1000 [00:35<00:55, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.12101\n",
      "Training_loss 2.11501\n",
      "Training_loss 2.10948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 385/1000 [00:36<00:57, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.10144\n",
      "Training_loss 2.09580\n",
      "Training_loss 2.08999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 387/1000 [00:36<00:56, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.08340\n",
      "Training_loss 2.07456\n",
      "Training_loss 2.06526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 391/1000 [00:36<00:55, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.05845\n",
      "Training_loss 2.05378\n",
      "Training_loss 2.04645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 393/1000 [00:36<00:53, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.04124\n",
      "Training_loss 2.02992\n",
      "Training_loss 2.02312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 397/1000 [00:37<00:51, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 2.01316\n",
      "Training_loss 2.00457\n",
      "Training_loss 1.99637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 399/1000 [00:37<00:53, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.99099\n",
      "Training_loss 1.98485\n",
      "Training_loss 1.97582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 403/1000 [00:37<00:49, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.96777\n",
      "Training_loss 1.96066\n",
      "Training_loss 1.95692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 405/1000 [00:37<00:47, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.95077\n",
      "Training_loss 1.93988\n",
      "Training_loss 1.92988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 409/1000 [00:38<00:46, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.92018\n",
      "Training_loss 1.91580\n",
      "Training_loss 1.91000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 411/1000 [00:38<00:45, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.90352\n",
      "Training_loss 1.89644\n",
      "Training_loss 1.88830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 415/1000 [00:38<00:45, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.87867\n",
      "Training_loss 1.86904\n",
      "Training_loss 1.86057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 417/1000 [00:38<00:46, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.85111\n",
      "Training_loss 1.84458\n",
      "Training_loss 1.83629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 421/1000 [00:38<00:44, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.82948\n",
      "Training_loss 1.82374\n",
      "Training_loss 1.82010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 423/1000 [00:39<00:44, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.81487\n",
      "Training_loss 1.80976\n",
      "Training_loss 1.80365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 427/1000 [00:39<00:42, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.79919\n",
      "Training_loss 1.79128\n",
      "Training_loss 1.78661\n",
      "Training_loss 1.77929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 431/1000 [00:39<00:41, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.77507\n",
      "Training_loss 1.76960\n",
      "Training_loss 1.76372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 433/1000 [00:39<00:45, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.75635\n",
      "Training_loss 1.74951\n",
      "Training_loss 1.74506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 437/1000 [00:40<00:44, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.73769\n",
      "Training_loss 1.73172\n",
      "Training_loss 1.72710\n",
      "Training_loss 1.72161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [00:40<00:42, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.71769\n",
      "Training_loss 1.71217\n",
      "Training_loss 1.70570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 443/1000 [00:40<00:42, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.69570\n",
      "Training_loss 1.69105\n",
      "Training_loss 1.68401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 447/1000 [00:40<00:41, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.67771\n",
      "Training_loss 1.67399\n",
      "Training_loss 1.66899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 449/1000 [00:41<00:41, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.65974\n",
      "Training_loss 1.65414\n",
      "Training_loss 1.64768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 453/1000 [00:41<00:40, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.64119\n",
      "Training_loss 1.63541\n",
      "Training_loss 1.63051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 457/1000 [00:41<00:41, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.62417\n",
      "Training_loss 1.61911\n",
      "Training_loss 1.61303\n",
      "Training_loss 1.60770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 459/1000 [00:41<00:40, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.60192\n",
      "Training_loss 1.59663\n",
      "Training_loss 1.58963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 463/1000 [00:42<00:41, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.58487\n",
      "Training_loss 1.57649\n",
      "Training_loss 1.56985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 465/1000 [00:42<00:40, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.56668\n",
      "Training_loss 1.56175\n",
      "Training_loss 1.55705\n",
      "Training_loss 1.54997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 469/1000 [00:42<00:40, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.54516\n",
      "Training_loss 1.54023\n",
      "Training_loss 1.53623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 473/1000 [00:42<00:39, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.52854\n",
      "Training_loss 1.52474\n",
      "Training_loss 1.51813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 475/1000 [00:43<00:39, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.51078\n",
      "Training_loss 1.50308\n",
      "Training_loss 1.49669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 479/1000 [00:43<00:38, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.48874\n",
      "Training_loss 1.48313\n",
      "Training_loss 1.47364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 481/1000 [00:43<00:38, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.46911\n",
      "Training_loss 1.46510\n",
      "Training_loss 1.46162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 485/1000 [00:43<00:38, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.45720\n",
      "Training_loss 1.45094\n",
      "Training_loss 1.44581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 487/1000 [00:43<00:39, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.43903\n",
      "Training_loss 1.43453\n",
      "Training_loss 1.43054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [00:44<00:40, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.42677\n",
      "Training_loss 1.42122\n",
      "Training_loss 1.41407\n",
      "Training_loss 1.41108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 495/1000 [00:44<00:38, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.40650\n",
      "Training_loss 1.40026\n",
      "Training_loss 1.39642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 497/1000 [00:44<00:37, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.39248\n",
      "Training_loss 1.38989\n",
      "Training_loss 1.38589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [00:45<00:36, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.37958\n",
      "Training_loss 1.37289\n",
      "Training_loss 1.36908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 503/1000 [00:45<00:37, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.36432\n",
      "Training_loss 1.36109\n",
      "Training_loss 1.35675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 507/1000 [00:45<00:36, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.35327\n",
      "Training_loss 1.34850\n",
      "Training_loss 1.34174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [00:45<00:36, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.33460\n",
      "Training_loss 1.33038\n",
      "Training_loss 1.32527\n",
      "Training_loss 1.32137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 515/1000 [00:46<00:36, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.31670\n",
      "Training_loss 1.31070\n",
      "Training_loss 1.30612\n",
      "Training_loss 1.30237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 517/1000 [00:46<00:36, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.29862\n",
      "Training_loss 1.29526\n",
      "Training_loss 1.29251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 521/1000 [00:46<00:37, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.28678\n",
      "Training_loss 1.28245\n",
      "Training_loss 1.27848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 523/1000 [00:46<00:36, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.27241\n",
      "Training_loss 1.26682\n",
      "Training_loss 1.26366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 527/1000 [00:46<00:35, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.25933\n",
      "Training_loss 1.25474\n",
      "Training_loss 1.24949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [00:47<00:34, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.24482\n",
      "Training_loss 1.24188\n",
      "Training_loss 1.23676\n",
      "Training_loss 1.23175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 533/1000 [00:47<00:33, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.22614\n",
      "Training_loss 1.22295\n",
      "Training_loss 1.21778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 537/1000 [00:47<00:33, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.21474\n",
      "Training_loss 1.20955\n",
      "Training_loss 1.20409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 539/1000 [00:47<00:33, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.19840\n",
      "Training_loss 1.19458\n",
      "Training_loss 1.18848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 543/1000 [00:48<00:34, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.18349\n",
      "Training_loss 1.17687\n",
      "Training_loss 1.17209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 545/1000 [00:48<00:34, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.16989\n",
      "Training_loss 1.16519\n",
      "Training_loss 1.16074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 549/1000 [00:48<00:36, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.15640\n",
      "Training_loss 1.15232\n",
      "Training_loss 1.14919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 553/1000 [00:48<00:34, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.14467\n",
      "Training_loss 1.13834\n",
      "Training_loss 1.13434\n",
      "Training_loss 1.12942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 557/1000 [00:49<00:33, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.12542\n",
      "Training_loss 1.12324\n",
      "Training_loss 1.11793\n",
      "Training_loss 1.11267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 561/1000 [00:49<00:30, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.11050\n",
      "Training_loss 1.10631\n",
      "Training_loss 1.10275\n",
      "Training_loss 1.09849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 563/1000 [00:49<00:31, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.09545\n",
      "Training_loss 1.09187\n",
      "Training_loss 1.08784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 567/1000 [00:49<00:30, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.08406\n",
      "Training_loss 1.07989\n",
      "Training_loss 1.07642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 569/1000 [00:50<00:31, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.07000\n",
      "Training_loss 1.06707\n",
      "Training_loss 1.06430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 573/1000 [00:50<00:30, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.06052\n",
      "Training_loss 1.05883\n",
      "Training_loss 1.05428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 577/1000 [00:50<00:32, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.05185\n",
      "Training_loss 1.04772\n",
      "Training_loss 1.04492\n",
      "Training_loss 1.03921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 579/1000 [00:50<00:31, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.03513\n",
      "Training_loss 1.03194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 581/1000 [00:51<00:36, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.02821\n",
      "Training_loss 1.02597\n",
      "Training_loss 1.02259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 585/1000 [00:51<00:33, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.01876\n",
      "Training_loss 1.01413\n",
      "Training_loss 1.01199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 587/1000 [00:51<00:33, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 1.00851\n",
      "Training_loss 1.00467\n",
      "Training_loss 1.00113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 591/1000 [00:51<00:31, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.99854\n",
      "Training_loss 0.99596\n",
      "Training_loss 0.99086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 593/1000 [00:52<00:33, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.98659\n",
      "Training_loss 0.98372\n",
      "Training_loss 0.98073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 597/1000 [00:52<00:32, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.97789\n",
      "Training_loss 0.97486\n",
      "Training_loss 0.97202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 599/1000 [00:52<00:32, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.96955\n",
      "Training_loss 0.96632\n",
      "Training_loss 0.96242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 603/1000 [00:52<00:35, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.95947\n",
      "Training_loss 0.95457\n",
      "Training_loss 0.95198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 605/1000 [00:53<00:33, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.94829\n",
      "Training_loss 0.94681\n",
      "Training_loss 0.94340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 609/1000 [00:53<00:30, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.94086\n",
      "Training_loss 0.93856\n",
      "Training_loss 0.93629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 611/1000 [00:53<00:30, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.93284\n",
      "Training_loss 0.92940\n",
      "Training_loss 0.92716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 615/1000 [00:53<00:29, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.92513\n",
      "Training_loss 0.92179\n",
      "Training_loss 0.91820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 617/1000 [00:53<00:28, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.91487\n",
      "Training_loss 0.91238\n",
      "Training_loss 0.90994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 621/1000 [00:54<00:28, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.90742\n",
      "Training_loss 0.90424\n",
      "Training_loss 0.90144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 623/1000 [00:54<00:28, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.89688\n",
      "Training_loss 0.89399\n",
      "Training_loss 0.88958\n",
      "Training_loss 0.88327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 627/1000 [00:54<00:29, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.87991\n",
      "Training_loss 0.87768\n",
      "Training_loss 0.87525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 631/1000 [00:55<00:28, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.87173\n",
      "Training_loss 0.86795\n",
      "Training_loss 0.86419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 635/1000 [00:55<00:27, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.86127\n",
      "Training_loss 0.85856\n",
      "Training_loss 0.85537\n",
      "Training_loss 0.85098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 639/1000 [00:55<00:26, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.84710\n",
      "Training_loss 0.84503\n",
      "Training_loss 0.84258\n",
      "Training_loss 0.84076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 641/1000 [00:55<00:26, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.83868\n",
      "Training_loss 0.83595\n",
      "Training_loss 0.83335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 645/1000 [00:56<00:28, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.82998\n",
      "Training_loss 0.82730\n",
      "Training_loss 0.82360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 647/1000 [00:56<00:29, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.81964\n",
      "Training_loss 0.81702\n",
      "Training_loss 0.81528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [00:56<00:28, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.81295\n",
      "Training_loss 0.81013\n",
      "Training_loss 0.80777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 653/1000 [00:56<00:28, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.80559\n",
      "Training_loss 0.80231\n",
      "Training_loss 0.80025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 657/1000 [00:57<00:27, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.79827\n",
      "Training_loss 0.79587\n",
      "Training_loss 0.79379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 659/1000 [00:57<00:26, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.79103\n",
      "Training_loss 0.78787\n",
      "Training_loss 0.78580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 663/1000 [00:57<00:25, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.78370\n",
      "Training_loss 0.78104\n",
      "Training_loss 0.77889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 667/1000 [00:57<00:24, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.77716\n",
      "Training_loss 0.77452\n",
      "Training_loss 0.77164\n",
      "Training_loss 0.77009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 671/1000 [00:58<00:23, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.76698\n",
      "Training_loss 0.76487\n",
      "Training_loss 0.76122\n",
      "Training_loss 0.75913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 673/1000 [00:58<00:23, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.75681\n",
      "Training_loss 0.75378\n",
      "Training_loss 0.75217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 677/1000 [00:58<00:23, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.74887\n",
      "Training_loss 0.74606\n",
      "Training_loss 0.74463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 679/1000 [00:58<00:23, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.74234\n",
      "Training_loss 0.73871\n",
      "Training_loss 0.73609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 683/1000 [00:59<00:24, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.73291\n",
      "Training_loss 0.72982\n",
      "Training_loss 0.72644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 685/1000 [00:59<00:24, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.72450\n",
      "Training_loss 0.72243\n",
      "Training_loss 0.71803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 689/1000 [00:59<00:23, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.71661\n",
      "Training_loss 0.71226\n",
      "Training_loss 0.71042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 693/1000 [00:59<00:22, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.70828\n",
      "Training_loss 0.70626\n",
      "Training_loss 0.70440\n",
      "Training_loss 0.70162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 695/1000 [00:59<00:22, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.69959\n",
      "Training_loss 0.69700\n",
      "Training_loss 0.69431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 699/1000 [01:00<00:22, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.69119\n",
      "Training_loss 0.68873\n",
      "Training_loss 0.68599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 703/1000 [01:00<00:21, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.68300\n",
      "Training_loss 0.68018\n",
      "Training_loss 0.67828\n",
      "Training_loss 0.67556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 705/1000 [01:00<00:21, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.67354\n",
      "Training_loss 0.67161\n",
      "Training_loss 0.66919\n",
      "Training_loss 0.66599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 709/1000 [01:00<00:21, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.66269\n",
      "Training_loss 0.66103\n",
      "Training_loss 0.65902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 713/1000 [01:01<00:21, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65677\n",
      "Training_loss 0.65534\n",
      "Training_loss 0.65351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 715/1000 [01:01<00:21, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.65055\n",
      "Training_loss 0.64896\n",
      "Training_loss 0.64693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 719/1000 [01:01<00:20, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.64402\n",
      "Training_loss 0.64233\n",
      "Training_loss 0.64073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 721/1000 [01:01<00:20, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.63798\n",
      "Training_loss 0.63566\n",
      "Training_loss 0.63466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 725/1000 [01:02<00:20, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.63265\n",
      "Training_loss 0.63068\n",
      "Training_loss 0.62824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 727/1000 [01:02<00:21, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.62640\n",
      "Training_loss 0.62344\n",
      "Training_loss 0.62141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 731/1000 [01:02<00:20, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.61884\n",
      "Training_loss 0.61629\n",
      "Training_loss 0.61399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 733/1000 [01:02<00:20, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.61250\n",
      "Training_loss 0.61047\n",
      "Training_loss 0.60731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 737/1000 [01:03<00:19, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.60592\n",
      "Training_loss 0.60418\n",
      "Training_loss 0.60183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 739/1000 [01:03<00:20, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59974\n",
      "Training_loss 0.59694\n",
      "Training_loss 0.59549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 743/1000 [01:03<00:19, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.59321\n",
      "Training_loss 0.59117\n",
      "Training_loss 0.58800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 745/1000 [01:03<00:18, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.58661\n",
      "Training_loss 0.58480\n",
      "Training_loss 0.58181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 749/1000 [01:03<00:17, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.57895\n",
      "Training_loss 0.57678\n",
      "Training_loss 0.57408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 751/1000 [01:04<00:19, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.57229\n",
      "Training_loss 0.57048\n",
      "Training_loss 0.56848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 755/1000 [01:04<00:19, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.56642\n",
      "Training_loss 0.56542\n",
      "Training_loss 0.56376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 759/1000 [01:04<00:17, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.56088\n",
      "Training_loss 0.55793\n",
      "Training_loss 0.55562\n",
      "Training_loss 0.55400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 763/1000 [01:04<00:17, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.55227\n",
      "Training_loss 0.55128\n",
      "Training_loss 0.54952\n",
      "Training_loss 0.54808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 765/1000 [01:05<00:18, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54652\n",
      "Training_loss 0.54458\n",
      "Training_loss 0.54282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 769/1000 [01:05<00:17, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.54041\n",
      "Training_loss 0.53821\n",
      "Training_loss 0.53538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 771/1000 [01:05<00:17, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.53318\n",
      "Training_loss 0.53108\n",
      "Training_loss 0.52960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 775/1000 [01:05<00:16, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52813\n",
      "Training_loss 0.52693\n",
      "Training_loss 0.52540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 777/1000 [01:06<00:16, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.52422\n",
      "Training_loss 0.52231\n",
      "Training_loss 0.52001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 781/1000 [01:06<00:16, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.51854\n",
      "Training_loss 0.51559\n",
      "Training_loss 0.51386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 783/1000 [01:06<00:16, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.51277\n",
      "Training_loss 0.51045\n",
      "Training_loss 0.50896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 787/1000 [01:06<00:16, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50708\n",
      "Training_loss 0.50540\n",
      "Training_loss 0.50370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 789/1000 [01:06<00:15, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.50135\n",
      "Training_loss 0.49981\n",
      "Training_loss 0.49874\n",
      "Training_loss 0.49767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 793/1000 [01:07<00:15, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49683\n",
      "Training_loss 0.49516\n",
      "Training_loss 0.49390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 795/1000 [01:07<00:15, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.49070\n",
      "Training_loss 0.48946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 799/1000 [01:07<00:16, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48774\n",
      "Training_loss 0.48669\n",
      "Training_loss 0.48439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 801/1000 [01:07<00:16, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.48268\n",
      "Training_loss 0.48104\n",
      "Training_loss 0.47919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 805/1000 [01:08<00:16, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47814\n",
      "Training_loss 0.47620\n",
      "Training_loss 0.47482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 807/1000 [01:08<00:16, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.47339\n",
      "Training_loss 0.47166\n",
      "Training_loss 0.46962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 811/1000 [01:08<00:16, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46829\n",
      "Training_loss 0.46617\n",
      "Training_loss 0.46526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 813/1000 [01:09<00:15, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46427\n",
      "Training_loss 0.46272\n",
      "Training_loss 0.46131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 817/1000 [01:09<00:14, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.46035\n",
      "Training_loss 0.45923\n",
      "Training_loss 0.45790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 819/1000 [01:09<00:14, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45604\n",
      "Training_loss 0.45451\n",
      "Training_loss 0.45282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 823/1000 [01:09<00:13, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.45177\n",
      "Training_loss 0.44908\n",
      "Training_loss 0.44755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 825/1000 [01:09<00:13, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.44548\n",
      "Training_loss 0.44263\n",
      "Training_loss 0.44193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 829/1000 [01:10<00:12, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43936\n",
      "Training_loss 0.43814\n",
      "Training_loss 0.43696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 833/1000 [01:10<00:12, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43556\n",
      "Training_loss 0.43426\n",
      "Training_loss 0.43285\n",
      "Training_loss 0.43103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 835/1000 [01:10<00:12, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.43002\n",
      "Training_loss 0.42932\n",
      "Training_loss 0.42795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 839/1000 [01:10<00:11, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42652\n",
      "Training_loss 0.42570\n",
      "Training_loss 0.42333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 841/1000 [01:11<00:11, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.42217\n",
      "Training_loss 0.42099\n",
      "Training_loss 0.41914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 845/1000 [01:11<00:11, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41763\n",
      "Training_loss 0.41631\n",
      "Training_loss 0.41441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 847/1000 [01:11<00:11, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.41289\n",
      "Training_loss 0.41173\n",
      "Training_loss 0.41071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [01:11<00:11, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40949\n",
      "Training_loss 0.40803\n",
      "Training_loss 0.40653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 853/1000 [01:12<00:12, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40503\n",
      "Training_loss 0.40387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 855/1000 [01:12<00:14,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40315\n",
      "Training_loss 0.40148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 857/1000 [01:12<00:15,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.40070\n",
      "Training_loss 0.39953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 860/1000 [01:12<00:13, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39829\n",
      "Training_loss 0.39735\n",
      "Training_loss 0.39600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 862/1000 [01:13<00:12, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39386\n",
      "Training_loss 0.39287\n",
      "Training_loss 0.39137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 866/1000 [01:13<00:11, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.39051\n",
      "Training_loss 0.38866\n",
      "Training_loss 0.38702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 868/1000 [01:13<00:10, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38499\n",
      "Training_loss 0.38359\n",
      "Training_loss 0.38205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 872/1000 [01:13<00:09, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.38039\n",
      "Training_loss 0.37907\n",
      "Training_loss 0.37754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 874/1000 [01:13<00:09, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37687\n",
      "Training_loss 0.37517\n",
      "Training_loss 0.37424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 876/1000 [01:14<00:10, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37263\n",
      "Training_loss 0.37164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 880/1000 [01:14<00:11, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.37057\n",
      "Training_loss 0.36939\n",
      "Training_loss 0.36789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 884/1000 [01:14<00:09, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36673\n",
      "Training_loss 0.36559\n",
      "Training_loss 0.36461\n",
      "Training_loss 0.36373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 886/1000 [01:15<00:09, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.36239\n",
      "Training_loss 0.36140\n",
      "Training_loss 0.35983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 890/1000 [01:15<00:08, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35909\n",
      "Training_loss 0.35777\n",
      "Training_loss 0.35671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 892/1000 [01:15<00:08, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35519\n",
      "Training_loss 0.35433\n",
      "Training_loss 0.35301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 896/1000 [01:15<00:08, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.35223\n",
      "Training_loss 0.35055\n",
      "Training_loss 0.34914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 898/1000 [01:15<00:08, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34797\n",
      "Training_loss 0.34686\n",
      "Training_loss 0.34606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [01:16<00:07, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34538\n",
      "Training_loss 0.34456\n",
      "Training_loss 0.34294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 904/1000 [01:16<00:07, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.34180\n",
      "Training_loss 0.34006\n",
      "Training_loss 0.33904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 908/1000 [01:16<00:07, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33803\n",
      "Training_loss 0.33684\n",
      "Training_loss 0.33610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 910/1000 [01:16<00:07, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33482\n",
      "Training_loss 0.33333\n",
      "Training_loss 0.33211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 914/1000 [01:17<00:06, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.33040\n",
      "Training_loss 0.32946\n",
      "Training_loss 0.32780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 916/1000 [01:17<00:06, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32665\n",
      "Training_loss 0.32516\n",
      "Training_loss 0.32389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 920/1000 [01:17<00:06, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.32231\n",
      "Training_loss 0.32119\n",
      "Training_loss 0.32027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 922/1000 [01:17<00:06, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31890\n",
      "Training_loss 0.31795\n",
      "Training_loss 0.31743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 926/1000 [01:18<00:05, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31653\n",
      "Training_loss 0.31517\n",
      "Training_loss 0.31451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 928/1000 [01:18<00:05, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.31332\n",
      "Training_loss 0.31167\n",
      "Training_loss 0.31016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 932/1000 [01:18<00:05, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30902\n",
      "Training_loss 0.30807\n",
      "Training_loss 0.30738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 934/1000 [01:18<00:05, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30620\n",
      "Training_loss 0.30458\n",
      "Training_loss 0.30358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 938/1000 [01:19<00:05, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.30250\n",
      "Training_loss 0.30107\n",
      "Training_loss 0.30036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 940/1000 [01:19<00:05, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29916\n",
      "Training_loss 0.29800\n",
      "Training_loss 0.29738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 944/1000 [01:19<00:04, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29613\n",
      "Training_loss 0.29533\n",
      "Training_loss 0.29419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 946/1000 [01:19<00:04, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.29260\n",
      "Training_loss 0.29083\n",
      "Training_loss 0.29002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/1000 [01:20<00:04, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28956\n",
      "Training_loss 0.28871\n",
      "Training_loss 0.28743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 952/1000 [01:20<00:03, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28624\n",
      "Training_loss 0.28513\n",
      "Training_loss 0.28427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 956/1000 [01:20<00:03, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28345\n",
      "Training_loss 0.28296\n",
      "Training_loss 0.28195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 958/1000 [01:20<00:03, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.28108\n",
      "Training_loss 0.27993\n",
      "Training_loss 0.27892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 962/1000 [01:21<00:03, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27776\n",
      "Training_loss 0.27733\n",
      "Training_loss 0.27643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 964/1000 [01:21<00:02, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27524\n",
      "Training_loss 0.27418\n",
      "Training_loss 0.27266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 968/1000 [01:21<00:02, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.27181\n",
      "Training_loss 0.27052\n",
      "Training_loss 0.26892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 970/1000 [01:21<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26816\n",
      "Training_loss 0.26723\n",
      "Training_loss 0.26647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 974/1000 [01:22<00:02, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26532\n",
      "Training_loss 0.26423\n",
      "Training_loss 0.26335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 976/1000 [01:22<00:01, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.26259\n",
      "Training_loss 0.26140\n",
      "Training_loss 0.26075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 980/1000 [01:22<00:01, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25989\n",
      "Training_loss 0.25916\n",
      "Training_loss 0.25859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 982/1000 [01:22<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25725\n",
      "Training_loss 0.25666\n",
      "Training_loss 0.25595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 986/1000 [01:23<00:01, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25488\n",
      "Training_loss 0.25418\n",
      "Training_loss 0.25341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 988/1000 [01:23<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.25273\n",
      "Training_loss 0.25199\n",
      "Training_loss 0.25130\n",
      "Training_loss 0.24969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 994/1000 [01:23<00:00, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24859\n",
      "Training_loss 0.24777\n",
      "Training_loss 0.24628\n",
      "Training_loss 0.24543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 996/1000 [01:23<00:00, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24456\n",
      "Training_loss 0.24355\n",
      "Training_loss 0.24294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:24<00:00, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_loss 0.24202\n",
      "Training_loss 0.24087\n",
      "Training_loss 0.23976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#global_model = CNN_Net().cuda()\n",
    "models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "dummy_models = [MLP_Net(user_id=i) for i in range(no_users)]\n",
    "\n",
    "#model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "for curr_round in tqdm(range(1, it+1)):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        dummy_models[i].load_state_dict(models[i].state_dict())\n",
    "        local_update = ClientUpdate(dataset=datapoints[i], batchSize=batch_size, alpha=alpha, lamda=lamda, epochs=1, projection_list=projection_list, projected_weights=projected_weights)\n",
    "        weights, loss = local_update.train(dummy_models[i])\n",
    "        w.append(weights)\n",
    "        local_loss.append(loss)\n",
    "        models[i].load_state_dict(w[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Update prjection matrix\n",
    "    \n",
    "    #print(projection_list[0], projected_weights[0])\n",
    "    \n",
    "    for i in range(no_users):\n",
    "        weights = parameters_to_vector(models[i].parameters())\n",
    "        for j in G.neighbors(i):\n",
    "            weights = parameters_to_vector(model.parameters())\n",
    "            mat_vec_sum = torch.zeros_like(weights)\n",
    "            for k in G.neighbors(i):\n",
    "                 mat_vec_sum = torch.add(mat_vec_sum, torch.matmul(projected_weights[k][i] - projected_weights[i][k],\n",
    "                                                                  torch.transpose(weights, -1, 0)))\n",
    "            projection_list[i][j] = torch.add(projection_list[i][j], -1 * eta * lamda * mat_vec_sum)\n",
    "                                         \n",
    "    projected_weights = []                                          \n",
    "    update_ProjWeight(projection_list, projected_weights, first_run=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "\n",
    "    local_test_acc = []\n",
    "    local_test_loss = []\n",
    "    for k in range(no_users):\n",
    "      \n",
    "      g_loss = testing(models[i], datapoints[i], 50, criterion)\n",
    "      local_test_loss.append(g_loss)\n",
    "    \n",
    "        \n",
    "\n",
    "    g_loss = sum(local_test_loss) / len(local_test_loss)\n",
    "    #g_accuracy = sum(local_test_acc) / len(local_test_acc)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_loss.append(g_loss)\n",
    "    #test_accuracy.append(g_accuracy)\n",
    "    print(\"Training_loss %2.5f\"% (test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_axis = np.arange(1, T+1)\n",
    "y_axis = np.array(test_accuracy)\n",
    "ax.plot(x_axis, y_axis)\n",
    "\n",
    "ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy')\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
